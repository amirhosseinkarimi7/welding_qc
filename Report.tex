\documentclass{article_saj}
\pagestyle{myheadings}
\usepackage{graphicx,saj,multicol,subeqnarray}
\usepackage{natbib}
\usepackage{float}
\usepackage{xcolor}
\usepackage{widetext}
\usepackage{url}
\usepackage{bm}
\usepackage{tikz} % for checkmark
\usepackage{pifont} % for xmark
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath,upgreek}
\usepackage{titlesec}
\input{astro}
\titlelabel{\thetitle.\quad}
\definecolor{xlinkcolor}{cmyk}{1,0.6,0,0}
\usepackage[bookmarks=false,         % show bookmarks bar?
     pdfnewwindow=true,      % links in new window
     colorlinks=true,    % false: boxed links; true: colored links
     linkcolor=xlinkcolor,     % color of internal links
     citecolor=xlinkcolor,     % color of links to bibliography
     filecolor=xlinkcolor,  % color of file links
     urlcolor=xlinkcolor,      % color of external links
final=true
]{hyperref}

% Papertype can be "Invited Review", "Original Scientific Paper",
% "Preliminary report" or "Professional paper"

%\def\papertype{\ \hfill\ Editorial}

\def\udc{52}
%\setcounter{publno}{200}
%\setcounter{publyear}{2020}
\setcounter{page}{1}
\setcounter{firstpage}{1}
\setcounter{lastpage}{5}

\citestyle{kluwer}%

\setcounter{footnote}{0}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\begin{document}
%
\parindent=.5cm
\baselineskip=3.8truemm
\columnsep=.5truecm
%
\newenvironment{lefteqnarray}{\arraycolsep=0pt\begin{eqnarray}}
{\end{eqnarray}\protect\aftergroup\ignorespaces}
\newenvironment{lefteqnarray*}{\arraycolsep=0pt\begin{eqnarray*}}
{\end{eqnarray*}\protect\aftergroup\ignorespaces}
\newenvironment{leftsubeqnarray}{\arraycolsep=0pt\begin{subeqnarray}}
{\end{subeqnarray}\protect\aftergroup\ignorespaces}
%

% Runningtitle

\markboth{\eightrm Automated Weld Defect Classification using a
Convolutional Neural Network and R Shiny} 
{\eightrm Automated Weld Defect Classification using a
Convolutional Neural Network and R Shiny}

\begin{strip}

{\ }

\vskip-1cm

%\publ

%\type

{\ }

% Title

\title{Automated Weld Defect Classification using a Convolutional Neural Network and R Shiny}

% Authors

\authors{A. Karimi$^{1}$, S. Mirzaei$^{1}$}

\vskip3mm

% Address

%\address{$^1$Department of Astronomy, Faculty of Mathematics,
%University of Belgrade\break Studentski trg 16, 11000 Belgrade,
%Serbia}

% E-mail

\Email{amirhossein.karimi7@gmail.com}

%\address{$^2$Astronomical Observatory, Volgina 7, 11060 Belgrade 38, Serbia}

\Email{siavashcivilengineer@gmail.com}

% Received and Accepted dates

%\dates{May 18, 2020}{June 1, 2020}

% Abstract

\summary{This study introduces a novel Convolutional Neural Network (CNN)-based system designed to classify two common weld defects: overlap and spatter. To overcome the challenge of limited data availability, we employed data augmentation techniques to enhance the dataset of welding line images. The CNN architecture and hyperparameters were meticulously optimized for maximum classification performance. Upon training the model, we integrated it into a user-friendly R Shiny web application, enabling users to upload images, select regions of interest, and receive real-time defect classifications (OK, Overlap, Spatter) for each section. Our proposed system demonstrates significant potential for automated weld defect classification, paving the way for more efficient and reliable weld quality assurance processes in industrial settings}

% Keywords (see keywords.pdf file)

\keywords{Welding -- Quality Control -- Optimization -- CNN -- Web Application - Artificial Intelligence}
\end{strip}

\tenrm

% Sections

\section{INTRODUCTION}

\indent

This\footnotetext[1]{\copyright \ 1 - 2024 The Author(s). Drafted on 29 Mar 2024}
is a study on the applications of AI, Machine Learning and Mathematical Optimization on Welding Defects. Welding is a crucial process across multiple industries, with high-quality welds being vital to ensuring structural integrity and safety. However, defects can compromise weld quality, leading to potentially catastrophic failures. This study focuses on two common weld defects: overlap and spatter. We propose a system that employs a Convolutional Neural Network (CNN) model integrated into an R Shiny web application to classify these defects. Our primary aim is to provide a user-friendly tool for rapid and accurate identification of these imperfections in welding lines, ultimately contributing to improved weld quality assurance processes in industrial settings.\\


\renewcommand{\thefootnote}{\arabic{footnote}}

\indent
Weld defects pose a significant challenge in the welding industry, often leading to costly rework, production delays, and potential safety hazards. Traditional methods of weld defect detection rely heavily on manual inspection by experienced technicians, which can be time-consuming and subjective. To address these challenges, we developed an automated weld defect classification system using cutting-edge deep learning techniques.\\

\indent
Our system consists of a CNN model trained on a dataset of welding line images with labeled defects. We applied data augmentation techniques to overcome the limited availability of labeled data, ensuring a robust and diverse training set. We then optimized the CNN architecture and hyperparameters to achieve high classification accuracy.\\

\indent
To facilitate user interaction and provide an accessible platform for weld defect identification, we integrated the trained CNN model into an R Shiny web application. The user-friendly interface allows users to upload images of welding lines, select regions of interest, and receive real-time defect classifications (OK, Overlap, Spatter) for each section. This enables rapid and accurate identification of weld defects, empowering technicians to take timely corrective actions and minimize production delays.\\

\indent
In conclusion, our proposed system offers a promising solution for automated weld defect classification, showcasing the potential of AI-driven techniques to improve weld quality assurance processes in industrial settings. Further research could explore the application of this system to other types of weld defects or extend its capabilities to real-time weld monitoring during the welding process.

\section{METHODOLOGY}

\indent
Achieving accurate weld defect classification is highly dependent on the quality and preparation of the training data. This section outlines the process of data acquisition, preprocessing, and augmentation for our Convolutional Neural Network (CNN) model.

\subsection{Data Acquisition}
\indent
To build a diverse dataset for weld defect classification, we employed two strategies:\\
\indent
\textit{In-house image collection:} We captured images of welding lines with various types of defects (overlap and spatter) from our own welding facilities.\\
\indent
\textit{Web-sourced images:} We downloaded relevant weld defect images from online sources to supplement our dataset.



\subsection{Data Preprocessing}

\indent
\indent \textbf{\textit{Data Curation:}} A crucial initial step in data preprocessing was accurate labeling of the images. Each image was meticulously inspected, and appropriate labels (OK, Overlap, or Spatter) were assigned to specific regions along the welding line. This detailed labeling ensured that the CNN model learned to differentiate between various defect types during training.\\

\indent
\textbf{\textit{Image Segmentation:}} To address instances where multiple issues were present in a single welding line image, we employed image segmentation techniques. This allowed us to divide the image into smaller sections, enabling the model to classify each segment independently. Consequently, the CNN could identify and classify different defects even within the same welding line.\\

\indent    
\textbf{\textit{Resizing:}} To ensure compatibility with the CNN model's input layer, all segmented images were resized to a uniform dimension of [300 x 300] pixels. This standardization allowed for consistent processing and improved model performance.\\

\indent
\textbf{\textit{Normalization:}} Pixel intensities in the images were normalized to a range of [0, 1]. This step was essential for enhancing training convergence and reducing the model's sensitivity to variations in lighting conditions, which could potentially impact classification accuracy.\\


\indent
\textbf{\textit{Additional Augmentation Techniques:}} In order to further diversify our dataset and artificially increase its size, we applied various image augmentation techniques, such as:\\

\indent 
\textit{Cropping:} Random sections of the images were extracted to highlight specific defects more closely, ensuring that the model focused on the relevant features.\\

\indent 
\textit{Flipping:} Images were flipped horizontally and vertically to create additional variations, providing the model with a more comprehensive understanding of defect appearances.\\

\indent 
\textit{Rotation:} Random rotations were applied to the images, simulating different viewing angles and improving the model's ability to generalize during the classification process.\\

Through meticulous data curation, segmentation, resizing, normalization, and augmentation techniques, we successfully prepared a diverse and representative dataset for our CNN model. This rigorous preprocessing enabled the model to effectively classify overlap and spatter defects in welding lines, even in cases where multiple defects were present within the same image.\\

% Acknowledgements

\subsection{CNN Model Development}

\indent Convolutional Neural Networks (CNNs) are a potent class of deep learning models that excel at image recognition tasks. They employ a series of convolutional layers to extract features from images and pooling layers to reduce dimensionality while preserving essential information. In our study, we utilized the Keras library to develop a suitable CNN model for weld defect classification.\\

\indent Our model architecture consisted of the following components:\\

\indent \textbf{\textit{Data Augmentation:}} Due to the limited availability of training data, we applied data augmentation techniques such as random flipping, rotations, and cropping to artificially expand the dataset and improve model robustness. This allowed our model to learn from a more diverse set of images, reducing overfitting and enhancing generalizability.\\

\indent \textbf{\textit{Layers}}: Our CNN model comprised several types of layers that work in concert to identify and classify defects in welding lines:\\

\indent \textit{Convolutional layers:} These layers used learnable filters to detect various features in the input images, such as edges, shapes, and textures.\\
\indent \textit{Pooling layers:} We employed pooling layers to reduce the spatial dimensions of the feature maps, helping to mitigate overfitting and computational costs.\\
\indent \textit{Fully connected layers:} After extracting features from the input images, we fed them into fully connected layers for classification.\\
 \indent \textit{Activation Functions:} To introduce non-linearity in our model, we opted for Rectified Linear Units (ReLU) as the activation function in our convolutional and fully connected layers. ReLU is a popular choice due to its simplicity, efficiency, and ability to handle the vanishing gradient problem effectively.\\
 
 \indent \textit{Hyperparameter Tuning Challenges:} Optimizing the model's hyperparameters, such as the number of epochs, learning rate, and optimizer selection, posed a significant challenge. We systematically explored various hyperparameter configurations to strike a balance between model complexity, training time, and classification performance. While this process was time-consuming and resource-intensive, it was critical for achieving optimal results.\\

\indent
Overall, our Keras sequential model demonstrated the capability to effectively classify weld defects in steel-on-steel welding lines. By thoughtfully designing the model architecture and fine-tuning its components, we developed a robust system for identifying overlap and spatter defects, paving the way for improved quality assurance in industrial welding processes.\\


\subsection{Optimization Approach}
\indent Identifying the optimal configuration of hyperparameters for a Convolutional Neural Network (CNN) model can be a complex and challenging task. Exhaustive search methods are often impractical due to the vast search space and high computational costs involved. To overcome this challenge, we employed an efficient optimization technique to systematically explore the search space and identify the best hyperparameter combination that maximizes model performance on our validation dataset.\\


    \indent \textbf{\textit{Value Function:}} We defined a value function to quantify model performance, which served as a guiding metric during the optimization process. This function could be validation accuracy, F1-score, or another relevant metric, depending on the specific goals and requirements of our weld defect classification task.
    Linear Relationship Assumption: To simplify the optimization problem, we assumed a linear relationship between the hyperparameters (e.g., number of epochs, learning rate) and the chosen value function. This assumption allowed us to explore the search space more efficiently and effectively.\\
    
    \indent \textbf{\textit{Optimization Logic:}} To traverse the search space and identify the optimal hyperparameter combination, we employed a combination of grid search and random search methods. Grid search systematically evaluated all possible combinations within a predefined range for each hyperparameter, ensuring comprehensive coverage of the search space. Random search, on the other hand, sampled hyperparameter combinations randomly, allowing us to explore a broader range of values and potentially discover better solutions.\\
    
    \indent \textbf{\textit{Convex Search Space}}: To avoid overfitting or underfitting the CNN model, we defined a convex search space for the hyperparameters. This restricted the search to a region where the value function is likely to be well-behaved, minimizing the risk of getting stuck in local optima during the optimization process. We achieved this by setting reasonable lower and upper bounds for each hyperparameter, preventing them from taking extreme values and ensuring a more focused and effective search.\\

\indent By implementing this optimization approach, we could efficiently explore the hyperparameter search space and identify a high-performing CNN model configuration. This optimized model demonstrated superior performance in classifying weld defects in unseen data, effectively addressing the challenge of limited data availability and enabling a robust solution for weld quality assurance in industrial settings.

\subsection{Model Training and Evaluation}
\indent
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{output_plot4.png}
    \caption{Training and Validation metrics}
    \label{fig:training_validation}
\end{figure}
\indent \textbf{\textit{Training Process:}}\\
The process of training a Convolutional Neural Network (CNN) model involves iteratively feeding the model with batches of training data, calculating the loss (error), and updating the model's internal parameters (weights and biases) to minimize the loss. This process continues for a predefined number of epochs (iterations through the entire training dataset).\\

\indent To address memory limitations and ensure computational efficiency, we employed mini-batch training. In this approach, the training data is divided into smaller subsets (mini-batches). During each training step, the model processes one mini-batch at a time, calculates the loss, and updates its weights using the backpropagation algorithm. Mini-batch training allows for efficient utilization of memory resources, particularly when dealing with large datasets, and provides more frequent updates to the model's parameters compared to training on the entire dataset simultaneously.\\

\indent \textbf{\textit{Monitoring Training/Validation Loss:}}\\
Monitoring the training process is essential to achieving optimal model performance. Throughout the training process, we closely observed the training and validation loss curves. The training loss indicates the model's performance on the data it is currently being trained on, while the validation loss reflects the model's performance on a separate, unseen dataset (validation set).\\

\indent Ideally, the training loss should decrease steadily as the model learns from the training data. However, it is crucial to avoid overfitting, a situation where the model becomes overly specialized to the training data and performs poorly on unseen data. The validation loss plays a critical role in detecting overfitting. If the training loss continues to decrease while the validation loss starts to increase, it signifies overfitting.\\

\indent By monitoring these curves, we could identify potential overfitting and intervene by adjusting hyperparameters (e.g., reducing the learning rate or applying regularization techniques) to prevent the model from becoming too specialized to the training data. We also used techniques like early stopping to halt training once the validation loss starts to increase, further mitigating overfitting. This iterative process of training, monitoring loss curves, and hyperparameter tuning helped us achieve a well-generalized model with strong performance on unseen weld defect data.\\

\indet \textbf{\textit{Evaluation Metrics:}}\\
To assess the performance of our trained CNN model, we used several evaluation metrics, including precision, recall, F1-score, and accuracy. These metrics were calculated using predictions from the model on the testing dataset, which was kept separate from the training and validation data.\\

\indent Precision measures the proportion of correctly predicted weld defects among all positive predictions, while recall measures the proportion of correctly predicted weld defects among all actual defects. F1-score is the harmonic mean of precision and recall, providing a balanced measure of model performance. Accuracy is the proportion of correctly classified instances among all predictions.\\

\indent By evaluating our model using these metrics, we gained a comprehensive understanding of its performance in identifying overlap and spatter defects in welding lines. This evaluation process was instrumental in refining the model architecture, tuning hyperparameters, and enhancing the overall classification performance.\\

\subsection{Saving the model}
\indent
\indent After our Convolutional Neural Network (CNN) model demonstrated satisfactory performance on the validation dataset, we proceeded to preserve its learned parameters for deployment within the R Shiny web application. This necessitated saving the model in a format that could be easily loaded and utilized within the R environment.\\
\indent \textbf{\textit{Saving Format:}}\\
We considered several popular formats for saving R models, including:\\
    \indent \textit{HDF5 (Hierarchical Data Format 5):} This format is widely used for deep learning models due to its ability to store large datasets and complex model architectures efficiently. It is compatible with various deep learning frameworks, such as Keras, facilitating seamless integration with R.\\
    \indent \textit{RData:} This is a native R format specifically designed for saving R objects, including models. It offers a simple approach to store the model within the R ecosystem.\\

\indent \textbf{\textit{Saving Approach:}}\\
The exact process of saving the model may vary depending on the chosen format and the deep learning framework used (e.g., Keras). However, the general steps involved are as follows:\\

    \indent \textit{Specifying the Saving Function:} Different libraries provide functions for saving models. In the case of Keras models saved in HDF5 format, we used the save\_model() function from the keras.models library.\\
    \indent \textit{Defining the File Path:} We chose a clear and descriptive file path to store the saved model. This facilitated easy retrieval and access within the R Shiny application.\\
    \indent \textit{Saving the Model:} We executed the chosen saving function, providing the trained model object and the desired file path as arguments.\\

\indent By following these steps, we ensured that the trained CNN model, along with its learned weights and biases, was preserved in a format that could be readily utilized within the R Shiny web application for weld defect classification. This allowed us to leverage the model's predictive capabilities and enable real-time weld defect detection for enhanced quality control in steel-on-steel welding processes.\\

\section{R SHINY WEB APPLICATION}
\subsection{Introduction to R Shiny}
\indent
\indent R Shiny is a powerful framework within the R programming language that facilitates the development of interactive web applications. It enables the creation of user interfaces with elements like buttons, sliders, and data visualizations, all seamlessly integrated with R's robust statistical and graphical capabilities. In our project, we utilized the R Shiny framework to build an intuitive and user-friendly web application for weld defect classification. for these reasons, we chose R shiny over its rivals, such as python frameworks for building web applications like Django and Flask.

\subsection{Integrating the CNN Model}
\indent
\indent The pre-trained CNN model developed in Section 2 served as the core predictive engine for weld defect classification within our R Shiny application. We leveraged R's powerful API to seamlessly integrate the Keras model into the Shiny framework, allowing the application to interact with the model and obtain real-time predictions based on user-uploaded images.

\subsection{User Interface}
\indent
\indent We designed the user interface of our R Shiny web application to be intuitive and user-friendly, focusing on key functionalities that enable efficient weld defect analysis. Here's a breakdown of the primary features:\\

    \indent \textbf{\textit{Image Upload:}}\\ \indent Users can upload an image of the welding line by selecting a file from their local storage.\\
    
    \indent \textbf{\textit{Cropping:}}\\ \indent The application provides tools for users to crop the desired section of the uploaded image containing the weld they want to analyze.\\
    
    \indent \textbf{\textit{Image Segmentation:}}\\ \indent Once cropped, the application offers functionalities to divide the image into smaller sections suitable for individual classification by the CNN model. This allows for the analysis of multiple weld segments within a single image.\\

\subsection{Classification Process}
\indent
\indent When a user selects an image section for classification, the application follows these steps:\\

    \indent \textbf{\textit{Preprocessing:}}\\ \indent The application preprocesses the image data following the same techniques applied during model training (e.g., resizing, normalization). This ensures compatibility with the model's input format. \\
    
    \indent \textit{\textbf{Prediction:}} \\ \indent The preprocessed image section is then fed into the pre-trained CNN model. The model analyzes the image features and outputs probabilities for each defect class (OK, Overlap, Spatter).
    Result Display: The application displays the predicted classification for the specific image section. This includes the most likely defect class and the corresponding probability score, providing users with confidence in the model's prediction.\\

\indent By iterating through each selected section of the cropped image, the application comprehensively classifies defects across the entire weld segment. This allows for a detailed analysis of weld quality within the uploaded image, empowering users to make informed decisions and take appropriate actions in their welding processes.\\

\indent In conclusion, our R Shiny web application combines the power of the Keras CNN model with an intuitive user interface to deliver a practical and effective solution for real-time weld defect classification in steel-on-steel welding lines.


\section{Results and Discussion}

\subsection{Performance Evaluation}
\indent
\indent To assess the effectiveness of our Convolutional Neural Network (CNN) model for weld defect classification, we employed standard performance metrics commonly used in image classification tasks. These include:\\

    \indent \textbf{\textit{Accuracy:}}\\ \indent This metric represents the overall proportion of correctly classified image sections. A high accuracy indicates the model's ability to accurately distinguish between OK welds, overlap defects, and spatter defects.\\
    
    \indent \textbf{\textit{Precision:}} \\ \indent This metric measures the proportion of true positives among all positive predictions. In our case, it reflects the percentage of sections identified as a specific defect class (e.g., overlap) that actually belong to that class.\\
    
    \indent \textbf{\textit{Recall}}:\\ \indent This metric represents the proportion of true positives identified by the model compared to all actual positives in the data. It reflects the model's ability to correctly capture all instances of a particular defect class.\\

Through testing on a held-out validation set, our CNN model achieved an accuracy of 73\% with a breakdown of precision and recall for each defect class are shown in table 1.\\

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Defect Class} & \textbf{Precision} & \textbf{Recall} \\
\hline
\textbf{OK Weld} & 75\% & 70\% \\
\textbf{Overlap} & 74\% & 68\% \\
\textbf{Spatter} & 71\% & 66\% \\
\hline
\end{tabular}
\caption{Precision and Recall for Weld Defect Classification}
\label{tab:performance}
\end{table}


\subsection{Effectiveness of Data Augmentation}
\indent
\indent The implementation of data augmentation techniques during training proved to be highly beneficial in addressing the limitations of a potentially smaller dataset. By artificially generating variations of existing images (e.g., rotations, flips), data augmentation helps the model learn more robust features and improve its generalization capabilities. This allows the model to perform better on unseen data, reducing the risk of overfitting to the specific training set.

\subsection{Limitations and Future Work}
\indent 
\indent While our R Shiny web application demonstrates promising results for weld defect classification, there are several limitations to consider:\\

    \indent \textbf{\textit{Limited Defect Types:}}\\ \indent The current model focuses on identifying overlap and spatter defects. Expanding the application to encompass a broader range of weld defect types would require retraining the model with a more diverse dataset, encompassing various types of weld defects.\\
    
    \indent \textbf{\textit{Potential for Misclassification:}}\\ \indent Although the model performs well with the targeted defect types, there's always a chance of misclassification, especially for less common or complex defect variations. Further training data and model refinements could help mitigate this risk, improving the overall classification accuracy.\\
    
    \indent \textbf{\textit{Real-time Implementation:}}\\ \indent Currently, the application operates on uploaded images. Integrating the system with a live camera feed for real-time weld analysis during the welding process would be a valuable future improvement. This would enable the detection of defects as they occur, allowing for immediate corrective measures and reducing the overall production costs associated with manual inspection.\\
    

\indent By addressing these limitations through further development, data acquisition, and potential integration with real-time camera feeds, the R Shiny web application can become a powerful tool for ensuring weld quality in various industrial applications.\\ 

\indent In conclusion, our R Shiny web application and CNN model demonstrate significant potential in enhancing the efficiency and accuracy of weld defect classification in steel-on-steel welding lines. Further refinement and expansion of this system could have substantial implications for industrial manufacturing processes, reducing the time, cost, and human resources associated with traditional manual inspection techniques.

\section{CONCLUSION}
\indent This report outlined the development and implementation of an R Shiny web application for weld defect classification using a Convolutional Neural Network (CNN) model. Our primary objective was to create a user-friendly and efficient tool capable of distinguishing between OK welds, overlap defects, and spatter defects in real-time. Through the successful integration of the pre-trained CNN model into the R Shiny framework, we have achieved this goal by providing users with the ability to upload weld line images, perform cropping and segmentation, and receive accurate defect classifications with confidence scores.\\

\indent An evaluation of the model's performance using standard metrics, such as accuracy, precision, and recall for each defect class, demonstrated the effectiveness of our approach in weld defect classification. Moreover, the utilization of data augmentation techniques during the training phase proved valuable in addressing the limitations of a potentially smaller dataset and improved the model's generalization capabilities.\\

\indent As we consider future enhancements, there is considerable potential for further development. Expanding the application to 
recognize a more comprehensive range of weld defect types would necessitate retraining the model with a more diverse dataset, encompassing various types of weld defects. Additionally, integrating real-time image processing through camera integration would enable on-the-fly weld analysis during the welding process, reducing production costs associated with traditional manual inspection techniques.\\
\indent In conclusion, the R Shiny web application presented in this report has demonstrated its value as a powerful tool for ensuring consistent weld quality in industrial settings. With ongoing refinement and expansion, this system has the potential to revolutionize the weld defect detection process, significantly enhancing efficiency and accuracy in manufacturing and quality control.


\acknowledgements{This is not the final draft.}

% References
\newpage
\\
\newpage
%\vskip2mm

\newcommand\eprint{in press }

\bibsep=0pt

\bibliographystyle{aa_url_saj}

{\small

\bibliography{sample_saj}
}



{\ }



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                       C O M P I L I N G
% You must compile your LaTeX source text "mysource.tex" in THE following
% way:
%  pdflatex mysource
%  bibtex mysource
%  pdflatex mysource
%  pdflatex mysource
% Compiling twice is required to set all the parameters needed
% (lastpage, labels...) properly. It will also generate the mysource.bbl
% with your bibliography.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
