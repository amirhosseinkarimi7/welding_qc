{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prerequisits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 10:47:25.972851: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-01 10:47:26.023989: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-01 10:47:26.263642: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-01 10:47:26.263690: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-01 10:47:26.314249: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-01 10:47:26.409790: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-01 10:47:26.410872: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-01 10:47:27.377770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images: 381\n",
      "Found 401 files belonging to 3 classes.\n",
      "Using 321 files for training.\n",
      "Found 401 files belonging to 3 classes.\n",
      "Using 80 files for validation.\n",
      "['Okey', 'Spatter', 'overlap']\n",
      "minumum value: 0.0 maximum values:  1.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "#Tensorflow libs\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_dir = pathlib.Path('database')\n",
    "\n",
    "#get image count\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(\"Total Images:\",image_count)\n",
    "\n",
    "\n",
    "# Batch size\n",
    "batch_size = 45\n",
    "# image height\n",
    "img_height = 250\n",
    "# image width\n",
    "img_width = 250\n",
    "\n",
    "# split dataset for train\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=142,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "\n",
    "# split dataset for validation\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=142,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "#get class names\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "\n",
    "#Create autotune object\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(234).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Create a normalization layer\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "#normalize dataser using with norm. layer\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "# sparete as image and label\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "# check the first image max and min value\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(\"minumum value:\",np.min(first_image), \"maximum values: \",np.max(first_image))\n",
    "\n",
    "# Define the function to convert images to grayscale\n",
    "def grayscale_conversion(image):\n",
    "    return tf.image.rgb_to_grayscale(image)\n",
    "\n",
    "\n",
    "\n",
    "# create augmentation sequentions\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.Lambda(grayscale_conversion, output_shape=(img_height, img_width, 1)),  # Convert to grayscale\n",
    "  ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get class names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  \n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 1)),  # Update input shape\n",
    "\n",
    "  layers.Conv2D(400, 3, [10,10],padding='same', activation='tanh'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.1),  # Adjusted dropout rate\n",
    "\n",
    "  #layers.Flatten(),\n",
    "  layers.Conv2D(600, 3,[7,7], padding='same', activation='tanh'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.3),\n",
    "\n",
    "  #layers.Flatten(),\n",
    "  #layers.Conv2D(200, 3,[5,5], padding='same', activation='tanh'),\n",
    "  #layers.MaxPooling2D(),\n",
    "  #layers.Dropout(0.3),\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(1500, activation='tanh'),\n",
    "  #layers.Flatten(),\n",
    "  #layers.Dense(1000, activation='tanh'),\n",
    "  #layers.Flatten(),\n",
    "  layers.Dense(650,activation='relu'),\n",
    "  layers.Dense(500, activation='tanh'),\n",
    "  layers.Dense(650,activation='relu'),\n",
    "  layers.Dense(500, activation='tanh'),\n",
    "  layers.Dense(650,activation='relu'),\n",
    "  layers.Dense(500, activation='tanh'),\n",
    "  layers.Dense(650,activation='relu'),\n",
    "  layers.Dense(500, activation='tanh'),\n",
    "  #layers.Dense(250,activation='relu'),\n",
    "  layers.Dense(650,activation='relu'),\n",
    "  layers.Dense(500, activation='tanh'),\n",
    "  layers.Dense(650,activation='relu'),\n",
    "  layers.Dense(500, activation='tanh'),\n",
    "  layers.Dense(100,activation='tanh'),\n",
    "  layers.Dense(50,activation='relu'),\n",
    "  layers.Dense(25,activation='tanh'),\n",
    "  layers.Dense(10,activation='relu'),\n",
    "  layers.Dense(5,activation='tanh'),\n",
    "  layers.Dense(50,activation='relu'),\n",
    "  layers.Dense(25,activation='tanh'),\n",
    "  layers.Dense(10,activation='relu'),\n",
    "  layers.Dense(5,activation='tanh'),\n",
    "  #layers.Dense(3,activation='relu'),\n",
    "  #layers.Flatten(),\n",
    "  layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiler and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 250, 250, 1)       0         \n",
      "                                                                 \n",
      " rescaling_1 (Rescaling)     (None, 250, 250, 1)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 25, 25, 400)       4000      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 12, 12, 400)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 12, 400)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 2, 2, 600)         2160600   \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 1, 1, 600)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 1, 600)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 600)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1500)              901500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 650)               975650    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 500)               325500    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 650)               325650    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 500)               325500    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 650)               325650    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 500)               325500    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 650)               325650    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 500)               325500    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 650)               325650    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 500)               325500    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 650)               325650    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 500)               325500    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               50100     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                260       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 50)                300       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                260       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7681648 (29.30 MB)\n",
      "Trainable params: 7681648 (29.30 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.01)\n",
    "model.compile(optimizer = opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "8/8 [==============================] - 3s 178ms/step - loss: 1.0964 - accuracy: 0.4268 - val_loss: 1.0927 - val_accuracy: 0.4750\n",
      "Epoch 2/3000\n",
      "8/8 [==============================] - 1s 138ms/step - loss: 1.0898 - accuracy: 0.4704 - val_loss: 1.0875 - val_accuracy: 0.4750\n",
      "Epoch 3/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 1.0849 - accuracy: 0.4704 - val_loss: 1.0821 - val_accuracy: 0.4750\n",
      "Epoch 4/3000\n",
      "8/8 [==============================] - 1s 137ms/step - loss: 1.0789 - accuracy: 0.4704 - val_loss: 1.0777 - val_accuracy: 0.4750\n",
      "Epoch 5/3000\n",
      "8/8 [==============================] - 1s 137ms/step - loss: 1.0752 - accuracy: 0.4704 - val_loss: 1.0746 - val_accuracy: 0.4750\n",
      "Epoch 6/3000\n",
      "8/8 [==============================] - 1s 138ms/step - loss: 1.0725 - accuracy: 0.4704 - val_loss: 1.0722 - val_accuracy: 0.4750\n",
      "Epoch 7/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 1.0704 - accuracy: 0.4704 - val_loss: 1.0704 - val_accuracy: 0.4750\n",
      "Epoch 8/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0686 - accuracy: 0.4704 - val_loss: 1.0689 - val_accuracy: 0.4750\n",
      "Epoch 9/3000\n",
      "8/8 [==============================] - 1s 138ms/step - loss: 1.0673 - accuracy: 0.4704 - val_loss: 1.0678 - val_accuracy: 0.4750\n",
      "Epoch 10/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0659 - accuracy: 0.4704 - val_loss: 1.0669 - val_accuracy: 0.4750\n",
      "Epoch 11/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0653 - accuracy: 0.4704 - val_loss: 1.0662 - val_accuracy: 0.4750\n",
      "Epoch 12/3000\n",
      "8/8 [==============================] - 1s 137ms/step - loss: 1.0646 - accuracy: 0.4704 - val_loss: 1.0656 - val_accuracy: 0.4750\n",
      "Epoch 13/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 1.0640 - accuracy: 0.4704 - val_loss: 1.0650 - val_accuracy: 0.4750\n",
      "Epoch 14/3000\n",
      "8/8 [==============================] - 1s 138ms/step - loss: 1.0636 - accuracy: 0.4704 - val_loss: 1.0646 - val_accuracy: 0.4750\n",
      "Epoch 15/3000\n",
      "8/8 [==============================] - 1s 137ms/step - loss: 1.0633 - accuracy: 0.4704 - val_loss: 1.0641 - val_accuracy: 0.4750\n",
      "Epoch 16/3000\n",
      "8/8 [==============================] - 1s 139ms/step - loss: 1.0630 - accuracy: 0.4704 - val_loss: 1.0637 - val_accuracy: 0.4750\n",
      "Epoch 17/3000\n",
      "8/8 [==============================] - 1s 137ms/step - loss: 1.0627 - accuracy: 0.4704 - val_loss: 1.0632 - val_accuracy: 0.4750\n",
      "Epoch 18/3000\n",
      "8/8 [==============================] - 1s 139ms/step - loss: 1.0623 - accuracy: 0.4704 - val_loss: 1.0629 - val_accuracy: 0.4750\n",
      "Epoch 19/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 1.0622 - accuracy: 0.4704 - val_loss: 1.0626 - val_accuracy: 0.4750\n",
      "Epoch 20/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0621 - accuracy: 0.4704 - val_loss: 1.0622 - val_accuracy: 0.4750\n",
      "Epoch 21/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 1.0617 - accuracy: 0.4704 - val_loss: 1.0619 - val_accuracy: 0.4750\n",
      "Epoch 22/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0615 - accuracy: 0.4704 - val_loss: 1.0616 - val_accuracy: 0.4750\n",
      "Epoch 23/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 1.0612 - accuracy: 0.4704 - val_loss: 1.0614 - val_accuracy: 0.4750\n",
      "Epoch 24/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0612 - accuracy: 0.4704 - val_loss: 1.0609 - val_accuracy: 0.4750\n",
      "Epoch 25/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0611 - accuracy: 0.4704 - val_loss: 1.0606 - val_accuracy: 0.4750\n",
      "Epoch 26/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0609 - accuracy: 0.4704 - val_loss: 1.0604 - val_accuracy: 0.4750\n",
      "Epoch 27/3000\n",
      "8/8 [==============================] - 1s 136ms/step - loss: 1.0610 - accuracy: 0.4704 - val_loss: 1.0602 - val_accuracy: 0.4750\n",
      "Epoch 28/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 1.0608 - accuracy: 0.4704 - val_loss: 1.0599 - val_accuracy: 0.4750\n",
      "Epoch 29/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 1.0607 - accuracy: 0.4704 - val_loss: 1.0596 - val_accuracy: 0.4750\n",
      "Epoch 30/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0604 - accuracy: 0.4704 - val_loss: 1.0594 - val_accuracy: 0.4750\n",
      "Epoch 31/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0604 - accuracy: 0.4704 - val_loss: 1.0591 - val_accuracy: 0.4750\n",
      "Epoch 32/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0602 - accuracy: 0.4704 - val_loss: 1.0587 - val_accuracy: 0.4750\n",
      "Epoch 33/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0601 - accuracy: 0.4704 - val_loss: 1.0582 - val_accuracy: 0.4750\n",
      "Epoch 34/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 1.0600 - accuracy: 0.4704 - val_loss: 1.0578 - val_accuracy: 0.4750\n",
      "Epoch 35/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0597 - accuracy: 0.4704 - val_loss: 1.0576 - val_accuracy: 0.4750\n",
      "Epoch 36/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 1.0598 - accuracy: 0.4704 - val_loss: 1.0571 - val_accuracy: 0.4750\n",
      "Epoch 37/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0592 - accuracy: 0.4704 - val_loss: 1.0564 - val_accuracy: 0.4750\n",
      "Epoch 38/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0593 - accuracy: 0.4704 - val_loss: 1.0563 - val_accuracy: 0.4750\n",
      "Epoch 39/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 1.0595 - accuracy: 0.4704 - val_loss: 1.0557 - val_accuracy: 0.4750\n",
      "Epoch 40/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 1.0592 - accuracy: 0.4704 - val_loss: 1.0561 - val_accuracy: 0.4750\n",
      "Epoch 41/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 1.0587 - accuracy: 0.4704 - val_loss: 1.0554 - val_accuracy: 0.4750\n",
      "Epoch 42/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0591 - accuracy: 0.4704 - val_loss: 1.0544 - val_accuracy: 0.4750\n",
      "Epoch 43/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0580 - accuracy: 0.4704 - val_loss: 1.0538 - val_accuracy: 0.4750\n",
      "Epoch 44/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 1.0589 - accuracy: 0.4704 - val_loss: 1.0535 - val_accuracy: 0.4750\n",
      "Epoch 45/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0581 - accuracy: 0.4704 - val_loss: 1.0525 - val_accuracy: 0.4750\n",
      "Epoch 46/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0582 - accuracy: 0.4704 - val_loss: 1.0528 - val_accuracy: 0.4750\n",
      "Epoch 47/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 1.0581 - accuracy: 0.4704 - val_loss: 1.0520 - val_accuracy: 0.4750\n",
      "Epoch 48/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 1.0584 - accuracy: 0.4704 - val_loss: 1.0519 - val_accuracy: 0.4750\n",
      "Epoch 49/3000\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 1.0574 - accuracy: 0.4704 - val_loss: 1.0531 - val_accuracy: 0.4750\n",
      "Epoch 50/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 1.0579 - accuracy: 0.4704 - val_loss: 1.0499 - val_accuracy: 0.4750\n",
      "Epoch 51/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 1.0567 - accuracy: 0.4704 - val_loss: 1.0496 - val_accuracy: 0.4750\n",
      "Epoch 52/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0572 - accuracy: 0.4704 - val_loss: 1.0508 - val_accuracy: 0.4750\n",
      "Epoch 53/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0569 - accuracy: 0.4704 - val_loss: 1.0512 - val_accuracy: 0.4750\n",
      "Epoch 54/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 1.0565 - accuracy: 0.4704 - val_loss: 1.0478 - val_accuracy: 0.4750\n",
      "Epoch 55/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 1.0571 - accuracy: 0.4704 - val_loss: 1.0471 - val_accuracy: 0.4750\n",
      "Epoch 56/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 1.0560 - accuracy: 0.4704 - val_loss: 1.0465 - val_accuracy: 0.4750\n",
      "Epoch 57/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0553 - accuracy: 0.4704 - val_loss: 1.0454 - val_accuracy: 0.4750\n",
      "Epoch 58/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0556 - accuracy: 0.4704 - val_loss: 1.0512 - val_accuracy: 0.4750\n",
      "Epoch 59/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0551 - accuracy: 0.4704 - val_loss: 1.0446 - val_accuracy: 0.4750\n",
      "Epoch 60/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 1.0574 - accuracy: 0.4704 - val_loss: 1.0441 - val_accuracy: 0.4750\n",
      "Epoch 61/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0537 - accuracy: 0.4704 - val_loss: 1.0500 - val_accuracy: 0.4750\n",
      "Epoch 62/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0550 - accuracy: 0.4704 - val_loss: 1.0515 - val_accuracy: 0.4750\n",
      "Epoch 63/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 1.0552 - accuracy: 0.4704 - val_loss: 1.0419 - val_accuracy: 0.4750\n",
      "Epoch 64/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0548 - accuracy: 0.4704 - val_loss: 1.0416 - val_accuracy: 0.4750\n",
      "Epoch 65/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 1.0536 - accuracy: 0.4704 - val_loss: 1.0432 - val_accuracy: 0.4750\n",
      "Epoch 66/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 1.0538 - accuracy: 0.4704 - val_loss: 1.0386 - val_accuracy: 0.4750\n",
      "Epoch 67/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 1.0526 - accuracy: 0.4704 - val_loss: 1.0424 - val_accuracy: 0.4750\n",
      "Epoch 68/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 1.0520 - accuracy: 0.4704 - val_loss: 1.0417 - val_accuracy: 0.4750\n",
      "Epoch 69/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 1.0542 - accuracy: 0.4704 - val_loss: 1.0338 - val_accuracy: 0.4750\n",
      "Epoch 70/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 1.0506 - accuracy: 0.4704 - val_loss: 1.0471 - val_accuracy: 0.4750\n",
      "Epoch 71/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0528 - accuracy: 0.4704 - val_loss: 1.0398 - val_accuracy: 0.4750\n",
      "Epoch 72/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0496 - accuracy: 0.4704 - val_loss: 1.0406 - val_accuracy: 0.4750\n",
      "Epoch 73/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 1.0501 - accuracy: 0.4704 - val_loss: 1.0308 - val_accuracy: 0.4750\n",
      "Epoch 74/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 1.0484 - accuracy: 0.4704 - val_loss: 1.0281 - val_accuracy: 0.4750\n",
      "Epoch 75/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 1.0477 - accuracy: 0.4704 - val_loss: 1.0380 - val_accuracy: 0.4750\n",
      "Epoch 76/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 1.0504 - accuracy: 0.4704 - val_loss: 1.0230 - val_accuracy: 0.4750\n",
      "Epoch 77/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 1.0479 - accuracy: 0.4704 - val_loss: 1.0220 - val_accuracy: 0.4750\n",
      "Epoch 78/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 1.0505 - accuracy: 0.4704 - val_loss: 1.0201 - val_accuracy: 0.4750\n",
      "Epoch 79/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 1.0455 - accuracy: 0.4704 - val_loss: 1.0285 - val_accuracy: 0.4750\n",
      "Epoch 80/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 1.0461 - accuracy: 0.4704 - val_loss: 1.0226 - val_accuracy: 0.4750\n",
      "Epoch 81/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 1.0460 - accuracy: 0.4704 - val_loss: 1.0309 - val_accuracy: 0.4750\n",
      "Epoch 82/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0438 - accuracy: 0.4704 - val_loss: 1.0137 - val_accuracy: 0.4750\n",
      "Epoch 83/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0455 - accuracy: 0.4704 - val_loss: 1.0133 - val_accuracy: 0.4750\n",
      "Epoch 84/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0441 - accuracy: 0.4704 - val_loss: 1.0124 - val_accuracy: 0.4750\n",
      "Epoch 85/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0420 - accuracy: 0.4704 - val_loss: 1.0102 - val_accuracy: 0.4750\n",
      "Epoch 86/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0458 - accuracy: 0.4704 - val_loss: 1.0219 - val_accuracy: 0.4750\n",
      "Epoch 87/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0468 - accuracy: 0.4704 - val_loss: 1.0102 - val_accuracy: 0.4750\n",
      "Epoch 88/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0448 - accuracy: 0.4704 - val_loss: 1.0060 - val_accuracy: 0.4750\n",
      "Epoch 89/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0423 - accuracy: 0.4704 - val_loss: 1.0374 - val_accuracy: 0.4750\n",
      "Epoch 90/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 1.0502 - accuracy: 0.4704 - val_loss: 1.0053 - val_accuracy: 0.4750\n",
      "Epoch 91/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0436 - accuracy: 0.4704 - val_loss: 1.0105 - val_accuracy: 0.4750\n",
      "Epoch 92/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0481 - accuracy: 0.4704 - val_loss: 1.0040 - val_accuracy: 0.4750\n",
      "Epoch 93/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0400 - accuracy: 0.4704 - val_loss: 1.0261 - val_accuracy: 0.4750\n",
      "Epoch 94/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0336 - accuracy: 0.4704 - val_loss: 0.9965 - val_accuracy: 0.4750\n",
      "Epoch 95/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0515 - accuracy: 0.4704 - val_loss: 1.0081 - val_accuracy: 0.4750\n",
      "Epoch 96/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0382 - accuracy: 0.4704 - val_loss: 1.0011 - val_accuracy: 0.4750\n",
      "Epoch 97/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 1.0479 - accuracy: 0.4704 - val_loss: 0.9936 - val_accuracy: 0.4750\n",
      "Epoch 98/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0433 - accuracy: 0.4704 - val_loss: 1.0088 - val_accuracy: 0.4750\n",
      "Epoch 99/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0444 - accuracy: 0.4704 - val_loss: 0.9961 - val_accuracy: 0.4750\n",
      "Epoch 100/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 1.0434 - accuracy: 0.4704 - val_loss: 1.0048 - val_accuracy: 0.4750\n",
      "Epoch 101/3000\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 1.0443 - accuracy: 0.4704 - val_loss: 0.9999 - val_accuracy: 0.4750\n",
      "Epoch 102/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 1.0452 - accuracy: 0.4704 - val_loss: 0.9915 - val_accuracy: 0.4750\n",
      "Epoch 103/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 1.0341 - accuracy: 0.4704 - val_loss: 0.9881 - val_accuracy: 0.4750\n",
      "Epoch 104/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0428 - accuracy: 0.4704 - val_loss: 1.0271 - val_accuracy: 0.4750\n",
      "Epoch 105/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0430 - accuracy: 0.4704 - val_loss: 0.9938 - val_accuracy: 0.4750\n",
      "Epoch 106/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0361 - accuracy: 0.4704 - val_loss: 1.0062 - val_accuracy: 0.5625\n",
      "Epoch 107/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0361 - accuracy: 0.4829 - val_loss: 0.9816 - val_accuracy: 0.5000\n",
      "Epoch 108/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0293 - accuracy: 0.4829 - val_loss: 0.9804 - val_accuracy: 0.5500\n",
      "Epoch 109/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0316 - accuracy: 0.5047 - val_loss: 1.0297 - val_accuracy: 0.5000\n",
      "Epoch 110/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 1.0364 - accuracy: 0.4860 - val_loss: 0.9786 - val_accuracy: 0.5375\n",
      "Epoch 111/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 1.0418 - accuracy: 0.4642 - val_loss: 0.9819 - val_accuracy: 0.5875\n",
      "Epoch 112/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0295 - accuracy: 0.5140 - val_loss: 0.9785 - val_accuracy: 0.5750\n",
      "Epoch 113/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0290 - accuracy: 0.4953 - val_loss: 1.0018 - val_accuracy: 0.6250\n",
      "Epoch 114/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0503 - accuracy: 0.4704 - val_loss: 0.9720 - val_accuracy: 0.5625\n",
      "Epoch 115/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0285 - accuracy: 0.5016 - val_loss: 1.0177 - val_accuracy: 0.5625\n",
      "Epoch 116/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0351 - accuracy: 0.4766 - val_loss: 1.0085 - val_accuracy: 0.5750\n",
      "Epoch 117/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0468 - accuracy: 0.4922 - val_loss: 0.9696 - val_accuracy: 0.6250\n",
      "Epoch 118/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0371 - accuracy: 0.4891 - val_loss: 0.9647 - val_accuracy: 0.5625\n",
      "Epoch 119/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0384 - accuracy: 0.4704 - val_loss: 0.9742 - val_accuracy: 0.5375\n",
      "Epoch 120/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0322 - accuracy: 0.4922 - val_loss: 0.9635 - val_accuracy: 0.5625\n",
      "Epoch 121/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 1.0305 - accuracy: 0.4953 - val_loss: 0.9741 - val_accuracy: 0.6500\n",
      "Epoch 122/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0290 - accuracy: 0.5078 - val_loss: 0.9837 - val_accuracy: 0.5375\n",
      "Epoch 123/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 1.0324 - accuracy: 0.4922 - val_loss: 0.9597 - val_accuracy: 0.6250\n",
      "Epoch 124/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0245 - accuracy: 0.5078 - val_loss: 0.9561 - val_accuracy: 0.6125\n",
      "Epoch 125/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0193 - accuracy: 0.5109 - val_loss: 0.9603 - val_accuracy: 0.5750\n",
      "Epoch 126/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 1.0420 - accuracy: 0.4735 - val_loss: 0.9558 - val_accuracy: 0.6125\n",
      "Epoch 127/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 1.0315 - accuracy: 0.4860 - val_loss: 0.9592 - val_accuracy: 0.5750\n",
      "Epoch 128/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 1.0403 - accuracy: 0.4517 - val_loss: 1.0303 - val_accuracy: 0.4625\n",
      "Epoch 129/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 1.0267 - accuracy: 0.4860 - val_loss: 0.9503 - val_accuracy: 0.6000\n",
      "Epoch 130/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0419 - accuracy: 0.4798 - val_loss: 0.9690 - val_accuracy: 0.5500\n",
      "Epoch 131/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 1.0502 - accuracy: 0.4393 - val_loss: 0.9565 - val_accuracy: 0.6250\n",
      "Epoch 132/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0299 - accuracy: 0.5078 - val_loss: 0.9633 - val_accuracy: 0.6250\n",
      "Epoch 133/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0284 - accuracy: 0.5047 - val_loss: 0.9620 - val_accuracy: 0.6250\n",
      "Epoch 134/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 1.0255 - accuracy: 0.5078 - val_loss: 0.9549 - val_accuracy: 0.6625\n",
      "Epoch 135/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0307 - accuracy: 0.4984 - val_loss: 0.9872 - val_accuracy: 0.5500\n",
      "Epoch 136/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0159 - accuracy: 0.5171 - val_loss: 0.9484 - val_accuracy: 0.5750\n",
      "Epoch 137/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0475 - accuracy: 0.4953 - val_loss: 1.0223 - val_accuracy: 0.5000\n",
      "Epoch 138/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 1.0265 - accuracy: 0.4829 - val_loss: 0.9874 - val_accuracy: 0.5500\n",
      "Epoch 139/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0285 - accuracy: 0.5078 - val_loss: 0.9460 - val_accuracy: 0.6250\n",
      "Epoch 140/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0265 - accuracy: 0.4984 - val_loss: 0.9474 - val_accuracy: 0.6000\n",
      "Epoch 141/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0255 - accuracy: 0.5016 - val_loss: 0.9574 - val_accuracy: 0.5750\n",
      "Epoch 142/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 1.0289 - accuracy: 0.4673 - val_loss: 0.9822 - val_accuracy: 0.5625\n",
      "Epoch 143/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 1.0501 - accuracy: 0.4486 - val_loss: 0.9495 - val_accuracy: 0.6250\n",
      "Epoch 144/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0221 - accuracy: 0.5078 - val_loss: 0.9572 - val_accuracy: 0.6250\n",
      "Epoch 145/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0385 - accuracy: 0.4704 - val_loss: 0.9484 - val_accuracy: 0.6375\n",
      "Epoch 146/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0191 - accuracy: 0.4984 - val_loss: 0.9522 - val_accuracy: 0.5625\n",
      "Epoch 147/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0055 - accuracy: 0.5140 - val_loss: 0.9704 - val_accuracy: 0.5500\n",
      "Epoch 148/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0331 - accuracy: 0.4611 - val_loss: 0.9610 - val_accuracy: 0.5500\n",
      "Epoch 149/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 1.0329 - accuracy: 0.4891 - val_loss: 0.9451 - val_accuracy: 0.6625\n",
      "Epoch 150/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0153 - accuracy: 0.4984 - val_loss: 0.9368 - val_accuracy: 0.6125\n",
      "Epoch 151/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 1.0250 - accuracy: 0.5078 - val_loss: 0.9763 - val_accuracy: 0.5500\n",
      "Epoch 152/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 1.0289 - accuracy: 0.4891 - val_loss: 0.9410 - val_accuracy: 0.6250\n",
      "Epoch 153/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 1.0229 - accuracy: 0.4984 - val_loss: 0.9370 - val_accuracy: 0.6250\n",
      "Epoch 154/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 1.0224 - accuracy: 0.4829 - val_loss: 0.9401 - val_accuracy: 0.6125\n",
      "Epoch 155/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0306 - accuracy: 0.4860 - val_loss: 1.0128 - val_accuracy: 0.5125\n",
      "Epoch 156/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0391 - accuracy: 0.4704 - val_loss: 0.9380 - val_accuracy: 0.6250\n",
      "Epoch 157/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0225 - accuracy: 0.4798 - val_loss: 0.9511 - val_accuracy: 0.5625\n",
      "Epoch 158/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 1.0257 - accuracy: 0.4953 - val_loss: 0.9719 - val_accuracy: 0.5500\n",
      "Epoch 159/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 1.0255 - accuracy: 0.4891 - val_loss: 0.9446 - val_accuracy: 0.6125\n",
      "Epoch 160/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0229 - accuracy: 0.4642 - val_loss: 0.9474 - val_accuracy: 0.5625\n",
      "Epoch 161/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0383 - accuracy: 0.4673 - val_loss: 0.9831 - val_accuracy: 0.5625\n",
      "Epoch 162/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0176 - accuracy: 0.5109 - val_loss: 0.9452 - val_accuracy: 0.5750\n",
      "Epoch 163/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0214 - accuracy: 0.4860 - val_loss: 0.9406 - val_accuracy: 0.5750\n",
      "Epoch 164/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0033 - accuracy: 0.5140 - val_loss: 0.9236 - val_accuracy: 0.6500\n",
      "Epoch 165/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0251 - accuracy: 0.4953 - val_loss: 0.9238 - val_accuracy: 0.6250\n",
      "Epoch 166/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0217 - accuracy: 0.5016 - val_loss: 0.9355 - val_accuracy: 0.6250\n",
      "Epoch 167/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0234 - accuracy: 0.4953 - val_loss: 0.9655 - val_accuracy: 0.5500\n",
      "Epoch 168/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0328 - accuracy: 0.4798 - val_loss: 0.9372 - val_accuracy: 0.6250\n",
      "Epoch 169/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 1.0095 - accuracy: 0.5109 - val_loss: 0.9329 - val_accuracy: 0.5875\n",
      "Epoch 170/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0061 - accuracy: 0.5078 - val_loss: 0.9511 - val_accuracy: 0.5625\n",
      "Epoch 171/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0291 - accuracy: 0.4891 - val_loss: 0.9714 - val_accuracy: 0.5375\n",
      "Epoch 172/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0174 - accuracy: 0.4984 - val_loss: 0.9317 - val_accuracy: 0.5875\n",
      "Epoch 173/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 1.0242 - accuracy: 0.4953 - val_loss: 0.9543 - val_accuracy: 0.5750\n",
      "Epoch 174/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0259 - accuracy: 0.4891 - val_loss: 1.0097 - val_accuracy: 0.4875\n",
      "Epoch 175/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0077 - accuracy: 0.5047 - val_loss: 0.9353 - val_accuracy: 0.6500\n",
      "Epoch 176/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0193 - accuracy: 0.4860 - val_loss: 0.9349 - val_accuracy: 0.5750\n",
      "Epoch 177/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 1.0265 - accuracy: 0.4922 - val_loss: 0.9587 - val_accuracy: 0.5500\n",
      "Epoch 178/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 1.0191 - accuracy: 0.4860 - val_loss: 0.9831 - val_accuracy: 0.5375\n",
      "Epoch 179/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 1.0152 - accuracy: 0.5047 - val_loss: 0.9496 - val_accuracy: 0.5750\n",
      "Epoch 180/3000\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 1.0294 - accuracy: 0.5016 - val_loss: 0.9275 - val_accuracy: 0.6500\n",
      "Epoch 181/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0185 - accuracy: 0.4860 - val_loss: 0.9258 - val_accuracy: 0.6375\n",
      "Epoch 182/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0284 - accuracy: 0.4766 - val_loss: 0.9392 - val_accuracy: 0.6000\n",
      "Epoch 183/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0313 - accuracy: 0.4953 - val_loss: 0.9214 - val_accuracy: 0.6125\n",
      "Epoch 184/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0046 - accuracy: 0.4984 - val_loss: 0.9937 - val_accuracy: 0.4875\n",
      "Epoch 185/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0311 - accuracy: 0.4611 - val_loss: 0.9941 - val_accuracy: 0.5000\n",
      "Epoch 186/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0309 - accuracy: 0.4829 - val_loss: 0.9210 - val_accuracy: 0.6500\n",
      "Epoch 187/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 1.0064 - accuracy: 0.5016 - val_loss: 0.9455 - val_accuracy: 0.6000\n",
      "Epoch 188/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0338 - accuracy: 0.4766 - val_loss: 0.9413 - val_accuracy: 0.5875\n",
      "Epoch 189/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0267 - accuracy: 0.4704 - val_loss: 0.9694 - val_accuracy: 0.5375\n",
      "Epoch 190/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0108 - accuracy: 0.5171 - val_loss: 0.9169 - val_accuracy: 0.6500\n",
      "Epoch 191/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 1.0285 - accuracy: 0.4579 - val_loss: 1.0023 - val_accuracy: 0.5000\n",
      "Epoch 192/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0003 - accuracy: 0.5296 - val_loss: 0.9228 - val_accuracy: 0.6250\n",
      "Epoch 193/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0259 - accuracy: 0.4704 - val_loss: 0.9136 - val_accuracy: 0.6125\n",
      "Epoch 194/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 1.0276 - accuracy: 0.4798 - val_loss: 0.9507 - val_accuracy: 0.5750\n",
      "Epoch 195/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0093 - accuracy: 0.4922 - val_loss: 0.9313 - val_accuracy: 0.5750\n",
      "Epoch 196/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 1.0122 - accuracy: 0.4829 - val_loss: 0.9291 - val_accuracy: 0.6125\n",
      "Epoch 197/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0267 - accuracy: 0.4984 - val_loss: 0.9559 - val_accuracy: 0.5875\n",
      "Epoch 198/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0089 - accuracy: 0.4953 - val_loss: 0.9224 - val_accuracy: 0.6000\n",
      "Epoch 199/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0271 - accuracy: 0.4798 - val_loss: 0.9364 - val_accuracy: 0.5750\n",
      "Epoch 200/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0108 - accuracy: 0.5109 - val_loss: 0.9294 - val_accuracy: 0.6375\n",
      "Epoch 201/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.9991 - accuracy: 0.5016 - val_loss: 0.9833 - val_accuracy: 0.5375\n",
      "Epoch 202/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 1.0038 - accuracy: 0.4953 - val_loss: 0.9295 - val_accuracy: 0.6250\n",
      "Epoch 203/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 1.0135 - accuracy: 0.5109 - val_loss: 0.9472 - val_accuracy: 0.6125\n",
      "Epoch 204/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 1.0085 - accuracy: 0.4922 - val_loss: 0.9331 - val_accuracy: 0.5750\n",
      "Epoch 205/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9932 - accuracy: 0.5078 - val_loss: 0.9448 - val_accuracy: 0.5500\n",
      "Epoch 206/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0297 - accuracy: 0.4860 - val_loss: 0.9249 - val_accuracy: 0.6250\n",
      "Epoch 207/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0153 - accuracy: 0.4922 - val_loss: 0.9258 - val_accuracy: 0.6250\n",
      "Epoch 208/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0075 - accuracy: 0.4984 - val_loss: 0.9737 - val_accuracy: 0.5750\n",
      "Epoch 209/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0006 - accuracy: 0.4953 - val_loss: 0.9314 - val_accuracy: 0.5750\n",
      "Epoch 210/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0226 - accuracy: 0.4611 - val_loss: 0.9523 - val_accuracy: 0.6000\n",
      "Epoch 211/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0176 - accuracy: 0.5047 - val_loss: 0.9269 - val_accuracy: 0.6125\n",
      "Epoch 212/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0278 - accuracy: 0.4829 - val_loss: 0.9266 - val_accuracy: 0.5750\n",
      "Epoch 213/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0212 - accuracy: 0.4984 - val_loss: 0.9213 - val_accuracy: 0.6125\n",
      "Epoch 214/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9993 - accuracy: 0.5016 - val_loss: 0.9253 - val_accuracy: 0.5750\n",
      "Epoch 215/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0118 - accuracy: 0.4922 - val_loss: 0.9210 - val_accuracy: 0.6250\n",
      "Epoch 216/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 1.0012 - accuracy: 0.4953 - val_loss: 0.9511 - val_accuracy: 0.5500\n",
      "Epoch 217/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0111 - accuracy: 0.5202 - val_loss: 0.9277 - val_accuracy: 0.5625\n",
      "Epoch 218/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0071 - accuracy: 0.5047 - val_loss: 1.0346 - val_accuracy: 0.4875\n",
      "Epoch 219/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0041 - accuracy: 0.5016 - val_loss: 0.9230 - val_accuracy: 0.5750\n",
      "Epoch 220/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0239 - accuracy: 0.4642 - val_loss: 0.9315 - val_accuracy: 0.6375\n",
      "Epoch 221/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0084 - accuracy: 0.5296 - val_loss: 0.9186 - val_accuracy: 0.5875\n",
      "Epoch 222/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 1.0217 - accuracy: 0.5016 - val_loss: 0.9231 - val_accuracy: 0.5750\n",
      "Epoch 223/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9929 - accuracy: 0.5047 - val_loss: 0.9783 - val_accuracy: 0.5750\n",
      "Epoch 224/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 1.0188 - accuracy: 0.4953 - val_loss: 0.9223 - val_accuracy: 0.5750\n",
      "Epoch 225/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0164 - accuracy: 0.5265 - val_loss: 0.9216 - val_accuracy: 0.5875\n",
      "Epoch 226/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0161 - accuracy: 0.4798 - val_loss: 0.9448 - val_accuracy: 0.6000\n",
      "Epoch 227/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 1.0073 - accuracy: 0.5202 - val_loss: 0.9513 - val_accuracy: 0.5875\n",
      "Epoch 228/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 1.0130 - accuracy: 0.5078 - val_loss: 0.9175 - val_accuracy: 0.5750\n",
      "Epoch 229/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 1.0041 - accuracy: 0.4922 - val_loss: 0.9306 - val_accuracy: 0.6000\n",
      "Epoch 230/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 1.0357 - accuracy: 0.4455 - val_loss: 0.9134 - val_accuracy: 0.6125\n",
      "Epoch 231/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9930 - accuracy: 0.5358 - val_loss: 0.9080 - val_accuracy: 0.6125\n",
      "Epoch 232/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 1.0090 - accuracy: 0.4984 - val_loss: 0.9306 - val_accuracy: 0.6125\n",
      "Epoch 233/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0100 - accuracy: 0.4984 - val_loss: 0.9283 - val_accuracy: 0.6000\n",
      "Epoch 234/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0102 - accuracy: 0.4922 - val_loss: 0.9127 - val_accuracy: 0.6000\n",
      "Epoch 235/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0181 - accuracy: 0.4984 - val_loss: 0.9581 - val_accuracy: 0.5875\n",
      "Epoch 236/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0076 - accuracy: 0.4829 - val_loss: 0.9662 - val_accuracy: 0.5875\n",
      "Epoch 237/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 1.0142 - accuracy: 0.4829 - val_loss: 0.9717 - val_accuracy: 0.5750\n",
      "Epoch 238/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0222 - accuracy: 0.5047 - val_loss: 0.9477 - val_accuracy: 0.6125\n",
      "Epoch 239/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 1.0190 - accuracy: 0.4891 - val_loss: 0.9183 - val_accuracy: 0.5750\n",
      "Epoch 240/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.9953 - accuracy: 0.4860 - val_loss: 0.9132 - val_accuracy: 0.5750\n",
      "Epoch 241/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9913 - accuracy: 0.5202 - val_loss: 0.9651 - val_accuracy: 0.5625\n",
      "Epoch 242/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0148 - accuracy: 0.4922 - val_loss: 0.9055 - val_accuracy: 0.6125\n",
      "Epoch 243/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9978 - accuracy: 0.5016 - val_loss: 1.0111 - val_accuracy: 0.5250\n",
      "Epoch 244/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 1.0355 - accuracy: 0.4860 - val_loss: 0.9080 - val_accuracy: 0.6375\n",
      "Epoch 245/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 1.0027 - accuracy: 0.5265 - val_loss: 0.9375 - val_accuracy: 0.5750\n",
      "Epoch 246/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0017 - accuracy: 0.4984 - val_loss: 0.9324 - val_accuracy: 0.5750\n",
      "Epoch 247/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0053 - accuracy: 0.4891 - val_loss: 0.9141 - val_accuracy: 0.5625\n",
      "Epoch 248/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0059 - accuracy: 0.4860 - val_loss: 0.9853 - val_accuracy: 0.5375\n",
      "Epoch 249/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9826 - accuracy: 0.5140 - val_loss: 0.9073 - val_accuracy: 0.6250\n",
      "Epoch 250/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9885 - accuracy: 0.4953 - val_loss: 0.9081 - val_accuracy: 0.5750\n",
      "Epoch 251/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0034 - accuracy: 0.5047 - val_loss: 0.9375 - val_accuracy: 0.6000\n",
      "Epoch 252/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0051 - accuracy: 0.5016 - val_loss: 0.9065 - val_accuracy: 0.6125\n",
      "Epoch 253/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9939 - accuracy: 0.5078 - val_loss: 0.9047 - val_accuracy: 0.6250\n",
      "Epoch 254/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9919 - accuracy: 0.5078 - val_loss: 0.9334 - val_accuracy: 0.6000\n",
      "Epoch 255/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9956 - accuracy: 0.4891 - val_loss: 0.9020 - val_accuracy: 0.6000\n",
      "Epoch 256/3000\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.9954 - accuracy: 0.5265 - val_loss: 0.9056 - val_accuracy: 0.6375\n",
      "Epoch 257/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 1.0175 - accuracy: 0.5047 - val_loss: 0.9245 - val_accuracy: 0.5625\n",
      "Epoch 258/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 1.0177 - accuracy: 0.4984 - val_loss: 0.9600 - val_accuracy: 0.5750\n",
      "Epoch 259/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9965 - accuracy: 0.4953 - val_loss: 0.9063 - val_accuracy: 0.6375\n",
      "Epoch 260/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0150 - accuracy: 0.5016 - val_loss: 0.9394 - val_accuracy: 0.5625\n",
      "Epoch 261/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0092 - accuracy: 0.4579 - val_loss: 0.9189 - val_accuracy: 0.5625\n",
      "Epoch 262/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0009 - accuracy: 0.5171 - val_loss: 0.9664 - val_accuracy: 0.5625\n",
      "Epoch 263/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0163 - accuracy: 0.4766 - val_loss: 0.9098 - val_accuracy: 0.6000\n",
      "Epoch 264/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 1.0013 - accuracy: 0.5078 - val_loss: 0.9699 - val_accuracy: 0.5250\n",
      "Epoch 265/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0070 - accuracy: 0.5016 - val_loss: 0.9316 - val_accuracy: 0.5875\n",
      "Epoch 266/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0004 - accuracy: 0.5047 - val_loss: 0.9114 - val_accuracy: 0.5625\n",
      "Epoch 267/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0115 - accuracy: 0.4984 - val_loss: 0.9184 - val_accuracy: 0.5625\n",
      "Epoch 268/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9882 - accuracy: 0.5109 - val_loss: 0.9074 - val_accuracy: 0.6250\n",
      "Epoch 269/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0084 - accuracy: 0.4860 - val_loss: 0.9282 - val_accuracy: 0.6125\n",
      "Epoch 270/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 1.0000 - accuracy: 0.4953 - val_loss: 0.9140 - val_accuracy: 0.5625\n",
      "Epoch 271/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0153 - accuracy: 0.4735 - val_loss: 0.9102 - val_accuracy: 0.5625\n",
      "Epoch 272/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9672 - accuracy: 0.5202 - val_loss: 0.9491 - val_accuracy: 0.5750\n",
      "Epoch 273/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9976 - accuracy: 0.5078 - val_loss: 0.9134 - val_accuracy: 0.6000\n",
      "Epoch 274/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 1.0018 - accuracy: 0.4953 - val_loss: 0.9073 - val_accuracy: 0.6125\n",
      "Epoch 275/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0156 - accuracy: 0.4798 - val_loss: 0.9113 - val_accuracy: 0.5625\n",
      "Epoch 276/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 1.0020 - accuracy: 0.5078 - val_loss: 0.9099 - val_accuracy: 0.5750\n",
      "Epoch 277/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0146 - accuracy: 0.5109 - val_loss: 0.9088 - val_accuracy: 0.5625\n",
      "Epoch 278/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.9943 - accuracy: 0.5234 - val_loss: 0.9036 - val_accuracy: 0.5875\n",
      "Epoch 279/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 1.0074 - accuracy: 0.4922 - val_loss: 0.9130 - val_accuracy: 0.6250\n",
      "Epoch 280/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 1.0086 - accuracy: 0.4953 - val_loss: 0.9126 - val_accuracy: 0.6000\n",
      "Epoch 281/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9778 - accuracy: 0.4984 - val_loss: 0.9052 - val_accuracy: 0.5750\n",
      "Epoch 282/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.9948 - accuracy: 0.5016 - val_loss: 0.8988 - val_accuracy: 0.6250\n",
      "Epoch 283/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0344 - accuracy: 0.4829 - val_loss: 0.9126 - val_accuracy: 0.5625\n",
      "Epoch 284/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9893 - accuracy: 0.5047 - val_loss: 0.8985 - val_accuracy: 0.5875\n",
      "Epoch 285/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0093 - accuracy: 0.4860 - val_loss: 0.9186 - val_accuracy: 0.5750\n",
      "Epoch 286/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9991 - accuracy: 0.4891 - val_loss: 1.0076 - val_accuracy: 0.5375\n",
      "Epoch 287/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0022 - accuracy: 0.4766 - val_loss: 0.9851 - val_accuracy: 0.5375\n",
      "Epoch 288/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0043 - accuracy: 0.5016 - val_loss: 0.9529 - val_accuracy: 0.5500\n",
      "Epoch 289/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9988 - accuracy: 0.4798 - val_loss: 0.9115 - val_accuracy: 0.5625\n",
      "Epoch 290/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 1.0082 - accuracy: 0.5016 - val_loss: 0.9276 - val_accuracy: 0.5750\n",
      "Epoch 291/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9840 - accuracy: 0.5078 - val_loss: 0.9062 - val_accuracy: 0.5250\n",
      "Epoch 292/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 1.0010 - accuracy: 0.5078 - val_loss: 0.8974 - val_accuracy: 0.5625\n",
      "Epoch 293/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9986 - accuracy: 0.5140 - val_loss: 0.9047 - val_accuracy: 0.5750\n",
      "Epoch 294/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9923 - accuracy: 0.5483 - val_loss: 0.9508 - val_accuracy: 0.4500\n",
      "Epoch 295/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0028 - accuracy: 0.4984 - val_loss: 0.9100 - val_accuracy: 0.5250\n",
      "Epoch 296/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0028 - accuracy: 0.5140 - val_loss: 0.9222 - val_accuracy: 0.5125\n",
      "Epoch 297/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 1.0255 - accuracy: 0.4611 - val_loss: 0.9232 - val_accuracy: 0.5750\n",
      "Epoch 298/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9996 - accuracy: 0.5140 - val_loss: 0.9734 - val_accuracy: 0.5000\n",
      "Epoch 299/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0016 - accuracy: 0.5202 - val_loss: 0.9363 - val_accuracy: 0.4875\n",
      "Epoch 300/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9893 - accuracy: 0.5078 - val_loss: 0.9206 - val_accuracy: 0.5250\n",
      "Epoch 301/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0089 - accuracy: 0.5140 - val_loss: 0.9061 - val_accuracy: 0.5125\n",
      "Epoch 302/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9802 - accuracy: 0.5265 - val_loss: 0.9265 - val_accuracy: 0.5375\n",
      "Epoch 303/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9815 - accuracy: 0.5109 - val_loss: 0.9022 - val_accuracy: 0.5125\n",
      "Epoch 304/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.9932 - accuracy: 0.5047 - val_loss: 0.9292 - val_accuracy: 0.4875\n",
      "Epoch 305/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 1.0052 - accuracy: 0.5234 - val_loss: 0.9125 - val_accuracy: 0.5125\n",
      "Epoch 306/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.9648 - accuracy: 0.5483 - val_loss: 0.9301 - val_accuracy: 0.4875\n",
      "Epoch 307/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9856 - accuracy: 0.5047 - val_loss: 0.9270 - val_accuracy: 0.4875\n",
      "Epoch 308/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 1.0116 - accuracy: 0.4953 - val_loss: 0.9167 - val_accuracy: 0.5125\n",
      "Epoch 309/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9728 - accuracy: 0.5202 - val_loss: 0.9039 - val_accuracy: 0.5625\n",
      "Epoch 310/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0050 - accuracy: 0.5358 - val_loss: 0.9218 - val_accuracy: 0.5000\n",
      "Epoch 311/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0082 - accuracy: 0.5016 - val_loss: 0.9738 - val_accuracy: 0.4625\n",
      "Epoch 312/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9789 - accuracy: 0.5389 - val_loss: 0.9239 - val_accuracy: 0.5000\n",
      "Epoch 313/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9995 - accuracy: 0.5421 - val_loss: 0.9080 - val_accuracy: 0.5375\n",
      "Epoch 314/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9819 - accuracy: 0.5452 - val_loss: 0.9158 - val_accuracy: 0.5250\n",
      "Epoch 315/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9935 - accuracy: 0.5358 - val_loss: 0.9136 - val_accuracy: 0.5125\n",
      "Epoch 316/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9933 - accuracy: 0.5421 - val_loss: 0.9098 - val_accuracy: 0.5000\n",
      "Epoch 317/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9870 - accuracy: 0.5296 - val_loss: 0.9168 - val_accuracy: 0.5250\n",
      "Epoch 318/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9908 - accuracy: 0.5016 - val_loss: 0.9049 - val_accuracy: 0.5250\n",
      "Epoch 319/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9954 - accuracy: 0.5109 - val_loss: 0.8985 - val_accuracy: 0.5375\n",
      "Epoch 320/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0088 - accuracy: 0.5047 - val_loss: 0.9403 - val_accuracy: 0.4875\n",
      "Epoch 321/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.0118 - accuracy: 0.5234 - val_loss: 0.9263 - val_accuracy: 0.5250\n",
      "Epoch 322/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9839 - accuracy: 0.5202 - val_loss: 0.9062 - val_accuracy: 0.5375\n",
      "Epoch 323/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9825 - accuracy: 0.5234 - val_loss: 0.9010 - val_accuracy: 0.5375\n",
      "Epoch 324/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0104 - accuracy: 0.4860 - val_loss: 0.9056 - val_accuracy: 0.5000\n",
      "Epoch 325/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9751 - accuracy: 0.5389 - val_loss: 0.9438 - val_accuracy: 0.5125\n",
      "Epoch 326/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9744 - accuracy: 0.5514 - val_loss: 0.9172 - val_accuracy: 0.5125\n",
      "Epoch 327/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9813 - accuracy: 0.5265 - val_loss: 0.9025 - val_accuracy: 0.5375\n",
      "Epoch 328/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9896 - accuracy: 0.5327 - val_loss: 0.9165 - val_accuracy: 0.5125\n",
      "Epoch 329/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 1.0108 - accuracy: 0.5140 - val_loss: 0.9241 - val_accuracy: 0.5125\n",
      "Epoch 330/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 1.0085 - accuracy: 0.5140 - val_loss: 0.9129 - val_accuracy: 0.5000\n",
      "Epoch 331/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9848 - accuracy: 0.5171 - val_loss: 0.9050 - val_accuracy: 0.5375\n",
      "Epoch 332/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9729 - accuracy: 0.5327 - val_loss: 0.9453 - val_accuracy: 0.4625\n",
      "Epoch 333/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0065 - accuracy: 0.5140 - val_loss: 0.9035 - val_accuracy: 0.5375\n",
      "Epoch 334/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9934 - accuracy: 0.4953 - val_loss: 0.9012 - val_accuracy: 0.5125\n",
      "Epoch 335/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9834 - accuracy: 0.5296 - val_loss: 0.9007 - val_accuracy: 0.5375\n",
      "Epoch 336/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9959 - accuracy: 0.5047 - val_loss: 0.9086 - val_accuracy: 0.5000\n",
      "Epoch 337/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9865 - accuracy: 0.5265 - val_loss: 0.9184 - val_accuracy: 0.5375\n",
      "Epoch 338/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9783 - accuracy: 0.5514 - val_loss: 0.9120 - val_accuracy: 0.5000\n",
      "Epoch 339/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9984 - accuracy: 0.5140 - val_loss: 0.9322 - val_accuracy: 0.5375\n",
      "Epoch 340/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9902 - accuracy: 0.5327 - val_loss: 0.9805 - val_accuracy: 0.5000\n",
      "Epoch 341/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9880 - accuracy: 0.5358 - val_loss: 0.9518 - val_accuracy: 0.5250\n",
      "Epoch 342/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9605 - accuracy: 0.5452 - val_loss: 0.9040 - val_accuracy: 0.5000\n",
      "Epoch 343/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.9948 - accuracy: 0.5140 - val_loss: 0.9296 - val_accuracy: 0.5250\n",
      "Epoch 344/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9774 - accuracy: 0.5514 - val_loss: 0.8969 - val_accuracy: 0.5375\n",
      "Epoch 345/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9832 - accuracy: 0.5296 - val_loss: 0.9018 - val_accuracy: 0.5250\n",
      "Epoch 346/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0051 - accuracy: 0.5109 - val_loss: 0.9047 - val_accuracy: 0.5000\n",
      "Epoch 347/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.9820 - accuracy: 0.5171 - val_loss: 0.9004 - val_accuracy: 0.5250\n",
      "Epoch 348/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9635 - accuracy: 0.5514 - val_loss: 0.9179 - val_accuracy: 0.5250\n",
      "Epoch 349/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 1.0007 - accuracy: 0.5016 - val_loss: 0.9734 - val_accuracy: 0.4500\n",
      "Epoch 350/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 1.0129 - accuracy: 0.4829 - val_loss: 0.8939 - val_accuracy: 0.5375\n",
      "Epoch 351/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 1.0124 - accuracy: 0.5078 - val_loss: 0.9136 - val_accuracy: 0.5125\n",
      "Epoch 352/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9852 - accuracy: 0.5265 - val_loss: 0.9733 - val_accuracy: 0.4500\n",
      "Epoch 353/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.0017 - accuracy: 0.5047 - val_loss: 0.9016 - val_accuracy: 0.5000\n",
      "Epoch 354/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9882 - accuracy: 0.4891 - val_loss: 0.9031 - val_accuracy: 0.5250\n",
      "Epoch 355/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9940 - accuracy: 0.5234 - val_loss: 0.9323 - val_accuracy: 0.5250\n",
      "Epoch 356/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9975 - accuracy: 0.5047 - val_loss: 0.9065 - val_accuracy: 0.5000\n",
      "Epoch 357/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 1.0179 - accuracy: 0.5171 - val_loss: 0.9086 - val_accuracy: 0.5125\n",
      "Epoch 358/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9865 - accuracy: 0.5202 - val_loss: 0.9011 - val_accuracy: 0.5250\n",
      "Epoch 359/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9954 - accuracy: 0.5202 - val_loss: 0.9206 - val_accuracy: 0.5375\n",
      "Epoch 360/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9895 - accuracy: 0.5327 - val_loss: 0.9247 - val_accuracy: 0.5250\n",
      "Epoch 361/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9997 - accuracy: 0.5047 - val_loss: 0.9154 - val_accuracy: 0.5125\n",
      "Epoch 362/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9810 - accuracy: 0.5202 - val_loss: 0.9183 - val_accuracy: 0.5125\n",
      "Epoch 363/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0139 - accuracy: 0.5265 - val_loss: 0.9315 - val_accuracy: 0.5250\n",
      "Epoch 364/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9858 - accuracy: 0.5140 - val_loss: 0.9061 - val_accuracy: 0.5375\n",
      "Epoch 365/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9788 - accuracy: 0.5078 - val_loss: 0.9047 - val_accuracy: 0.5375\n",
      "Epoch 366/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9760 - accuracy: 0.5327 - val_loss: 0.9451 - val_accuracy: 0.4625\n",
      "Epoch 367/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9800 - accuracy: 0.4953 - val_loss: 0.9062 - val_accuracy: 0.5125\n",
      "Epoch 368/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9858 - accuracy: 0.5109 - val_loss: 0.9055 - val_accuracy: 0.5375\n",
      "Epoch 369/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9802 - accuracy: 0.5389 - val_loss: 0.8976 - val_accuracy: 0.5375\n",
      "Epoch 370/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9990 - accuracy: 0.5296 - val_loss: 0.9135 - val_accuracy: 0.5375\n",
      "Epoch 371/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9892 - accuracy: 0.5109 - val_loss: 0.9054 - val_accuracy: 0.5000\n",
      "Epoch 372/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9820 - accuracy: 0.5358 - val_loss: 0.9131 - val_accuracy: 0.5000\n",
      "Epoch 373/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.9925 - accuracy: 0.5140 - val_loss: 0.9035 - val_accuracy: 0.5000\n",
      "Epoch 374/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9816 - accuracy: 0.5265 - val_loss: 0.9140 - val_accuracy: 0.5125\n",
      "Epoch 375/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9975 - accuracy: 0.5109 - val_loss: 0.8951 - val_accuracy: 0.5375\n",
      "Epoch 376/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 1.0041 - accuracy: 0.5078 - val_loss: 0.9138 - val_accuracy: 0.5375\n",
      "Epoch 377/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9892 - accuracy: 0.5171 - val_loss: 0.8856 - val_accuracy: 0.5000\n",
      "Epoch 378/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9820 - accuracy: 0.5171 - val_loss: 0.8946 - val_accuracy: 0.5375\n",
      "Epoch 379/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9664 - accuracy: 0.5296 - val_loss: 0.9339 - val_accuracy: 0.5250\n",
      "Epoch 380/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9750 - accuracy: 0.5171 - val_loss: 0.8905 - val_accuracy: 0.5125\n",
      "Epoch 381/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9712 - accuracy: 0.5171 - val_loss: 0.9062 - val_accuracy: 0.5250\n",
      "Epoch 382/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9824 - accuracy: 0.5327 - val_loss: 0.8903 - val_accuracy: 0.5000\n",
      "Epoch 383/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9840 - accuracy: 0.5296 - val_loss: 0.9566 - val_accuracy: 0.5250\n",
      "Epoch 384/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0035 - accuracy: 0.5047 - val_loss: 0.8974 - val_accuracy: 0.5000\n",
      "Epoch 385/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.9793 - accuracy: 0.5234 - val_loss: 0.8973 - val_accuracy: 0.5000\n",
      "Epoch 386/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9816 - accuracy: 0.5234 - val_loss: 0.9015 - val_accuracy: 0.5000\n",
      "Epoch 387/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9712 - accuracy: 0.5389 - val_loss: 0.9061 - val_accuracy: 0.5000\n",
      "Epoch 388/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9789 - accuracy: 0.5452 - val_loss: 0.9015 - val_accuracy: 0.5375\n",
      "Epoch 389/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9667 - accuracy: 0.5234 - val_loss: 1.0100 - val_accuracy: 0.4750\n",
      "Epoch 390/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9837 - accuracy: 0.5047 - val_loss: 0.8941 - val_accuracy: 0.5375\n",
      "Epoch 391/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9608 - accuracy: 0.5607 - val_loss: 0.8846 - val_accuracy: 0.5125\n",
      "Epoch 392/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9775 - accuracy: 0.5421 - val_loss: 0.9313 - val_accuracy: 0.5250\n",
      "Epoch 393/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0043 - accuracy: 0.5358 - val_loss: 0.9048 - val_accuracy: 0.5000\n",
      "Epoch 394/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9838 - accuracy: 0.5234 - val_loss: 0.9077 - val_accuracy: 0.5000\n",
      "Epoch 395/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9743 - accuracy: 0.5327 - val_loss: 0.9175 - val_accuracy: 0.5375\n",
      "Epoch 396/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9647 - accuracy: 0.5452 - val_loss: 0.9109 - val_accuracy: 0.5000\n",
      "Epoch 397/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.9675 - accuracy: 0.5483 - val_loss: 0.8990 - val_accuracy: 0.5500\n",
      "Epoch 398/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9858 - accuracy: 0.5171 - val_loss: 0.8931 - val_accuracy: 0.5000\n",
      "Epoch 399/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9669 - accuracy: 0.5389 - val_loss: 0.9857 - val_accuracy: 0.4500\n",
      "Epoch 400/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9753 - accuracy: 0.5234 - val_loss: 0.9395 - val_accuracy: 0.5125\n",
      "Epoch 401/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9903 - accuracy: 0.4829 - val_loss: 0.8969 - val_accuracy: 0.5000\n",
      "Epoch 402/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9796 - accuracy: 0.5296 - val_loss: 0.9437 - val_accuracy: 0.5000\n",
      "Epoch 403/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9875 - accuracy: 0.5047 - val_loss: 0.9125 - val_accuracy: 0.5125\n",
      "Epoch 404/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.9782 - accuracy: 0.5389 - val_loss: 0.9048 - val_accuracy: 0.5375\n",
      "Epoch 405/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 1.0099 - accuracy: 0.5109 - val_loss: 0.9050 - val_accuracy: 0.5375\n",
      "Epoch 406/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9619 - accuracy: 0.5265 - val_loss: 0.9153 - val_accuracy: 0.5125\n",
      "Epoch 407/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.9936 - accuracy: 0.5047 - val_loss: 0.8961 - val_accuracy: 0.5000\n",
      "Epoch 408/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9930 - accuracy: 0.5234 - val_loss: 0.8940 - val_accuracy: 0.5000\n",
      "Epoch 409/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9843 - accuracy: 0.5265 - val_loss: 0.8937 - val_accuracy: 0.5000\n",
      "Epoch 410/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 1.0072 - accuracy: 0.5234 - val_loss: 0.8948 - val_accuracy: 0.5375\n",
      "Epoch 411/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9662 - accuracy: 0.5296 - val_loss: 0.9162 - val_accuracy: 0.5375\n",
      "Epoch 412/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9808 - accuracy: 0.5202 - val_loss: 0.8918 - val_accuracy: 0.5125\n",
      "Epoch 413/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9606 - accuracy: 0.5389 - val_loss: 0.9458 - val_accuracy: 0.4625\n",
      "Epoch 414/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0081 - accuracy: 0.5047 - val_loss: 0.8924 - val_accuracy: 0.5500\n",
      "Epoch 415/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.9959 - accuracy: 0.5202 - val_loss: 0.9399 - val_accuracy: 0.5125\n",
      "Epoch 416/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9771 - accuracy: 0.5514 - val_loss: 0.8934 - val_accuracy: 0.5500\n",
      "Epoch 417/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9594 - accuracy: 0.5483 - val_loss: 0.9253 - val_accuracy: 0.5125\n",
      "Epoch 418/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9714 - accuracy: 0.5358 - val_loss: 0.9039 - val_accuracy: 0.5125\n",
      "Epoch 419/3000\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.9896 - accuracy: 0.5078 - val_loss: 0.8958 - val_accuracy: 0.5375\n",
      "Epoch 420/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9809 - accuracy: 0.5234 - val_loss: 0.8930 - val_accuracy: 0.5500\n",
      "Epoch 421/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.9746 - accuracy: 0.5545 - val_loss: 0.9097 - val_accuracy: 0.5125\n",
      "Epoch 422/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9845 - accuracy: 0.5358 - val_loss: 0.9100 - val_accuracy: 0.5375\n",
      "Epoch 423/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9755 - accuracy: 0.5171 - val_loss: 0.9072 - val_accuracy: 0.5500\n",
      "Epoch 424/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9974 - accuracy: 0.5234 - val_loss: 0.8899 - val_accuracy: 0.5250\n",
      "Epoch 425/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.0130 - accuracy: 0.4798 - val_loss: 0.8904 - val_accuracy: 0.5375\n",
      "Epoch 426/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9617 - accuracy: 0.5327 - val_loss: 0.8879 - val_accuracy: 0.5375\n",
      "Epoch 427/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 1.0174 - accuracy: 0.5109 - val_loss: 0.8992 - val_accuracy: 0.5000\n",
      "Epoch 428/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.9871 - accuracy: 0.5047 - val_loss: 0.8961 - val_accuracy: 0.5500\n",
      "Epoch 429/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9878 - accuracy: 0.5234 - val_loss: 0.9358 - val_accuracy: 0.5125\n",
      "Epoch 430/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.9926 - accuracy: 0.5078 - val_loss: 0.9381 - val_accuracy: 0.4750\n",
      "Epoch 431/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9838 - accuracy: 0.5358 - val_loss: 0.8881 - val_accuracy: 0.5375\n",
      "Epoch 432/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9511 - accuracy: 0.5358 - val_loss: 0.9087 - val_accuracy: 0.5000\n",
      "Epoch 433/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9740 - accuracy: 0.5296 - val_loss: 0.9007 - val_accuracy: 0.5250\n",
      "Epoch 434/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9903 - accuracy: 0.5358 - val_loss: 0.8864 - val_accuracy: 0.5000\n",
      "Epoch 435/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9754 - accuracy: 0.5234 - val_loss: 0.8806 - val_accuracy: 0.5375\n",
      "Epoch 436/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9765 - accuracy: 0.5202 - val_loss: 0.8818 - val_accuracy: 0.5375\n",
      "Epoch 437/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9797 - accuracy: 0.5265 - val_loss: 0.8883 - val_accuracy: 0.5125\n",
      "Epoch 438/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.9716 - accuracy: 0.5265 - val_loss: 0.8934 - val_accuracy: 0.5125\n",
      "Epoch 439/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.9914 - accuracy: 0.5327 - val_loss: 0.8902 - val_accuracy: 0.5125\n",
      "Epoch 440/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9749 - accuracy: 0.5234 - val_loss: 0.8884 - val_accuracy: 0.5000\n",
      "Epoch 441/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9857 - accuracy: 0.5296 - val_loss: 0.8924 - val_accuracy: 0.5375\n",
      "Epoch 442/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9534 - accuracy: 0.5452 - val_loss: 0.8821 - val_accuracy: 0.5125\n",
      "Epoch 443/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9586 - accuracy: 0.5358 - val_loss: 0.9174 - val_accuracy: 0.5000\n",
      "Epoch 444/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9810 - accuracy: 0.5265 - val_loss: 0.9904 - val_accuracy: 0.4500\n",
      "Epoch 445/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.9790 - accuracy: 0.5265 - val_loss: 0.8815 - val_accuracy: 0.5375\n",
      "Epoch 446/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9693 - accuracy: 0.5358 - val_loss: 0.9288 - val_accuracy: 0.5000\n",
      "Epoch 447/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.9676 - accuracy: 0.5452 - val_loss: 0.9281 - val_accuracy: 0.5125\n",
      "Epoch 448/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9598 - accuracy: 0.5421 - val_loss: 0.8747 - val_accuracy: 0.5375\n",
      "Epoch 449/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9990 - accuracy: 0.5171 - val_loss: 0.9107 - val_accuracy: 0.5250\n",
      "Epoch 450/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9695 - accuracy: 0.5234 - val_loss: 0.9022 - val_accuracy: 0.5125\n",
      "Epoch 451/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9453 - accuracy: 0.5483 - val_loss: 0.8859 - val_accuracy: 0.5500\n",
      "Epoch 452/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9793 - accuracy: 0.5452 - val_loss: 0.8891 - val_accuracy: 0.5375\n",
      "Epoch 453/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9730 - accuracy: 0.5296 - val_loss: 0.9151 - val_accuracy: 0.5125\n",
      "Epoch 454/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 1.0146 - accuracy: 0.4766 - val_loss: 0.8968 - val_accuracy: 0.5125\n",
      "Epoch 455/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9705 - accuracy: 0.5327 - val_loss: 0.8955 - val_accuracy: 0.5250\n",
      "Epoch 456/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.9915 - accuracy: 0.5421 - val_loss: 0.9035 - val_accuracy: 0.5000\n",
      "Epoch 457/3000\n",
      "8/8 [==============================] - 3s 427ms/step - loss: 0.9617 - accuracy: 0.5234 - val_loss: 0.9187 - val_accuracy: 0.5375\n",
      "Epoch 458/3000\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.9628 - accuracy: 0.5389 - val_loss: 0.9358 - val_accuracy: 0.5375\n",
      "Epoch 459/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.9790 - accuracy: 0.5358 - val_loss: 0.9105 - val_accuracy: 0.5250\n",
      "Epoch 460/3000\n",
      "8/8 [==============================] - 2s 216ms/step - loss: 0.9623 - accuracy: 0.5607 - val_loss: 0.8970 - val_accuracy: 0.5250\n",
      "Epoch 461/3000\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.9796 - accuracy: 0.5483 - val_loss: 0.9100 - val_accuracy: 0.5125\n",
      "Epoch 462/3000\n",
      "8/8 [==============================] - 2s 271ms/step - loss: 0.9959 - accuracy: 0.5140 - val_loss: 0.9170 - val_accuracy: 0.5375\n",
      "Epoch 463/3000\n",
      "8/8 [==============================] - 2s 240ms/step - loss: 0.9746 - accuracy: 0.5421 - val_loss: 0.9000 - val_accuracy: 0.5250\n",
      "Epoch 464/3000\n",
      "8/8 [==============================] - 2s 246ms/step - loss: 0.9703 - accuracy: 0.5140 - val_loss: 0.9085 - val_accuracy: 0.5250\n",
      "Epoch 465/3000\n",
      "8/8 [==============================] - 2s 275ms/step - loss: 0.9915 - accuracy: 0.5296 - val_loss: 0.8988 - val_accuracy: 0.5125\n",
      "Epoch 466/3000\n",
      "8/8 [==============================] - 2s 239ms/step - loss: 0.9829 - accuracy: 0.5327 - val_loss: 0.8977 - val_accuracy: 0.5375\n",
      "Epoch 467/3000\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 0.9858 - accuracy: 0.5234 - val_loss: 0.8944 - val_accuracy: 0.5250\n",
      "Epoch 468/3000\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.9866 - accuracy: 0.5358 - val_loss: 0.8977 - val_accuracy: 0.5000\n",
      "Epoch 469/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9700 - accuracy: 0.5171 - val_loss: 0.9014 - val_accuracy: 0.5125\n",
      "Epoch 470/3000\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 0.9533 - accuracy: 0.5358 - val_loss: 0.9488 - val_accuracy: 0.5250\n",
      "Epoch 471/3000\n",
      "8/8 [==============================] - 2s 269ms/step - loss: 0.9826 - accuracy: 0.5140 - val_loss: 0.9009 - val_accuracy: 0.5250\n",
      "Epoch 472/3000\n",
      "8/8 [==============================] - 2s 249ms/step - loss: 0.9623 - accuracy: 0.5514 - val_loss: 0.9149 - val_accuracy: 0.5000\n",
      "Epoch 473/3000\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.9861 - accuracy: 0.5514 - val_loss: 0.8879 - val_accuracy: 0.5250\n",
      "Epoch 474/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9874 - accuracy: 0.5047 - val_loss: 0.9316 - val_accuracy: 0.4500\n",
      "Epoch 475/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9751 - accuracy: 0.5202 - val_loss: 0.9033 - val_accuracy: 0.5250\n",
      "Epoch 476/3000\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.9705 - accuracy: 0.5389 - val_loss: 0.9201 - val_accuracy: 0.5000\n",
      "Epoch 477/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9937 - accuracy: 0.4922 - val_loss: 0.8926 - val_accuracy: 0.5125\n",
      "Epoch 478/3000\n",
      "8/8 [==============================] - 2s 247ms/step - loss: 0.9894 - accuracy: 0.5109 - val_loss: 0.8982 - val_accuracy: 0.5250\n",
      "Epoch 479/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9600 - accuracy: 0.5171 - val_loss: 0.9085 - val_accuracy: 0.5250\n",
      "Epoch 480/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9774 - accuracy: 0.5171 - val_loss: 0.9031 - val_accuracy: 0.5125\n",
      "Epoch 481/3000\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.9754 - accuracy: 0.5016 - val_loss: 0.8882 - val_accuracy: 0.5000\n",
      "Epoch 482/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9745 - accuracy: 0.5171 - val_loss: 0.8821 - val_accuracy: 0.5000\n",
      "Epoch 483/3000\n",
      "8/8 [==============================] - 2s 245ms/step - loss: 0.9584 - accuracy: 0.5514 - val_loss: 0.9602 - val_accuracy: 0.4500\n",
      "Epoch 484/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9629 - accuracy: 0.5483 - val_loss: 0.9464 - val_accuracy: 0.4625\n",
      "Epoch 485/3000\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.9832 - accuracy: 0.5171 - val_loss: 0.8848 - val_accuracy: 0.5250\n",
      "Epoch 486/3000\n",
      "8/8 [==============================] - 2s 250ms/step - loss: 0.9815 - accuracy: 0.5327 - val_loss: 0.8880 - val_accuracy: 0.5375\n",
      "Epoch 487/3000\n",
      "8/8 [==============================] - 2s 238ms/step - loss: 0.9765 - accuracy: 0.5514 - val_loss: 0.9289 - val_accuracy: 0.4750\n",
      "Epoch 488/3000\n",
      "8/8 [==============================] - 2s 257ms/step - loss: 0.9792 - accuracy: 0.5202 - val_loss: 0.8924 - val_accuracy: 0.5250\n",
      "Epoch 489/3000\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.9765 - accuracy: 0.5265 - val_loss: 0.8826 - val_accuracy: 0.5250\n",
      "Epoch 490/3000\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.9847 - accuracy: 0.5171 - val_loss: 0.8910 - val_accuracy: 0.5250\n",
      "Epoch 491/3000\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.9620 - accuracy: 0.5483 - val_loss: 0.8883 - val_accuracy: 0.5125\n",
      "Epoch 492/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9589 - accuracy: 0.5265 - val_loss: 0.9059 - val_accuracy: 0.5375\n",
      "Epoch 493/3000\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 0.9688 - accuracy: 0.5607 - val_loss: 0.9285 - val_accuracy: 0.4625\n",
      "Epoch 494/3000\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 0.9561 - accuracy: 0.5545 - val_loss: 0.8741 - val_accuracy: 0.5250\n",
      "Epoch 495/3000\n",
      "8/8 [==============================] - 2s 252ms/step - loss: 0.9864 - accuracy: 0.5202 - val_loss: 0.9263 - val_accuracy: 0.5125\n",
      "Epoch 496/3000\n",
      "8/8 [==============================] - 2s 242ms/step - loss: 0.9501 - accuracy: 0.5545 - val_loss: 0.9064 - val_accuracy: 0.5250\n",
      "Epoch 497/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9523 - accuracy: 0.5639 - val_loss: 0.8855 - val_accuracy: 0.5250\n",
      "Epoch 498/3000\n",
      "8/8 [==============================] - 2s 245ms/step - loss: 0.9918 - accuracy: 0.5078 - val_loss: 0.8860 - val_accuracy: 0.5250\n",
      "Epoch 499/3000\n",
      "8/8 [==============================] - 2s 246ms/step - loss: 0.9939 - accuracy: 0.5202 - val_loss: 0.8911 - val_accuracy: 0.5250\n",
      "Epoch 500/3000\n",
      "8/8 [==============================] - 2s 263ms/step - loss: 0.9878 - accuracy: 0.5265 - val_loss: 0.8957 - val_accuracy: 0.5375\n",
      "Epoch 501/3000\n",
      "8/8 [==============================] - 2s 249ms/step - loss: 0.9567 - accuracy: 0.5576 - val_loss: 0.8897 - val_accuracy: 0.5375\n",
      "Epoch 502/3000\n",
      "8/8 [==============================] - 2s 244ms/step - loss: 0.9741 - accuracy: 0.5296 - val_loss: 0.9099 - val_accuracy: 0.5250\n",
      "Epoch 503/3000\n",
      "8/8 [==============================] - 2s 239ms/step - loss: 0.9807 - accuracy: 0.5327 - val_loss: 0.8845 - val_accuracy: 0.5250\n",
      "Epoch 504/3000\n",
      "8/8 [==============================] - 2s 238ms/step - loss: 0.9479 - accuracy: 0.5452 - val_loss: 0.8969 - val_accuracy: 0.5125\n",
      "Epoch 505/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9609 - accuracy: 0.5265 - val_loss: 0.9423 - val_accuracy: 0.4500\n",
      "Epoch 506/3000\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.9647 - accuracy: 0.5296 - val_loss: 0.8768 - val_accuracy: 0.5375\n",
      "Epoch 507/3000\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 1.0138 - accuracy: 0.4891 - val_loss: 0.8800 - val_accuracy: 0.5375\n",
      "Epoch 508/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9696 - accuracy: 0.5358 - val_loss: 0.8774 - val_accuracy: 0.5375\n",
      "Epoch 509/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9971 - accuracy: 0.5140 - val_loss: 0.8907 - val_accuracy: 0.5250\n",
      "Epoch 510/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9635 - accuracy: 0.5483 - val_loss: 0.9051 - val_accuracy: 0.5375\n",
      "Epoch 511/3000\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.9537 - accuracy: 0.5514 - val_loss: 0.8903 - val_accuracy: 0.5375\n",
      "Epoch 512/3000\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.9629 - accuracy: 0.5327 - val_loss: 0.9129 - val_accuracy: 0.4875\n",
      "Epoch 513/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9545 - accuracy: 0.5545 - val_loss: 0.9017 - val_accuracy: 0.4875\n",
      "Epoch 514/3000\n",
      "8/8 [==============================] - 2s 252ms/step - loss: 0.9779 - accuracy: 0.5421 - val_loss: 0.9133 - val_accuracy: 0.4625\n",
      "Epoch 515/3000\n",
      "8/8 [==============================] - 2s 248ms/step - loss: 0.9998 - accuracy: 0.5265 - val_loss: 0.8821 - val_accuracy: 0.5250\n",
      "Epoch 516/3000\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.9517 - accuracy: 0.5389 - val_loss: 0.8823 - val_accuracy: 0.5375\n",
      "Epoch 517/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9660 - accuracy: 0.5327 - val_loss: 0.8869 - val_accuracy: 0.5375\n",
      "Epoch 518/3000\n",
      "8/8 [==============================] - 2s 263ms/step - loss: 0.9668 - accuracy: 0.5140 - val_loss: 0.8876 - val_accuracy: 0.5250\n",
      "Epoch 519/3000\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 1.0068 - accuracy: 0.5171 - val_loss: 0.8826 - val_accuracy: 0.5375\n",
      "Epoch 520/3000\n",
      "8/8 [==============================] - 2s 238ms/step - loss: 0.9581 - accuracy: 0.5389 - val_loss: 0.8747 - val_accuracy: 0.5250\n",
      "Epoch 521/3000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.9369 - accuracy: 0.5483 - val_loss: 0.8784 - val_accuracy: 0.5125\n",
      "Epoch 522/3000\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 0.9630 - accuracy: 0.5296 - val_loss: 0.8808 - val_accuracy: 0.5250\n",
      "Epoch 523/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9866 - accuracy: 0.5016 - val_loss: 0.8703 - val_accuracy: 0.5250\n",
      "Epoch 524/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9648 - accuracy: 0.5327 - val_loss: 0.8813 - val_accuracy: 0.5375\n",
      "Epoch 525/3000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 0.9865 - accuracy: 0.5202 - val_loss: 0.8668 - val_accuracy: 0.5250\n",
      "Epoch 526/3000\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.9788 - accuracy: 0.5234 - val_loss: 0.9754 - val_accuracy: 0.4625\n",
      "Epoch 527/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9591 - accuracy: 0.5421 - val_loss: 0.9500 - val_accuracy: 0.4625\n",
      "Epoch 528/3000\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.9966 - accuracy: 0.5047 - val_loss: 0.8739 - val_accuracy: 0.5250\n",
      "Epoch 529/3000\n",
      "8/8 [==============================] - 2s 237ms/step - loss: 0.9525 - accuracy: 0.5421 - val_loss: 0.9469 - val_accuracy: 0.5375\n",
      "Epoch 530/3000\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.9827 - accuracy: 0.5514 - val_loss: 0.8753 - val_accuracy: 0.5375\n",
      "Epoch 531/3000\n",
      "8/8 [==============================] - 2s 259ms/step - loss: 0.9948 - accuracy: 0.4953 - val_loss: 0.8771 - val_accuracy: 0.5250\n",
      "Epoch 532/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9797 - accuracy: 0.5265 - val_loss: 0.8757 - val_accuracy: 0.5375\n",
      "Epoch 533/3000\n",
      "8/8 [==============================] - 2s 249ms/step - loss: 0.9865 - accuracy: 0.5452 - val_loss: 0.8857 - val_accuracy: 0.5250\n",
      "Epoch 534/3000\n",
      "8/8 [==============================] - 2s 240ms/step - loss: 0.9467 - accuracy: 0.5296 - val_loss: 0.9292 - val_accuracy: 0.4500\n",
      "Epoch 535/3000\n",
      "8/8 [==============================] - 2s 273ms/step - loss: 0.9588 - accuracy: 0.5545 - val_loss: 0.8741 - val_accuracy: 0.5500\n",
      "Epoch 536/3000\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 0.9625 - accuracy: 0.5483 - val_loss: 0.8828 - val_accuracy: 0.5375\n",
      "Epoch 537/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9483 - accuracy: 0.5296 - val_loss: 0.8891 - val_accuracy: 0.5500\n",
      "Epoch 538/3000\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.9697 - accuracy: 0.5452 - val_loss: 0.8807 - val_accuracy: 0.5375\n",
      "Epoch 539/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9649 - accuracy: 0.5296 - val_loss: 0.8749 - val_accuracy: 0.5375\n",
      "Epoch 540/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9529 - accuracy: 0.5265 - val_loss: 0.8732 - val_accuracy: 0.5250\n",
      "Epoch 541/3000\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.9482 - accuracy: 0.5576 - val_loss: 0.8701 - val_accuracy: 0.5375\n",
      "Epoch 542/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9781 - accuracy: 0.5202 - val_loss: 0.9119 - val_accuracy: 0.5000\n",
      "Epoch 543/3000\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.9719 - accuracy: 0.5296 - val_loss: 0.8725 - val_accuracy: 0.5375\n",
      "Epoch 544/3000\n",
      "8/8 [==============================] - 2s 245ms/step - loss: 0.9602 - accuracy: 0.5358 - val_loss: 0.8775 - val_accuracy: 0.5375\n",
      "Epoch 545/3000\n",
      "8/8 [==============================] - 2s 251ms/step - loss: 0.9801 - accuracy: 0.5389 - val_loss: 0.8816 - val_accuracy: 0.5375\n",
      "Epoch 546/3000\n",
      "8/8 [==============================] - 2s 244ms/step - loss: 0.9419 - accuracy: 0.5327 - val_loss: 0.8664 - val_accuracy: 0.5375\n",
      "Epoch 547/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9702 - accuracy: 0.5483 - val_loss: 0.8659 - val_accuracy: 0.5375\n",
      "Epoch 548/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9790 - accuracy: 0.5265 - val_loss: 0.8884 - val_accuracy: 0.5250\n",
      "Epoch 549/3000\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.9832 - accuracy: 0.5327 - val_loss: 0.9038 - val_accuracy: 0.5125\n",
      "Epoch 550/3000\n",
      "8/8 [==============================] - 2s 244ms/step - loss: 0.9696 - accuracy: 0.5389 - val_loss: 0.8850 - val_accuracy: 0.5375\n",
      "Epoch 551/3000\n",
      "8/8 [==============================] - 2s 240ms/step - loss: 0.9565 - accuracy: 0.5202 - val_loss: 0.8685 - val_accuracy: 0.5500\n",
      "Epoch 552/3000\n",
      "8/8 [==============================] - 2s 239ms/step - loss: 0.9611 - accuracy: 0.5483 - val_loss: 0.8759 - val_accuracy: 0.5375\n",
      "Epoch 553/3000\n",
      "8/8 [==============================] - 2s 244ms/step - loss: 0.9808 - accuracy: 0.5202 - val_loss: 0.8781 - val_accuracy: 0.5500\n",
      "Epoch 554/3000\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.9611 - accuracy: 0.5296 - val_loss: 0.8801 - val_accuracy: 0.5250\n",
      "Epoch 555/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9463 - accuracy: 0.5452 - val_loss: 0.8675 - val_accuracy: 0.5500\n",
      "Epoch 556/3000\n",
      "8/8 [==============================] - 2s 250ms/step - loss: 0.9629 - accuracy: 0.5358 - val_loss: 0.8620 - val_accuracy: 0.5375\n",
      "Epoch 557/3000\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.9709 - accuracy: 0.5296 - val_loss: 0.8637 - val_accuracy: 0.5625\n",
      "Epoch 558/3000\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.9576 - accuracy: 0.5327 - val_loss: 0.8862 - val_accuracy: 0.5250\n",
      "Epoch 559/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9496 - accuracy: 0.5389 - val_loss: 0.8860 - val_accuracy: 0.5000\n",
      "Epoch 560/3000\n",
      "8/8 [==============================] - 2s 216ms/step - loss: 0.9637 - accuracy: 0.5234 - val_loss: 0.9060 - val_accuracy: 0.5250\n",
      "Epoch 561/3000\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 0.9759 - accuracy: 0.5202 - val_loss: 0.8717 - val_accuracy: 0.5625\n",
      "Epoch 562/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9524 - accuracy: 0.5421 - val_loss: 0.8974 - val_accuracy: 0.5250\n",
      "Epoch 563/3000\n",
      "8/8 [==============================] - 2s 246ms/step - loss: 0.9755 - accuracy: 0.5421 - val_loss: 0.8607 - val_accuracy: 0.5500\n",
      "Epoch 564/3000\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.9617 - accuracy: 0.5421 - val_loss: 0.8691 - val_accuracy: 0.5375\n",
      "Epoch 565/3000\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 0.9654 - accuracy: 0.5265 - val_loss: 0.8755 - val_accuracy: 0.5375\n",
      "Epoch 566/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9577 - accuracy: 0.5327 - val_loss: 0.8835 - val_accuracy: 0.5375\n",
      "Epoch 567/3000\n",
      "8/8 [==============================] - 2s 242ms/step - loss: 0.9427 - accuracy: 0.5421 - val_loss: 0.8768 - val_accuracy: 0.5375\n",
      "Epoch 568/3000\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 0.9643 - accuracy: 0.5389 - val_loss: 0.8694 - val_accuracy: 0.5375\n",
      "Epoch 569/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9609 - accuracy: 0.5234 - val_loss: 0.8768 - val_accuracy: 0.5500\n",
      "Epoch 570/3000\n",
      "8/8 [==============================] - 2s 240ms/step - loss: 0.9597 - accuracy: 0.5452 - val_loss: 0.9190 - val_accuracy: 0.4875\n",
      "Epoch 571/3000\n",
      "8/8 [==============================] - 2s 250ms/step - loss: 0.9845 - accuracy: 0.5389 - val_loss: 0.8850 - val_accuracy: 0.5625\n",
      "Epoch 572/3000\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.9880 - accuracy: 0.5265 - val_loss: 0.8851 - val_accuracy: 0.5375\n",
      "Epoch 573/3000\n",
      "8/8 [==============================] - 2s 248ms/step - loss: 0.9723 - accuracy: 0.5171 - val_loss: 0.9019 - val_accuracy: 0.5250\n",
      "Epoch 574/3000\n",
      "8/8 [==============================] - 2s 253ms/step - loss: 0.9708 - accuracy: 0.5389 - val_loss: 0.8918 - val_accuracy: 0.5250\n",
      "Epoch 575/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9917 - accuracy: 0.5202 - val_loss: 0.8777 - val_accuracy: 0.5375\n",
      "Epoch 576/3000\n",
      "8/8 [==============================] - 2s 253ms/step - loss: 0.9906 - accuracy: 0.5265 - val_loss: 0.8880 - val_accuracy: 0.5625\n",
      "Epoch 577/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9628 - accuracy: 0.5296 - val_loss: 0.8908 - val_accuracy: 0.5375\n",
      "Epoch 578/3000\n",
      "8/8 [==============================] - 2s 252ms/step - loss: 0.9647 - accuracy: 0.5389 - val_loss: 0.9125 - val_accuracy: 0.4875\n",
      "Epoch 579/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9570 - accuracy: 0.5545 - val_loss: 0.8700 - val_accuracy: 0.5500\n",
      "Epoch 580/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9631 - accuracy: 0.5421 - val_loss: 0.8693 - val_accuracy: 0.5500\n",
      "Epoch 581/3000\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.9720 - accuracy: 0.5234 - val_loss: 0.8912 - val_accuracy: 0.5250\n",
      "Epoch 582/3000\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 0.9524 - accuracy: 0.5545 - val_loss: 0.9137 - val_accuracy: 0.5000\n",
      "Epoch 583/3000\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.9677 - accuracy: 0.5389 - val_loss: 0.8660 - val_accuracy: 0.5500\n",
      "Epoch 584/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9535 - accuracy: 0.5202 - val_loss: 0.8637 - val_accuracy: 0.5625\n",
      "Epoch 585/3000\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 0.9588 - accuracy: 0.5327 - val_loss: 0.8890 - val_accuracy: 0.5250\n",
      "Epoch 586/3000\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 0.9750 - accuracy: 0.5265 - val_loss: 0.8775 - val_accuracy: 0.5625\n",
      "Epoch 587/3000\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 0.9788 - accuracy: 0.5171 - val_loss: 0.8787 - val_accuracy: 0.5250\n",
      "Epoch 588/3000\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.9809 - accuracy: 0.5358 - val_loss: 0.8846 - val_accuracy: 0.5250\n",
      "Epoch 589/3000\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 0.9841 - accuracy: 0.5171 - val_loss: 0.8634 - val_accuracy: 0.5375\n",
      "Epoch 590/3000\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.9509 - accuracy: 0.5452 - val_loss: 0.8638 - val_accuracy: 0.5500\n",
      "Epoch 591/3000\n",
      "8/8 [==============================] - 2s 252ms/step - loss: 0.9705 - accuracy: 0.5421 - val_loss: 0.8626 - val_accuracy: 0.5375\n",
      "Epoch 592/3000\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 0.9506 - accuracy: 0.5265 - val_loss: 0.8698 - val_accuracy: 0.5500\n",
      "Epoch 593/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9548 - accuracy: 0.5452 - val_loss: 0.8634 - val_accuracy: 0.5500\n",
      "Epoch 594/3000\n",
      "8/8 [==============================] - 2s 216ms/step - loss: 0.9401 - accuracy: 0.5389 - val_loss: 0.9051 - val_accuracy: 0.5125\n",
      "Epoch 595/3000\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.9673 - accuracy: 0.5234 - val_loss: 0.8671 - val_accuracy: 0.5250\n",
      "Epoch 596/3000\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 0.9918 - accuracy: 0.5327 - val_loss: 0.8747 - val_accuracy: 0.5250\n",
      "Epoch 597/3000\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 0.9547 - accuracy: 0.5421 - val_loss: 0.8815 - val_accuracy: 0.5625\n",
      "Epoch 598/3000\n",
      "8/8 [==============================] - 2s 260ms/step - loss: 0.9605 - accuracy: 0.5452 - val_loss: 0.8876 - val_accuracy: 0.5375\n",
      "Epoch 599/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9622 - accuracy: 0.5234 - val_loss: 0.8771 - val_accuracy: 0.5375\n",
      "Epoch 600/3000\n",
      "8/8 [==============================] - 2s 242ms/step - loss: 0.9723 - accuracy: 0.5483 - val_loss: 0.8930 - val_accuracy: 0.5250\n",
      "Epoch 601/3000\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.9684 - accuracy: 0.5452 - val_loss: 0.8794 - val_accuracy: 0.5500\n",
      "Epoch 602/3000\n",
      "8/8 [==============================] - 2s 209ms/step - loss: 0.9706 - accuracy: 0.5358 - val_loss: 0.8731 - val_accuracy: 0.5750\n",
      "Epoch 603/3000\n",
      "8/8 [==============================] - 2s 266ms/step - loss: 0.9478 - accuracy: 0.5358 - val_loss: 0.8679 - val_accuracy: 0.5500\n",
      "Epoch 604/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9478 - accuracy: 0.5607 - val_loss: 0.8632 - val_accuracy: 0.5375\n",
      "Epoch 605/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9593 - accuracy: 0.5358 - val_loss: 0.8686 - val_accuracy: 0.5250\n",
      "Epoch 606/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9370 - accuracy: 0.5483 - val_loss: 0.8600 - val_accuracy: 0.5250\n",
      "Epoch 607/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9757 - accuracy: 0.5389 - val_loss: 0.9167 - val_accuracy: 0.5000\n",
      "Epoch 608/3000\n",
      "8/8 [==============================] - 2s 246ms/step - loss: 0.9732 - accuracy: 0.5327 - val_loss: 0.8718 - val_accuracy: 0.5375\n",
      "Epoch 609/3000\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 0.9710 - accuracy: 0.5234 - val_loss: 0.9501 - val_accuracy: 0.4625\n",
      "Epoch 610/3000\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.9638 - accuracy: 0.5358 - val_loss: 0.8679 - val_accuracy: 0.5500\n",
      "Epoch 611/3000\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 0.9427 - accuracy: 0.5514 - val_loss: 0.8614 - val_accuracy: 0.5500\n",
      "Epoch 612/3000\n",
      "8/8 [==============================] - 2s 237ms/step - loss: 0.9637 - accuracy: 0.5202 - val_loss: 0.9339 - val_accuracy: 0.4500\n",
      "Epoch 613/3000\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 0.9993 - accuracy: 0.5109 - val_loss: 0.8670 - val_accuracy: 0.5500\n",
      "Epoch 614/3000\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 0.9584 - accuracy: 0.5483 - val_loss: 0.8648 - val_accuracy: 0.5625\n",
      "Epoch 615/3000\n",
      "8/8 [==============================] - 2s 271ms/step - loss: 0.9732 - accuracy: 0.5358 - val_loss: 0.8839 - val_accuracy: 0.5500\n",
      "Epoch 616/3000\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 0.9528 - accuracy: 0.5389 - val_loss: 0.8839 - val_accuracy: 0.5250\n",
      "Epoch 617/3000\n",
      "8/8 [==============================] - 2s 258ms/step - loss: 0.9780 - accuracy: 0.5171 - val_loss: 0.8716 - val_accuracy: 0.5625\n",
      "Epoch 618/3000\n",
      "8/8 [==============================] - 2s 248ms/step - loss: 0.9745 - accuracy: 0.5078 - val_loss: 0.8745 - val_accuracy: 0.5625\n",
      "Epoch 619/3000\n",
      "8/8 [==============================] - 2s 245ms/step - loss: 0.9542 - accuracy: 0.5545 - val_loss: 0.9050 - val_accuracy: 0.4875\n",
      "Epoch 620/3000\n",
      "8/8 [==============================] - 2s 244ms/step - loss: 0.9756 - accuracy: 0.5296 - val_loss: 0.8792 - val_accuracy: 0.5375\n",
      "Epoch 621/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9446 - accuracy: 0.5389 - val_loss: 0.8897 - val_accuracy: 0.4875\n",
      "Epoch 622/3000\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.9707 - accuracy: 0.5296 - val_loss: 0.8712 - val_accuracy: 0.5625\n",
      "Epoch 623/3000\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.9646 - accuracy: 0.5483 - val_loss: 0.8922 - val_accuracy: 0.5500\n",
      "Epoch 624/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9746 - accuracy: 0.5421 - val_loss: 0.9012 - val_accuracy: 0.5000\n",
      "Epoch 625/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9823 - accuracy: 0.5078 - val_loss: 0.8909 - val_accuracy: 0.5500\n",
      "Epoch 626/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9527 - accuracy: 0.5389 - val_loss: 0.8816 - val_accuracy: 0.5250\n",
      "Epoch 627/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9658 - accuracy: 0.5421 - val_loss: 0.8722 - val_accuracy: 0.5625\n",
      "Epoch 628/3000\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.9486 - accuracy: 0.5327 - val_loss: 0.8843 - val_accuracy: 0.5500\n",
      "Epoch 629/3000\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.9562 - accuracy: 0.5452 - val_loss: 0.8887 - val_accuracy: 0.5125\n",
      "Epoch 630/3000\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.9474 - accuracy: 0.5545 - val_loss: 0.8946 - val_accuracy: 0.4875\n",
      "Epoch 631/3000\n",
      "8/8 [==============================] - 2s 267ms/step - loss: 0.9993 - accuracy: 0.5327 - val_loss: 0.8716 - val_accuracy: 0.5500\n",
      "Epoch 632/3000\n",
      "8/8 [==============================] - 2s 244ms/step - loss: 0.9667 - accuracy: 0.5452 - val_loss: 0.8837 - val_accuracy: 0.5125\n",
      "Epoch 633/3000\n",
      "8/8 [==============================] - 2s 241ms/step - loss: 0.9533 - accuracy: 0.5452 - val_loss: 0.8741 - val_accuracy: 0.5625\n",
      "Epoch 634/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9644 - accuracy: 0.5265 - val_loss: 0.8811 - val_accuracy: 0.5375\n",
      "Epoch 635/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9920 - accuracy: 0.5202 - val_loss: 0.8784 - val_accuracy: 0.5375\n",
      "Epoch 636/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9530 - accuracy: 0.5545 - val_loss: 0.8566 - val_accuracy: 0.5625\n",
      "Epoch 637/3000\n",
      "8/8 [==============================] - 2s 249ms/step - loss: 0.9897 - accuracy: 0.5358 - val_loss: 0.8618 - val_accuracy: 0.5625\n",
      "Epoch 638/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9756 - accuracy: 0.5296 - val_loss: 0.8640 - val_accuracy: 0.5750\n",
      "Epoch 639/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9624 - accuracy: 0.5358 - val_loss: 0.8553 - val_accuracy: 0.5625\n",
      "Epoch 640/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9598 - accuracy: 0.5202 - val_loss: 0.8804 - val_accuracy: 0.5375\n",
      "Epoch 641/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9327 - accuracy: 0.5483 - val_loss: 0.8575 - val_accuracy: 0.5500\n",
      "Epoch 642/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9356 - accuracy: 0.5483 - val_loss: 0.9240 - val_accuracy: 0.4750\n",
      "Epoch 643/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9427 - accuracy: 0.5576 - val_loss: 0.9206 - val_accuracy: 0.5250\n",
      "Epoch 644/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9742 - accuracy: 0.5607 - val_loss: 0.8704 - val_accuracy: 0.5500\n",
      "Epoch 645/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9623 - accuracy: 0.5234 - val_loss: 0.8756 - val_accuracy: 0.5375\n",
      "Epoch 646/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9797 - accuracy: 0.5358 - val_loss: 0.9115 - val_accuracy: 0.4875\n",
      "Epoch 647/3000\n",
      "8/8 [==============================] - 2s 244ms/step - loss: 0.9444 - accuracy: 0.5514 - val_loss: 0.8889 - val_accuracy: 0.5250\n",
      "Epoch 648/3000\n",
      "8/8 [==============================] - 2s 246ms/step - loss: 0.9682 - accuracy: 0.5296 - val_loss: 0.8725 - val_accuracy: 0.5375\n",
      "Epoch 649/3000\n",
      "8/8 [==============================] - 2s 247ms/step - loss: 0.9730 - accuracy: 0.5296 - val_loss: 0.8697 - val_accuracy: 0.5375\n",
      "Epoch 650/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9703 - accuracy: 0.5327 - val_loss: 0.8712 - val_accuracy: 0.5625\n",
      "Epoch 651/3000\n",
      "8/8 [==============================] - 2s 235ms/step - loss: 0.9772 - accuracy: 0.5171 - val_loss: 0.8717 - val_accuracy: 0.5500\n",
      "Epoch 652/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9565 - accuracy: 0.5327 - val_loss: 0.8718 - val_accuracy: 0.5500\n",
      "Epoch 653/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9546 - accuracy: 0.5421 - val_loss: 0.8631 - val_accuracy: 0.5375\n",
      "Epoch 654/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9872 - accuracy: 0.5171 - val_loss: 0.8859 - val_accuracy: 0.5625\n",
      "Epoch 655/3000\n",
      "8/8 [==============================] - 2s 280ms/step - loss: 0.9459 - accuracy: 0.5358 - val_loss: 0.8657 - val_accuracy: 0.5625\n",
      "Epoch 656/3000\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 0.9537 - accuracy: 0.5389 - val_loss: 0.8906 - val_accuracy: 0.5125\n",
      "Epoch 657/3000\n",
      "8/8 [==============================] - 2s 241ms/step - loss: 0.9880 - accuracy: 0.5171 - val_loss: 0.8653 - val_accuracy: 0.5375\n",
      "Epoch 658/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9546 - accuracy: 0.5234 - val_loss: 0.8568 - val_accuracy: 0.5500\n",
      "Epoch 659/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9353 - accuracy: 0.5639 - val_loss: 0.9315 - val_accuracy: 0.4375\n",
      "Epoch 660/3000\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.9546 - accuracy: 0.5296 - val_loss: 0.8506 - val_accuracy: 0.5500\n",
      "Epoch 661/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9774 - accuracy: 0.5202 - val_loss: 0.8611 - val_accuracy: 0.5625\n",
      "Epoch 662/3000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.9686 - accuracy: 0.5234 - val_loss: 0.8656 - val_accuracy: 0.5500\n",
      "Epoch 663/3000\n",
      "8/8 [==============================] - 2s 248ms/step - loss: 0.9640 - accuracy: 0.5296 - val_loss: 0.8762 - val_accuracy: 0.5500\n",
      "Epoch 664/3000\n",
      "8/8 [==============================] - 2s 247ms/step - loss: 0.9337 - accuracy: 0.5576 - val_loss: 0.8956 - val_accuracy: 0.4750\n",
      "Epoch 665/3000\n",
      "8/8 [==============================] - 2s 270ms/step - loss: 0.9642 - accuracy: 0.5358 - val_loss: 0.8631 - val_accuracy: 0.5625\n",
      "Epoch 666/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9608 - accuracy: 0.5265 - val_loss: 0.8830 - val_accuracy: 0.5000\n",
      "Epoch 667/3000\n",
      "8/8 [==============================] - 2s 256ms/step - loss: 0.9948 - accuracy: 0.5327 - val_loss: 0.8682 - val_accuracy: 0.5625\n",
      "Epoch 668/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9512 - accuracy: 0.5327 - val_loss: 0.9494 - val_accuracy: 0.4375\n",
      "Epoch 669/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9696 - accuracy: 0.5109 - val_loss: 0.8716 - val_accuracy: 0.5625\n",
      "Epoch 670/3000\n",
      "8/8 [==============================] - 2s 238ms/step - loss: 0.9806 - accuracy: 0.5421 - val_loss: 0.8733 - val_accuracy: 0.5750\n",
      "Epoch 671/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9703 - accuracy: 0.5358 - val_loss: 0.8721 - val_accuracy: 0.5500\n",
      "Epoch 672/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9614 - accuracy: 0.5202 - val_loss: 0.8865 - val_accuracy: 0.4875\n",
      "Epoch 673/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9573 - accuracy: 0.5016 - val_loss: 0.8641 - val_accuracy: 0.5750\n",
      "Epoch 674/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9740 - accuracy: 0.5296 - val_loss: 0.8671 - val_accuracy: 0.5625\n",
      "Epoch 675/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9895 - accuracy: 0.5078 - val_loss: 0.9169 - val_accuracy: 0.5000\n",
      "Epoch 676/3000\n",
      "8/8 [==============================] - 2s 255ms/step - loss: 1.0145 - accuracy: 0.4922 - val_loss: 0.8803 - val_accuracy: 0.5500\n",
      "Epoch 677/3000\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.9543 - accuracy: 0.5265 - val_loss: 0.8695 - val_accuracy: 0.5375\n",
      "Epoch 678/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9888 - accuracy: 0.5171 - val_loss: 0.8712 - val_accuracy: 0.5375\n",
      "Epoch 679/3000\n",
      "8/8 [==============================] - 2s 241ms/step - loss: 0.9496 - accuracy: 0.5389 - val_loss: 0.9184 - val_accuracy: 0.4750\n",
      "Epoch 680/3000\n",
      "8/8 [==============================] - 2s 246ms/step - loss: 0.9687 - accuracy: 0.5358 - val_loss: 0.8954 - val_accuracy: 0.5250\n",
      "Epoch 681/3000\n",
      "8/8 [==============================] - 2s 240ms/step - loss: 0.9773 - accuracy: 0.5389 - val_loss: 0.9036 - val_accuracy: 0.5250\n",
      "Epoch 682/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9562 - accuracy: 0.5265 - val_loss: 0.8690 - val_accuracy: 0.5625\n",
      "Epoch 683/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9373 - accuracy: 0.5670 - val_loss: 0.8747 - val_accuracy: 0.5375\n",
      "Epoch 684/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9503 - accuracy: 0.5452 - val_loss: 0.8926 - val_accuracy: 0.4875\n",
      "Epoch 685/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9769 - accuracy: 0.5327 - val_loss: 0.8738 - val_accuracy: 0.5625\n",
      "Epoch 686/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9750 - accuracy: 0.5234 - val_loss: 0.9050 - val_accuracy: 0.5500\n",
      "Epoch 687/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9596 - accuracy: 0.5358 - val_loss: 0.8718 - val_accuracy: 0.5375\n",
      "Epoch 688/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9558 - accuracy: 0.5421 - val_loss: 0.9017 - val_accuracy: 0.5250\n",
      "Epoch 689/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9550 - accuracy: 0.5296 - val_loss: 0.9110 - val_accuracy: 0.4875\n",
      "Epoch 690/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9505 - accuracy: 0.5545 - val_loss: 0.8757 - val_accuracy: 0.5500\n",
      "Epoch 691/3000\n",
      "8/8 [==============================] - 2s 263ms/step - loss: 0.9620 - accuracy: 0.5545 - val_loss: 0.8654 - val_accuracy: 0.5500\n",
      "Epoch 692/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9538 - accuracy: 0.5389 - val_loss: 0.8749 - val_accuracy: 0.5250\n",
      "Epoch 693/3000\n",
      "8/8 [==============================] - 2s 237ms/step - loss: 0.9907 - accuracy: 0.5265 - val_loss: 0.8630 - val_accuracy: 0.5500\n",
      "Epoch 694/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9503 - accuracy: 0.5421 - val_loss: 0.8634 - val_accuracy: 0.5500\n",
      "Epoch 695/3000\n",
      "8/8 [==============================] - 2s 249ms/step - loss: 0.9786 - accuracy: 0.5296 - val_loss: 0.8787 - val_accuracy: 0.5625\n",
      "Epoch 696/3000\n",
      "8/8 [==============================] - 2s 241ms/step - loss: 0.9483 - accuracy: 0.5514 - val_loss: 0.8704 - val_accuracy: 0.5375\n",
      "Epoch 697/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9795 - accuracy: 0.5234 - val_loss: 0.8752 - val_accuracy: 0.5250\n",
      "Epoch 698/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9567 - accuracy: 0.5421 - val_loss: 0.8595 - val_accuracy: 0.5500\n",
      "Epoch 699/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9160 - accuracy: 0.5732 - val_loss: 0.8677 - val_accuracy: 0.5250\n",
      "Epoch 700/3000\n",
      "8/8 [==============================] - 2s 261ms/step - loss: 0.9770 - accuracy: 0.5296 - val_loss: 0.8597 - val_accuracy: 0.5500\n",
      "Epoch 701/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9545 - accuracy: 0.5545 - val_loss: 0.8803 - val_accuracy: 0.5125\n",
      "Epoch 702/3000\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 0.9573 - accuracy: 0.5483 - val_loss: 0.8602 - val_accuracy: 0.5625\n",
      "Epoch 703/3000\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.9625 - accuracy: 0.5452 - val_loss: 0.8805 - val_accuracy: 0.5125\n",
      "Epoch 704/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9603 - accuracy: 0.5265 - val_loss: 0.8666 - val_accuracy: 0.5500\n",
      "Epoch 705/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9684 - accuracy: 0.5140 - val_loss: 0.8912 - val_accuracy: 0.5125\n",
      "Epoch 706/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9628 - accuracy: 0.5171 - val_loss: 0.8617 - val_accuracy: 0.5375\n",
      "Epoch 707/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9568 - accuracy: 0.5202 - val_loss: 0.9121 - val_accuracy: 0.4750\n",
      "Epoch 708/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9593 - accuracy: 0.5483 - val_loss: 0.8622 - val_accuracy: 0.5500\n",
      "Epoch 709/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9413 - accuracy: 0.5389 - val_loss: 0.8686 - val_accuracy: 0.5375\n",
      "Epoch 710/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9427 - accuracy: 0.5483 - val_loss: 0.9431 - val_accuracy: 0.4375\n",
      "Epoch 711/3000\n",
      "8/8 [==============================] - 2s 244ms/step - loss: 0.9849 - accuracy: 0.5234 - val_loss: 0.8956 - val_accuracy: 0.5125\n",
      "Epoch 712/3000\n",
      "8/8 [==============================] - 2s 248ms/step - loss: 0.9544 - accuracy: 0.5265 - val_loss: 0.8551 - val_accuracy: 0.5750\n",
      "Epoch 713/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9626 - accuracy: 0.5296 - val_loss: 0.8578 - val_accuracy: 0.5625\n",
      "Epoch 714/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9378 - accuracy: 0.5514 - val_loss: 0.8570 - val_accuracy: 0.5750\n",
      "Epoch 715/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9727 - accuracy: 0.5171 - val_loss: 0.8847 - val_accuracy: 0.5625\n",
      "Epoch 716/3000\n",
      "8/8 [==============================] - 2s 235ms/step - loss: 0.9490 - accuracy: 0.5639 - val_loss: 0.8977 - val_accuracy: 0.5000\n",
      "Epoch 717/3000\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.9601 - accuracy: 0.5265 - val_loss: 0.9492 - val_accuracy: 0.5000\n",
      "Epoch 718/3000\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 0.9731 - accuracy: 0.5234 - val_loss: 0.8770 - val_accuracy: 0.5000\n",
      "Epoch 719/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9415 - accuracy: 0.5358 - val_loss: 0.8952 - val_accuracy: 0.5125\n",
      "Epoch 720/3000\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.9275 - accuracy: 0.5452 - val_loss: 0.8525 - val_accuracy: 0.5500\n",
      "Epoch 721/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9656 - accuracy: 0.5202 - val_loss: 0.8550 - val_accuracy: 0.5500\n",
      "Epoch 722/3000\n",
      "8/8 [==============================] - 2s 258ms/step - loss: 0.9678 - accuracy: 0.5109 - val_loss: 0.8671 - val_accuracy: 0.5625\n",
      "Epoch 723/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9495 - accuracy: 0.5296 - val_loss: 0.8636 - val_accuracy: 0.5500\n",
      "Epoch 724/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9385 - accuracy: 0.5483 - val_loss: 0.8880 - val_accuracy: 0.4875\n",
      "Epoch 725/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9434 - accuracy: 0.5639 - val_loss: 0.8535 - val_accuracy: 0.5500\n",
      "Epoch 726/3000\n",
      "8/8 [==============================] - 2s 254ms/step - loss: 0.9436 - accuracy: 0.5327 - val_loss: 0.8448 - val_accuracy: 0.5500\n",
      "Epoch 727/3000\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 0.9498 - accuracy: 0.5607 - val_loss: 0.8748 - val_accuracy: 0.5125\n",
      "Epoch 728/3000\n",
      "8/8 [==============================] - 2s 238ms/step - loss: 0.9293 - accuracy: 0.5483 - val_loss: 0.8601 - val_accuracy: 0.5625\n",
      "Epoch 729/3000\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.9598 - accuracy: 0.5452 - val_loss: 0.8627 - val_accuracy: 0.5250\n",
      "Epoch 730/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9656 - accuracy: 0.5296 - val_loss: 0.8529 - val_accuracy: 0.5500\n",
      "Epoch 731/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9470 - accuracy: 0.5296 - val_loss: 0.8533 - val_accuracy: 0.5500\n",
      "Epoch 732/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9732 - accuracy: 0.5327 - val_loss: 0.8640 - val_accuracy: 0.5500\n",
      "Epoch 733/3000\n",
      "8/8 [==============================] - 2s 258ms/step - loss: 0.9652 - accuracy: 0.5265 - val_loss: 0.8577 - val_accuracy: 0.5500\n",
      "Epoch 734/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9507 - accuracy: 0.5452 - val_loss: 0.8967 - val_accuracy: 0.4875\n",
      "Epoch 735/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9721 - accuracy: 0.5327 - val_loss: 0.8594 - val_accuracy: 0.5500\n",
      "Epoch 736/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9536 - accuracy: 0.5514 - val_loss: 0.8570 - val_accuracy: 0.5375\n",
      "Epoch 737/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9635 - accuracy: 0.5358 - val_loss: 0.8680 - val_accuracy: 0.5625\n",
      "Epoch 738/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9597 - accuracy: 0.5389 - val_loss: 0.8806 - val_accuracy: 0.5375\n",
      "Epoch 739/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9678 - accuracy: 0.5358 - val_loss: 0.8764 - val_accuracy: 0.5625\n",
      "Epoch 740/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9448 - accuracy: 0.5140 - val_loss: 0.8794 - val_accuracy: 0.5375\n",
      "Epoch 741/3000\n",
      "8/8 [==============================] - 2s 235ms/step - loss: 0.9472 - accuracy: 0.5389 - val_loss: 0.8718 - val_accuracy: 0.5625\n",
      "Epoch 742/3000\n",
      "8/8 [==============================] - 2s 278ms/step - loss: 0.9665 - accuracy: 0.5171 - val_loss: 0.8666 - val_accuracy: 0.5500\n",
      "Epoch 743/3000\n",
      "8/8 [==============================] - 2s 255ms/step - loss: 0.9663 - accuracy: 0.5109 - val_loss: 0.8702 - val_accuracy: 0.5500\n",
      "Epoch 744/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9518 - accuracy: 0.5483 - val_loss: 0.8789 - val_accuracy: 0.5375\n",
      "Epoch 745/3000\n",
      "8/8 [==============================] - 2s 237ms/step - loss: 0.9737 - accuracy: 0.5389 - val_loss: 0.8728 - val_accuracy: 0.5375\n",
      "Epoch 746/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9574 - accuracy: 0.5389 - val_loss: 0.8810 - val_accuracy: 0.5375\n",
      "Epoch 747/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9578 - accuracy: 0.5545 - val_loss: 0.8612 - val_accuracy: 0.5500\n",
      "Epoch 748/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9887 - accuracy: 0.5078 - val_loss: 0.8598 - val_accuracy: 0.5500\n",
      "Epoch 749/3000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.9373 - accuracy: 0.5296 - val_loss: 0.8513 - val_accuracy: 0.5500\n",
      "Epoch 750/3000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.9725 - accuracy: 0.5265 - val_loss: 0.8617 - val_accuracy: 0.5375\n",
      "Epoch 751/3000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.9682 - accuracy: 0.5171 - val_loss: 0.8510 - val_accuracy: 0.5500\n",
      "Epoch 752/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9583 - accuracy: 0.5327 - val_loss: 0.8745 - val_accuracy: 0.5375\n",
      "Epoch 753/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9712 - accuracy: 0.5452 - val_loss: 0.8742 - val_accuracy: 0.5250\n",
      "Epoch 754/3000\n",
      "8/8 [==============================] - 2s 255ms/step - loss: 0.9342 - accuracy: 0.5545 - val_loss: 0.8697 - val_accuracy: 0.5375\n",
      "Epoch 755/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9328 - accuracy: 0.5452 - val_loss: 0.8517 - val_accuracy: 0.5375\n",
      "Epoch 756/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9263 - accuracy: 0.5514 - val_loss: 0.8448 - val_accuracy: 0.5500\n",
      "Epoch 757/3000\n",
      "8/8 [==============================] - 2s 238ms/step - loss: 0.9545 - accuracy: 0.5296 - val_loss: 0.8663 - val_accuracy: 0.5625\n",
      "Epoch 758/3000\n",
      "8/8 [==============================] - 2s 242ms/step - loss: 0.9493 - accuracy: 0.5421 - val_loss: 0.8767 - val_accuracy: 0.5125\n",
      "Epoch 759/3000\n",
      "8/8 [==============================] - 2s 252ms/step - loss: 0.9700 - accuracy: 0.5202 - val_loss: 0.8732 - val_accuracy: 0.5625\n",
      "Epoch 760/3000\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 0.9709 - accuracy: 0.5327 - val_loss: 0.8567 - val_accuracy: 0.5625\n",
      "Epoch 761/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9727 - accuracy: 0.5234 - val_loss: 0.8569 - val_accuracy: 0.5625\n",
      "Epoch 762/3000\n",
      "8/8 [==============================] - 2s 259ms/step - loss: 0.9562 - accuracy: 0.5545 - val_loss: 0.8729 - val_accuracy: 0.5375\n",
      "Epoch 763/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9511 - accuracy: 0.5265 - val_loss: 0.8621 - val_accuracy: 0.5375\n",
      "Epoch 764/3000\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.9734 - accuracy: 0.5202 - val_loss: 0.8672 - val_accuracy: 0.5500\n",
      "Epoch 765/3000\n",
      "8/8 [==============================] - 2s 256ms/step - loss: 0.9797 - accuracy: 0.5234 - val_loss: 0.8636 - val_accuracy: 0.5500\n",
      "Epoch 766/3000\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 0.9384 - accuracy: 0.5452 - val_loss: 0.8969 - val_accuracy: 0.4750\n",
      "Epoch 767/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9423 - accuracy: 0.5607 - val_loss: 0.9145 - val_accuracy: 0.4750\n",
      "Epoch 768/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9413 - accuracy: 0.5483 - val_loss: 0.8586 - val_accuracy: 0.5625\n",
      "Epoch 769/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9782 - accuracy: 0.5514 - val_loss: 0.8609 - val_accuracy: 0.5500\n",
      "Epoch 770/3000\n",
      "8/8 [==============================] - 2s 248ms/step - loss: 0.9540 - accuracy: 0.5389 - val_loss: 0.8628 - val_accuracy: 0.5500\n",
      "Epoch 771/3000\n",
      "8/8 [==============================] - 2s 238ms/step - loss: 0.9776 - accuracy: 0.5265 - val_loss: 0.8663 - val_accuracy: 0.5375\n",
      "Epoch 772/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9669 - accuracy: 0.5296 - val_loss: 0.8935 - val_accuracy: 0.5125\n",
      "Epoch 773/3000\n",
      "8/8 [==============================] - 2s 257ms/step - loss: 0.9602 - accuracy: 0.5514 - val_loss: 0.9083 - val_accuracy: 0.5125\n",
      "Epoch 774/3000\n",
      "8/8 [==============================] - 2s 240ms/step - loss: 0.9827 - accuracy: 0.5140 - val_loss: 0.8846 - val_accuracy: 0.5125\n",
      "Epoch 775/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9596 - accuracy: 0.5327 - val_loss: 0.8606 - val_accuracy: 0.5625\n",
      "Epoch 776/3000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.9581 - accuracy: 0.5265 - val_loss: 0.8799 - val_accuracy: 0.5375\n",
      "Epoch 777/3000\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.9698 - accuracy: 0.5234 - val_loss: 0.8836 - val_accuracy: 0.5125\n",
      "Epoch 778/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9561 - accuracy: 0.5202 - val_loss: 0.9183 - val_accuracy: 0.4625\n",
      "Epoch 779/3000\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.9871 - accuracy: 0.5202 - val_loss: 0.8813 - val_accuracy: 0.5250\n",
      "Epoch 780/3000\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.9446 - accuracy: 0.5483 - val_loss: 0.8730 - val_accuracy: 0.5250\n",
      "Epoch 781/3000\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.9317 - accuracy: 0.5483 - val_loss: 0.8646 - val_accuracy: 0.5375\n",
      "Epoch 782/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9528 - accuracy: 0.5265 - val_loss: 0.8593 - val_accuracy: 0.5625\n",
      "Epoch 783/3000\n",
      "8/8 [==============================] - 2s 252ms/step - loss: 0.9632 - accuracy: 0.5358 - val_loss: 0.8900 - val_accuracy: 0.5125\n",
      "Epoch 784/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9549 - accuracy: 0.5421 - val_loss: 0.9010 - val_accuracy: 0.5000\n",
      "Epoch 785/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9451 - accuracy: 0.5327 - val_loss: 0.8601 - val_accuracy: 0.5625\n",
      "Epoch 786/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9525 - accuracy: 0.5265 - val_loss: 0.8675 - val_accuracy: 0.5500\n",
      "Epoch 787/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9478 - accuracy: 0.5483 - val_loss: 0.8510 - val_accuracy: 0.5625\n",
      "Epoch 788/3000\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 0.9598 - accuracy: 0.5358 - val_loss: 0.9160 - val_accuracy: 0.4875\n",
      "Epoch 789/3000\n",
      "8/8 [==============================] - 2s 237ms/step - loss: 0.9907 - accuracy: 0.5171 - val_loss: 0.8642 - val_accuracy: 0.5500\n",
      "Epoch 790/3000\n",
      "8/8 [==============================] - 2s 251ms/step - loss: 0.9594 - accuracy: 0.5202 - val_loss: 0.8846 - val_accuracy: 0.5375\n",
      "Epoch 791/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9551 - accuracy: 0.5296 - val_loss: 0.8627 - val_accuracy: 0.5625\n",
      "Epoch 792/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9658 - accuracy: 0.5171 - val_loss: 0.9107 - val_accuracy: 0.4750\n",
      "Epoch 793/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9703 - accuracy: 0.5265 - val_loss: 0.8701 - val_accuracy: 0.5500\n",
      "Epoch 794/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9245 - accuracy: 0.5483 - val_loss: 0.8882 - val_accuracy: 0.5000\n",
      "Epoch 795/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9701 - accuracy: 0.5421 - val_loss: 0.8833 - val_accuracy: 0.5125\n",
      "Epoch 796/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9652 - accuracy: 0.5265 - val_loss: 0.8570 - val_accuracy: 0.5375\n",
      "Epoch 797/3000\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 0.9342 - accuracy: 0.5514 - val_loss: 0.9522 - val_accuracy: 0.4625\n",
      "Epoch 798/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9970 - accuracy: 0.5171 - val_loss: 0.8542 - val_accuracy: 0.5500\n",
      "Epoch 799/3000\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 0.9547 - accuracy: 0.5452 - val_loss: 0.8723 - val_accuracy: 0.5375\n",
      "Epoch 800/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9777 - accuracy: 0.5265 - val_loss: 0.8686 - val_accuracy: 0.5500\n",
      "Epoch 801/3000\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.9403 - accuracy: 0.5483 - val_loss: 0.8838 - val_accuracy: 0.5125\n",
      "Epoch 802/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9358 - accuracy: 0.5701 - val_loss: 0.8630 - val_accuracy: 0.5500\n",
      "Epoch 803/3000\n",
      "8/8 [==============================] - 2s 251ms/step - loss: 0.9482 - accuracy: 0.5421 - val_loss: 0.8680 - val_accuracy: 0.5375\n",
      "Epoch 804/3000\n",
      "8/8 [==============================] - 2s 235ms/step - loss: 0.9455 - accuracy: 0.5576 - val_loss: 0.8588 - val_accuracy: 0.5250\n",
      "Epoch 805/3000\n",
      "8/8 [==============================] - 2s 237ms/step - loss: 0.9442 - accuracy: 0.5452 - val_loss: 0.8712 - val_accuracy: 0.5250\n",
      "Epoch 806/3000\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 0.9631 - accuracy: 0.5171 - val_loss: 0.8910 - val_accuracy: 0.5000\n",
      "Epoch 807/3000\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.9646 - accuracy: 0.5358 - val_loss: 0.8905 - val_accuracy: 0.5125\n",
      "Epoch 808/3000\n",
      "8/8 [==============================] - 2s 248ms/step - loss: 0.9294 - accuracy: 0.5576 - val_loss: 0.8758 - val_accuracy: 0.5375\n",
      "Epoch 809/3000\n",
      "8/8 [==============================] - 2s 239ms/step - loss: 0.9448 - accuracy: 0.5296 - val_loss: 0.8586 - val_accuracy: 0.5375\n",
      "Epoch 810/3000\n",
      "8/8 [==============================] - 2s 241ms/step - loss: 0.9651 - accuracy: 0.5327 - val_loss: 0.8656 - val_accuracy: 0.5500\n",
      "Epoch 811/3000\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.9434 - accuracy: 0.5483 - val_loss: 0.8548 - val_accuracy: 0.5375\n",
      "Epoch 812/3000\n",
      "8/8 [==============================] - 2s 203ms/step - loss: 0.9369 - accuracy: 0.5545 - val_loss: 0.8511 - val_accuracy: 0.5375\n",
      "Epoch 813/3000\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.9662 - accuracy: 0.5358 - val_loss: 0.8606 - val_accuracy: 0.5500\n",
      "Epoch 814/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9682 - accuracy: 0.5296 - val_loss: 0.8931 - val_accuracy: 0.5000\n",
      "Epoch 815/3000\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.9544 - accuracy: 0.5421 - val_loss: 0.8595 - val_accuracy: 0.5375\n",
      "Epoch 816/3000\n",
      "8/8 [==============================] - 2s 258ms/step - loss: 0.9726 - accuracy: 0.5296 - val_loss: 0.8885 - val_accuracy: 0.5125\n",
      "Epoch 817/3000\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.9559 - accuracy: 0.5234 - val_loss: 0.8538 - val_accuracy: 0.5500\n",
      "Epoch 818/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9566 - accuracy: 0.5701 - val_loss: 0.8576 - val_accuracy: 0.5500\n",
      "Epoch 819/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9456 - accuracy: 0.5452 - val_loss: 0.8594 - val_accuracy: 0.5500\n",
      "Epoch 820/3000\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 0.9413 - accuracy: 0.5452 - val_loss: 0.9059 - val_accuracy: 0.4625\n",
      "Epoch 821/3000\n",
      "8/8 [==============================] - 2s 244ms/step - loss: 0.9501 - accuracy: 0.5202 - val_loss: 0.8613 - val_accuracy: 0.5500\n",
      "Epoch 822/3000\n",
      "8/8 [==============================] - 2s 270ms/step - loss: 0.9593 - accuracy: 0.5358 - val_loss: 0.8586 - val_accuracy: 0.5375\n",
      "Epoch 823/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9658 - accuracy: 0.5296 - val_loss: 0.8589 - val_accuracy: 0.5500\n",
      "Epoch 824/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9731 - accuracy: 0.5358 - val_loss: 0.8558 - val_accuracy: 0.5375\n",
      "Epoch 825/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9267 - accuracy: 0.5452 - val_loss: 0.8826 - val_accuracy: 0.5125\n",
      "Epoch 826/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9783 - accuracy: 0.5483 - val_loss: 0.8488 - val_accuracy: 0.5500\n",
      "Epoch 827/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9603 - accuracy: 0.5265 - val_loss: 0.8504 - val_accuracy: 0.5500\n",
      "Epoch 828/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9402 - accuracy: 0.5327 - val_loss: 0.8811 - val_accuracy: 0.5125\n",
      "Epoch 829/3000\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.9628 - accuracy: 0.5140 - val_loss: 0.9107 - val_accuracy: 0.4625\n",
      "Epoch 830/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9647 - accuracy: 0.5327 - val_loss: 0.8498 - val_accuracy: 0.5375\n",
      "Epoch 831/3000\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 1.0234 - accuracy: 0.5327 - val_loss: 0.8640 - val_accuracy: 0.5500\n",
      "Epoch 832/3000\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 0.9605 - accuracy: 0.5265 - val_loss: 0.8785 - val_accuracy: 0.5500\n",
      "Epoch 833/3000\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.9418 - accuracy: 0.5514 - val_loss: 0.8785 - val_accuracy: 0.5000\n",
      "Epoch 834/3000\n",
      "8/8 [==============================] - 2s 249ms/step - loss: 0.9189 - accuracy: 0.5483 - val_loss: 0.8703 - val_accuracy: 0.5125\n",
      "Epoch 835/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9491 - accuracy: 0.5327 - val_loss: 0.8816 - val_accuracy: 0.5000\n",
      "Epoch 836/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9609 - accuracy: 0.5514 - val_loss: 0.8495 - val_accuracy: 0.5375\n",
      "Epoch 837/3000\n",
      "8/8 [==============================] - 2s 271ms/step - loss: 0.9445 - accuracy: 0.5545 - val_loss: 0.8470 - val_accuracy: 0.5625\n",
      "Epoch 838/3000\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 0.9251 - accuracy: 0.5607 - val_loss: 0.8667 - val_accuracy: 0.5500\n",
      "Epoch 839/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9649 - accuracy: 0.5265 - val_loss: 0.8525 - val_accuracy: 0.5500\n",
      "Epoch 840/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9486 - accuracy: 0.5327 - val_loss: 0.8513 - val_accuracy: 0.5500\n",
      "Epoch 841/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9405 - accuracy: 0.5452 - val_loss: 0.8568 - val_accuracy: 0.5375\n",
      "Epoch 842/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9173 - accuracy: 0.5607 - val_loss: 0.8759 - val_accuracy: 0.5000\n",
      "Epoch 843/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9558 - accuracy: 0.5265 - val_loss: 0.8991 - val_accuracy: 0.5125\n",
      "Epoch 844/3000\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.9450 - accuracy: 0.5202 - val_loss: 0.8847 - val_accuracy: 0.5000\n",
      "Epoch 845/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9521 - accuracy: 0.5109 - val_loss: 0.8619 - val_accuracy: 0.5250\n",
      "Epoch 846/3000\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.9600 - accuracy: 0.5202 - val_loss: 0.8590 - val_accuracy: 0.5500\n",
      "Epoch 847/3000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.9465 - accuracy: 0.5327 - val_loss: 0.8589 - val_accuracy: 0.5375\n",
      "Epoch 848/3000\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 0.9291 - accuracy: 0.5607 - val_loss: 0.8650 - val_accuracy: 0.5375\n",
      "Epoch 849/3000\n",
      "8/8 [==============================] - 2s 267ms/step - loss: 0.9460 - accuracy: 0.5421 - val_loss: 0.8574 - val_accuracy: 0.5500\n",
      "Epoch 850/3000\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.9730 - accuracy: 0.5358 - val_loss: 0.8602 - val_accuracy: 0.5500\n",
      "Epoch 851/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9389 - accuracy: 0.5514 - val_loss: 0.8535 - val_accuracy: 0.5500\n",
      "Epoch 852/3000\n",
      "8/8 [==============================] - 2s 244ms/step - loss: 0.9309 - accuracy: 0.5576 - val_loss: 0.8815 - val_accuracy: 0.5000\n",
      "Epoch 853/3000\n",
      "8/8 [==============================] - 2s 245ms/step - loss: 0.9526 - accuracy: 0.5234 - val_loss: 0.8568 - val_accuracy: 0.5500\n",
      "Epoch 854/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9593 - accuracy: 0.5670 - val_loss: 0.8700 - val_accuracy: 0.5500\n",
      "Epoch 855/3000\n",
      "8/8 [==============================] - 2s 253ms/step - loss: 0.9513 - accuracy: 0.5171 - val_loss: 0.8583 - val_accuracy: 0.5500\n",
      "Epoch 856/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9694 - accuracy: 0.5514 - val_loss: 0.8559 - val_accuracy: 0.5375\n",
      "Epoch 857/3000\n",
      "8/8 [==============================] - 2s 265ms/step - loss: 0.9510 - accuracy: 0.5389 - val_loss: 0.8794 - val_accuracy: 0.5375\n",
      "Epoch 858/3000\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.9491 - accuracy: 0.5389 - val_loss: 0.8946 - val_accuracy: 0.5125\n",
      "Epoch 859/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9643 - accuracy: 0.5421 - val_loss: 0.8668 - val_accuracy: 0.5375\n",
      "Epoch 860/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9431 - accuracy: 0.5576 - val_loss: 0.8625 - val_accuracy: 0.5500\n",
      "Epoch 861/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9277 - accuracy: 0.5421 - val_loss: 0.8622 - val_accuracy: 0.5500\n",
      "Epoch 862/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9612 - accuracy: 0.5234 - val_loss: 0.8619 - val_accuracy: 0.5500\n",
      "Epoch 863/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9364 - accuracy: 0.5202 - val_loss: 0.8550 - val_accuracy: 0.5625\n",
      "Epoch 864/3000\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.9378 - accuracy: 0.5701 - val_loss: 0.8491 - val_accuracy: 0.5375\n",
      "Epoch 865/3000\n",
      "8/8 [==============================] - 2s 289ms/step - loss: 0.9479 - accuracy: 0.5358 - val_loss: 0.8454 - val_accuracy: 0.5625\n",
      "Epoch 866/3000\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 0.9354 - accuracy: 0.5545 - val_loss: 0.9243 - val_accuracy: 0.4875\n",
      "Epoch 867/3000\n",
      "8/8 [==============================] - 2s 245ms/step - loss: 0.9505 - accuracy: 0.5483 - val_loss: 0.8569 - val_accuracy: 0.5375\n",
      "Epoch 868/3000\n",
      "8/8 [==============================] - 2s 239ms/step - loss: 0.9532 - accuracy: 0.5296 - val_loss: 0.8882 - val_accuracy: 0.5000\n",
      "Epoch 869/3000\n",
      "8/8 [==============================] - 2s 267ms/step - loss: 0.9599 - accuracy: 0.5296 - val_loss: 0.8721 - val_accuracy: 0.5375\n",
      "Epoch 870/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9574 - accuracy: 0.5452 - val_loss: 0.8518 - val_accuracy: 0.5500\n",
      "Epoch 871/3000\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.9610 - accuracy: 0.5296 - val_loss: 0.8584 - val_accuracy: 0.5250\n",
      "Epoch 872/3000\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.9094 - accuracy: 0.5670 - val_loss: 0.8476 - val_accuracy: 0.5500\n",
      "Epoch 873/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9809 - accuracy: 0.5327 - val_loss: 0.8740 - val_accuracy: 0.5000\n",
      "Epoch 874/3000\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.9411 - accuracy: 0.5576 - val_loss: 0.8745 - val_accuracy: 0.5000\n",
      "Epoch 875/3000\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.9360 - accuracy: 0.5421 - val_loss: 0.8429 - val_accuracy: 0.5500\n",
      "Epoch 876/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9318 - accuracy: 0.5483 - val_loss: 0.8450 - val_accuracy: 0.5625\n",
      "Epoch 877/3000\n",
      "8/8 [==============================] - 2s 250ms/step - loss: 0.9711 - accuracy: 0.5265 - val_loss: 0.8533 - val_accuracy: 0.5375\n",
      "Epoch 878/3000\n",
      "8/8 [==============================] - 2s 254ms/step - loss: 0.9391 - accuracy: 0.5452 - val_loss: 0.8511 - val_accuracy: 0.5375\n",
      "Epoch 879/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9539 - accuracy: 0.5327 - val_loss: 0.8701 - val_accuracy: 0.5125\n",
      "Epoch 880/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9441 - accuracy: 0.5234 - val_loss: 0.8618 - val_accuracy: 0.5500\n",
      "Epoch 881/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9571 - accuracy: 0.5327 - val_loss: 0.8648 - val_accuracy: 0.5500\n",
      "Epoch 882/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9177 - accuracy: 0.5701 - val_loss: 0.8669 - val_accuracy: 0.5125\n",
      "Epoch 883/3000\n",
      "8/8 [==============================] - 2s 235ms/step - loss: 0.9160 - accuracy: 0.5545 - val_loss: 0.8530 - val_accuracy: 0.5625\n",
      "Epoch 884/3000\n",
      "8/8 [==============================] - 2s 251ms/step - loss: 0.9480 - accuracy: 0.5265 - val_loss: 0.8947 - val_accuracy: 0.4875\n",
      "Epoch 885/3000\n",
      "8/8 [==============================] - 2s 240ms/step - loss: 0.9398 - accuracy: 0.5452 - val_loss: 0.8696 - val_accuracy: 0.5250\n",
      "Epoch 886/3000\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 0.9522 - accuracy: 0.5514 - val_loss: 0.8564 - val_accuracy: 0.5500\n",
      "Epoch 887/3000\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.9535 - accuracy: 0.5452 - val_loss: 0.8792 - val_accuracy: 0.5000\n",
      "Epoch 888/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9648 - accuracy: 0.5202 - val_loss: 0.8655 - val_accuracy: 0.5500\n",
      "Epoch 889/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9136 - accuracy: 0.5576 - val_loss: 0.8538 - val_accuracy: 0.5500\n",
      "Epoch 890/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9980 - accuracy: 0.5140 - val_loss: 0.8751 - val_accuracy: 0.5500\n",
      "Epoch 891/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9439 - accuracy: 0.5358 - val_loss: 0.8689 - val_accuracy: 0.5750\n",
      "Epoch 892/3000\n",
      "8/8 [==============================] - 2s 238ms/step - loss: 0.9570 - accuracy: 0.5140 - val_loss: 0.8809 - val_accuracy: 0.5125\n",
      "Epoch 893/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9646 - accuracy: 0.5140 - val_loss: 0.8609 - val_accuracy: 0.5500\n",
      "Epoch 894/3000\n",
      "8/8 [==============================] - 2s 253ms/step - loss: 0.9478 - accuracy: 0.5140 - val_loss: 0.8902 - val_accuracy: 0.5125\n",
      "Epoch 895/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9437 - accuracy: 0.5358 - val_loss: 0.8736 - val_accuracy: 0.5125\n",
      "Epoch 896/3000\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 0.9536 - accuracy: 0.5452 - val_loss: 0.9058 - val_accuracy: 0.4750\n",
      "Epoch 897/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9671 - accuracy: 0.5171 - val_loss: 0.8642 - val_accuracy: 0.5500\n",
      "Epoch 898/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9440 - accuracy: 0.5296 - val_loss: 0.8866 - val_accuracy: 0.5000\n",
      "Epoch 899/3000\n",
      "8/8 [==============================] - 2s 249ms/step - loss: 0.9490 - accuracy: 0.5296 - val_loss: 0.8576 - val_accuracy: 0.5250\n",
      "Epoch 900/3000\n",
      "8/8 [==============================] - 2s 244ms/step - loss: 0.9763 - accuracy: 0.5140 - val_loss: 0.8605 - val_accuracy: 0.5500\n",
      "Epoch 901/3000\n",
      "8/8 [==============================] - 2s 245ms/step - loss: 0.9460 - accuracy: 0.5545 - val_loss: 0.8592 - val_accuracy: 0.5375\n",
      "Epoch 902/3000\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 0.9546 - accuracy: 0.5389 - val_loss: 0.8572 - val_accuracy: 0.5625\n",
      "Epoch 903/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9496 - accuracy: 0.5607 - val_loss: 0.8954 - val_accuracy: 0.5000\n",
      "Epoch 904/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9428 - accuracy: 0.5545 - val_loss: 0.9085 - val_accuracy: 0.4500\n",
      "Epoch 905/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9635 - accuracy: 0.5234 - val_loss: 0.8664 - val_accuracy: 0.5250\n",
      "Epoch 906/3000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.9567 - accuracy: 0.5639 - val_loss: 0.9236 - val_accuracy: 0.4625\n",
      "Epoch 907/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9607 - accuracy: 0.5389 - val_loss: 0.8792 - val_accuracy: 0.5125\n",
      "Epoch 908/3000\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 0.9370 - accuracy: 0.5171 - val_loss: 0.8694 - val_accuracy: 0.5250\n",
      "Epoch 909/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9392 - accuracy: 0.5576 - val_loss: 0.8620 - val_accuracy: 0.5125\n",
      "Epoch 910/3000\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.9385 - accuracy: 0.5389 - val_loss: 0.8558 - val_accuracy: 0.5250\n",
      "Epoch 911/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9666 - accuracy: 0.5234 - val_loss: 0.8377 - val_accuracy: 0.5500\n",
      "Epoch 912/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9364 - accuracy: 0.5265 - val_loss: 0.8472 - val_accuracy: 0.5500\n",
      "Epoch 913/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9289 - accuracy: 0.5701 - val_loss: 0.9034 - val_accuracy: 0.4750\n",
      "Epoch 914/3000\n",
      "8/8 [==============================] - 2s 237ms/step - loss: 0.9149 - accuracy: 0.5545 - val_loss: 0.8624 - val_accuracy: 0.5000\n",
      "Epoch 915/3000\n",
      "8/8 [==============================] - 2s 250ms/step - loss: 0.9593 - accuracy: 0.5389 - val_loss: 0.8542 - val_accuracy: 0.5375\n",
      "Epoch 916/3000\n",
      "8/8 [==============================] - 2s 245ms/step - loss: 0.9709 - accuracy: 0.5234 - val_loss: 0.8683 - val_accuracy: 0.5250\n",
      "Epoch 917/3000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.9409 - accuracy: 0.5483 - val_loss: 0.8829 - val_accuracy: 0.5375\n",
      "Epoch 918/3000\n",
      "8/8 [==============================] - 2s 257ms/step - loss: 0.9664 - accuracy: 0.5234 - val_loss: 0.8649 - val_accuracy: 0.5625\n",
      "Epoch 919/3000\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 0.9642 - accuracy: 0.5202 - val_loss: 0.8656 - val_accuracy: 0.5250\n",
      "Epoch 920/3000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.9489 - accuracy: 0.5576 - val_loss: 0.8913 - val_accuracy: 0.4875\n",
      "Epoch 921/3000\n",
      "8/8 [==============================] - 2s 235ms/step - loss: 0.9501 - accuracy: 0.5545 - val_loss: 0.8740 - val_accuracy: 0.5250\n",
      "Epoch 922/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9714 - accuracy: 0.5140 - val_loss: 0.8751 - val_accuracy: 0.5125\n",
      "Epoch 923/3000\n",
      "8/8 [==============================] - 2s 237ms/step - loss: 0.9433 - accuracy: 0.5732 - val_loss: 0.8563 - val_accuracy: 0.5375\n",
      "Epoch 924/3000\n",
      "8/8 [==============================] - 2s 259ms/step - loss: 0.9423 - accuracy: 0.5421 - val_loss: 0.8730 - val_accuracy: 0.5125\n",
      "Epoch 925/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9409 - accuracy: 0.5452 - val_loss: 0.8664 - val_accuracy: 0.5500\n",
      "Epoch 926/3000\n",
      "8/8 [==============================] - 2s 203ms/step - loss: 0.9516 - accuracy: 0.5389 - val_loss: 0.8751 - val_accuracy: 0.5125\n",
      "Epoch 927/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9685 - accuracy: 0.5296 - val_loss: 0.8942 - val_accuracy: 0.5000\n",
      "Epoch 928/3000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.9391 - accuracy: 0.5514 - val_loss: 0.8923 - val_accuracy: 0.4750\n",
      "Epoch 929/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9487 - accuracy: 0.5545 - val_loss: 0.8735 - val_accuracy: 0.5500\n",
      "Epoch 930/3000\n",
      "8/8 [==============================] - 2s 235ms/step - loss: 0.9368 - accuracy: 0.5452 - val_loss: 0.8672 - val_accuracy: 0.5125\n",
      "Epoch 931/3000\n",
      "8/8 [==============================] - 2s 248ms/step - loss: 0.9184 - accuracy: 0.5576 - val_loss: 0.8478 - val_accuracy: 0.5500\n",
      "Epoch 932/3000\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 0.9211 - accuracy: 0.5607 - val_loss: 0.8580 - val_accuracy: 0.5375\n",
      "Epoch 933/3000\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.9595 - accuracy: 0.5452 - val_loss: 0.8615 - val_accuracy: 0.5125\n",
      "Epoch 934/3000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.9515 - accuracy: 0.5389 - val_loss: 0.8572 - val_accuracy: 0.5250\n",
      "Epoch 935/3000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.9476 - accuracy: 0.5265 - val_loss: 0.8518 - val_accuracy: 0.5375\n",
      "Epoch 936/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.9665 - accuracy: 0.5296 - val_loss: 0.8617 - val_accuracy: 0.5375\n",
      "Epoch 937/3000\n",
      "8/8 [==============================] - 2s 239ms/step - loss: 0.9627 - accuracy: 0.5358 - val_loss: 0.8845 - val_accuracy: 0.5000\n",
      "Epoch 938/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9676 - accuracy: 0.5327 - val_loss: 0.8701 - val_accuracy: 0.5500\n",
      "Epoch 939/3000\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.9188 - accuracy: 0.5670 - val_loss: 0.8550 - val_accuracy: 0.5250\n",
      "Epoch 940/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.9389 - accuracy: 0.5514 - val_loss: 0.8803 - val_accuracy: 0.5125\n",
      "Epoch 941/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9802 - accuracy: 0.5327 - val_loss: 0.8501 - val_accuracy: 0.5375\n",
      "Epoch 942/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9416 - accuracy: 0.5296 - val_loss: 0.9400 - val_accuracy: 0.4625\n",
      "Epoch 943/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9546 - accuracy: 0.5327 - val_loss: 0.8619 - val_accuracy: 0.5500\n",
      "Epoch 944/3000\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 0.9532 - accuracy: 0.5296 - val_loss: 0.8779 - val_accuracy: 0.5375\n",
      "Epoch 945/3000\n",
      "8/8 [==============================] - 2s 262ms/step - loss: 0.9528 - accuracy: 0.5514 - val_loss: 0.8587 - val_accuracy: 0.5375\n",
      "Epoch 946/3000\n",
      "8/8 [==============================] - 2s 261ms/step - loss: 0.9648 - accuracy: 0.5234 - val_loss: 0.8645 - val_accuracy: 0.5375\n",
      "Epoch 947/3000\n",
      "8/8 [==============================] - 2s 254ms/step - loss: 0.9379 - accuracy: 0.5483 - val_loss: 0.8728 - val_accuracy: 0.5500\n",
      "Epoch 948/3000\n",
      "8/8 [==============================] - 2s 268ms/step - loss: 0.9066 - accuracy: 0.5670 - val_loss: 0.8709 - val_accuracy: 0.5375\n",
      "Epoch 949/3000\n",
      "8/8 [==============================] - 2s 264ms/step - loss: 0.9592 - accuracy: 0.5327 - val_loss: 0.8689 - val_accuracy: 0.5500\n",
      "Epoch 950/3000\n",
      "8/8 [==============================] - 2s 260ms/step - loss: 0.9237 - accuracy: 0.5514 - val_loss: 0.8841 - val_accuracy: 0.5250\n",
      "Epoch 951/3000\n",
      "8/8 [==============================] - 2s 239ms/step - loss: 0.9091 - accuracy: 0.5514 - val_loss: 0.9124 - val_accuracy: 0.4875\n",
      "Epoch 952/3000\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 0.9264 - accuracy: 0.5514 - val_loss: 0.8689 - val_accuracy: 0.5375\n",
      "Epoch 953/3000\n",
      "8/8 [==============================] - 2s 269ms/step - loss: 0.9386 - accuracy: 0.5514 - val_loss: 0.9196 - val_accuracy: 0.4750\n",
      "Epoch 954/3000\n",
      "8/8 [==============================] - 2s 272ms/step - loss: 0.9635 - accuracy: 0.5296 - val_loss: 0.8730 - val_accuracy: 0.5375\n",
      "Epoch 955/3000\n",
      "8/8 [==============================] - 2s 263ms/step - loss: 0.9354 - accuracy: 0.5358 - val_loss: 0.8643 - val_accuracy: 0.5500\n",
      "Epoch 956/3000\n",
      "8/8 [==============================] - 2s 239ms/step - loss: 0.9300 - accuracy: 0.5421 - val_loss: 0.8505 - val_accuracy: 0.5750\n",
      "Epoch 957/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9418 - accuracy: 0.5670 - val_loss: 0.8563 - val_accuracy: 0.5375\n",
      "Epoch 958/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.9349 - accuracy: 0.5732 - val_loss: 0.8450 - val_accuracy: 0.5500\n",
      "Epoch 959/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9293 - accuracy: 0.5732 - val_loss: 0.8592 - val_accuracy: 0.5625\n",
      "Epoch 960/3000\n",
      "8/8 [==============================] - 2s 256ms/step - loss: 0.9052 - accuracy: 0.5763 - val_loss: 0.9278 - val_accuracy: 0.4625\n",
      "Epoch 961/3000\n",
      "8/8 [==============================] - 2s 245ms/step - loss: 0.9424 - accuracy: 0.5202 - val_loss: 0.8620 - val_accuracy: 0.5500\n",
      "Epoch 962/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9235 - accuracy: 0.5514 - val_loss: 0.8914 - val_accuracy: 0.5000\n",
      "Epoch 963/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9447 - accuracy: 0.5389 - val_loss: 0.8728 - val_accuracy: 0.5125\n",
      "Epoch 964/3000\n",
      "8/8 [==============================] - 2s 257ms/step - loss: 0.9495 - accuracy: 0.5358 - val_loss: 0.8829 - val_accuracy: 0.5000\n",
      "Epoch 965/3000\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 0.9496 - accuracy: 0.5265 - val_loss: 0.8690 - val_accuracy: 0.5625\n",
      "Epoch 966/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9530 - accuracy: 0.5483 - val_loss: 0.8685 - val_accuracy: 0.5500\n",
      "Epoch 967/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9140 - accuracy: 0.5639 - val_loss: 0.8474 - val_accuracy: 0.5250\n",
      "Epoch 968/3000\n",
      "8/8 [==============================] - 2s 252ms/step - loss: 0.9448 - accuracy: 0.5265 - val_loss: 0.8620 - val_accuracy: 0.5500\n",
      "Epoch 969/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9099 - accuracy: 0.5670 - val_loss: 0.8594 - val_accuracy: 0.5500\n",
      "Epoch 970/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9556 - accuracy: 0.5452 - val_loss: 0.8677 - val_accuracy: 0.5625\n",
      "Epoch 971/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.9206 - accuracy: 0.5514 - val_loss: 0.8562 - val_accuracy: 0.5625\n",
      "Epoch 972/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9609 - accuracy: 0.5452 - val_loss: 0.8585 - val_accuracy: 0.5625\n",
      "Epoch 973/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9663 - accuracy: 0.5140 - val_loss: 0.8729 - val_accuracy: 0.5500\n",
      "Epoch 974/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.9572 - accuracy: 0.5421 - val_loss: 0.8883 - val_accuracy: 0.5000\n",
      "Epoch 975/3000\n",
      "8/8 [==============================] - 2s 244ms/step - loss: 0.9412 - accuracy: 0.5421 - val_loss: 0.8710 - val_accuracy: 0.5000\n",
      "Epoch 976/3000\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.9446 - accuracy: 0.5607 - val_loss: 0.8482 - val_accuracy: 0.5500\n",
      "Epoch 977/3000\n",
      "8/8 [==============================] - 2s 244ms/step - loss: 0.9495 - accuracy: 0.5514 - val_loss: 0.8553 - val_accuracy: 0.5375\n",
      "Epoch 978/3000\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 0.9340 - accuracy: 0.5483 - val_loss: 0.8537 - val_accuracy: 0.5500\n",
      "Epoch 979/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9397 - accuracy: 0.5327 - val_loss: 0.8650 - val_accuracy: 0.5500\n",
      "Epoch 980/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9561 - accuracy: 0.5296 - val_loss: 0.8747 - val_accuracy: 0.5000\n",
      "Epoch 981/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9461 - accuracy: 0.5483 - val_loss: 0.8495 - val_accuracy: 0.5500\n",
      "Epoch 982/3000\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.9222 - accuracy: 0.5670 - val_loss: 0.8490 - val_accuracy: 0.5250\n",
      "Epoch 983/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.9482 - accuracy: 0.5234 - val_loss: 0.8838 - val_accuracy: 0.4750\n",
      "Epoch 984/3000\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.9365 - accuracy: 0.5421 - val_loss: 0.8723 - val_accuracy: 0.4875\n",
      "Epoch 985/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9536 - accuracy: 0.5452 - val_loss: 0.8636 - val_accuracy: 0.5500\n",
      "Epoch 986/3000\n",
      "8/8 [==============================] - 2s 252ms/step - loss: 0.9334 - accuracy: 0.5607 - val_loss: 0.8607 - val_accuracy: 0.5125\n",
      "Epoch 987/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.9132 - accuracy: 0.5514 - val_loss: 0.8590 - val_accuracy: 0.5375\n",
      "Epoch 988/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.9375 - accuracy: 0.5701 - val_loss: 0.8633 - val_accuracy: 0.5000\n",
      "Epoch 989/3000\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 0.9313 - accuracy: 0.5452 - val_loss: 0.8581 - val_accuracy: 0.5500\n",
      "Epoch 990/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9290 - accuracy: 0.5483 - val_loss: 0.8496 - val_accuracy: 0.5500\n",
      "Epoch 991/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.9538 - accuracy: 0.5358 - val_loss: 0.8696 - val_accuracy: 0.5500\n",
      "Epoch 992/3000\n",
      "8/8 [==============================] - 2s 269ms/step - loss: 0.9127 - accuracy: 0.5421 - val_loss: 0.8562 - val_accuracy: 0.5500\n",
      "Epoch 993/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.9304 - accuracy: 0.5358 - val_loss: 0.8669 - val_accuracy: 0.4875\n",
      "Epoch 994/3000\n",
      "8/8 [==============================] - 2s 247ms/step - loss: 0.9492 - accuracy: 0.5327 - val_loss: 0.8805 - val_accuracy: 0.4875\n",
      "Epoch 995/3000\n",
      "8/8 [==============================] - 2s 181ms/step - loss: 0.9616 - accuracy: 0.5202 - val_loss: 0.8625 - val_accuracy: 0.5125\n",
      "Epoch 996/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9484 - accuracy: 0.5296 - val_loss: 0.8775 - val_accuracy: 0.5375\n",
      "Epoch 997/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.9548 - accuracy: 0.5514 - val_loss: 0.8592 - val_accuracy: 0.5500\n",
      "Epoch 998/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9439 - accuracy: 0.5389 - val_loss: 0.8701 - val_accuracy: 0.5250\n",
      "Epoch 999/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9195 - accuracy: 0.5607 - val_loss: 0.8443 - val_accuracy: 0.5500\n",
      "Epoch 1000/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.9810 - accuracy: 0.5078 - val_loss: 0.8552 - val_accuracy: 0.5250\n",
      "Epoch 1001/3000\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.9317 - accuracy: 0.5452 - val_loss: 0.8499 - val_accuracy: 0.5500\n",
      "Epoch 1002/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.9158 - accuracy: 0.5483 - val_loss: 0.8483 - val_accuracy: 0.5125\n",
      "Epoch 1003/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.9312 - accuracy: 0.5358 - val_loss: 0.8534 - val_accuracy: 0.5125\n",
      "Epoch 1004/3000\n",
      "8/8 [==============================] - 1s 182ms/step - loss: 0.9354 - accuracy: 0.5545 - val_loss: 0.8585 - val_accuracy: 0.5375\n",
      "Epoch 1005/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9471 - accuracy: 0.5265 - val_loss: 0.8649 - val_accuracy: 0.5500\n",
      "Epoch 1006/3000\n",
      "8/8 [==============================] - 1s 183ms/step - loss: 0.9392 - accuracy: 0.5701 - val_loss: 0.9078 - val_accuracy: 0.5000\n",
      "Epoch 1007/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.9214 - accuracy: 0.5389 - val_loss: 0.8624 - val_accuracy: 0.5500\n",
      "Epoch 1008/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.9164 - accuracy: 0.5265 - val_loss: 0.8892 - val_accuracy: 0.5000\n",
      "Epoch 1009/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.9512 - accuracy: 0.5296 - val_loss: 0.8640 - val_accuracy: 0.5500\n",
      "Epoch 1010/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.9580 - accuracy: 0.5171 - val_loss: 0.8860 - val_accuracy: 0.5375\n",
      "Epoch 1011/3000\n",
      "8/8 [==============================] - 1s 181ms/step - loss: 0.9239 - accuracy: 0.5514 - val_loss: 0.8596 - val_accuracy: 0.5250\n",
      "Epoch 1012/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.9457 - accuracy: 0.5483 - val_loss: 0.8641 - val_accuracy: 0.5250\n",
      "Epoch 1013/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.9274 - accuracy: 0.5545 - val_loss: 0.8604 - val_accuracy: 0.5125\n",
      "Epoch 1014/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.9570 - accuracy: 0.5140 - val_loss: 0.8668 - val_accuracy: 0.5250\n",
      "Epoch 1015/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.9489 - accuracy: 0.5607 - val_loss: 0.8841 - val_accuracy: 0.5000\n",
      "Epoch 1016/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.9138 - accuracy: 0.5639 - val_loss: 0.8618 - val_accuracy: 0.5375\n",
      "Epoch 1017/3000\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.9323 - accuracy: 0.5327 - val_loss: 0.8950 - val_accuracy: 0.5250\n",
      "Epoch 1018/3000\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.9413 - accuracy: 0.5576 - val_loss: 0.8635 - val_accuracy: 0.5375\n",
      "Epoch 1019/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9381 - accuracy: 0.5452 - val_loss: 0.8578 - val_accuracy: 0.5375\n",
      "Epoch 1020/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9254 - accuracy: 0.5576 - val_loss: 0.8600 - val_accuracy: 0.5250\n",
      "Epoch 1021/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.9256 - accuracy: 0.5483 - val_loss: 0.8522 - val_accuracy: 0.5125\n",
      "Epoch 1022/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.9075 - accuracy: 0.5514 - val_loss: 0.8737 - val_accuracy: 0.5000\n",
      "Epoch 1023/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9272 - accuracy: 0.5545 - val_loss: 0.8486 - val_accuracy: 0.5125\n",
      "Epoch 1024/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9176 - accuracy: 0.5545 - val_loss: 0.8835 - val_accuracy: 0.4750\n",
      "Epoch 1025/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.9456 - accuracy: 0.5234 - val_loss: 0.8878 - val_accuracy: 0.4750\n",
      "Epoch 1026/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9593 - accuracy: 0.5234 - val_loss: 0.8619 - val_accuracy: 0.5125\n",
      "Epoch 1027/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.9366 - accuracy: 0.5452 - val_loss: 0.8822 - val_accuracy: 0.5000\n",
      "Epoch 1028/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.9347 - accuracy: 0.5421 - val_loss: 0.9026 - val_accuracy: 0.4875\n",
      "Epoch 1029/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9449 - accuracy: 0.5421 - val_loss: 0.8622 - val_accuracy: 0.5375\n",
      "Epoch 1030/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9198 - accuracy: 0.5514 - val_loss: 0.8625 - val_accuracy: 0.5500\n",
      "Epoch 1031/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9315 - accuracy: 0.5234 - val_loss: 0.8558 - val_accuracy: 0.5125\n",
      "Epoch 1032/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.9344 - accuracy: 0.5234 - val_loss: 0.8615 - val_accuracy: 0.5375\n",
      "Epoch 1033/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.9095 - accuracy: 0.5701 - val_loss: 0.8468 - val_accuracy: 0.5250\n",
      "Epoch 1034/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.9507 - accuracy: 0.5607 - val_loss: 0.8736 - val_accuracy: 0.5000\n",
      "Epoch 1035/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.9370 - accuracy: 0.5670 - val_loss: 0.8556 - val_accuracy: 0.5250\n",
      "Epoch 1036/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9230 - accuracy: 0.5514 - val_loss: 0.8479 - val_accuracy: 0.5250\n",
      "Epoch 1037/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.9587 - accuracy: 0.5421 - val_loss: 0.8659 - val_accuracy: 0.5375\n",
      "Epoch 1038/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.9034 - accuracy: 0.5826 - val_loss: 0.8575 - val_accuracy: 0.5375\n",
      "Epoch 1039/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.9393 - accuracy: 0.5358 - val_loss: 0.8624 - val_accuracy: 0.5250\n",
      "Epoch 1040/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.9695 - accuracy: 0.5265 - val_loss: 0.8597 - val_accuracy: 0.5250\n",
      "Epoch 1041/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.9247 - accuracy: 0.5327 - val_loss: 0.8556 - val_accuracy: 0.5250\n",
      "Epoch 1042/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.9492 - accuracy: 0.5639 - val_loss: 0.8585 - val_accuracy: 0.5250\n",
      "Epoch 1043/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.9367 - accuracy: 0.5327 - val_loss: 0.8588 - val_accuracy: 0.5375\n",
      "Epoch 1044/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9520 - accuracy: 0.5109 - val_loss: 0.8592 - val_accuracy: 0.5250\n",
      "Epoch 1045/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.9279 - accuracy: 0.5576 - val_loss: 0.8479 - val_accuracy: 0.5375\n",
      "Epoch 1046/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.9552 - accuracy: 0.5389 - val_loss: 0.8454 - val_accuracy: 0.5250\n",
      "Epoch 1047/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.9228 - accuracy: 0.5576 - val_loss: 0.8380 - val_accuracy: 0.5125\n",
      "Epoch 1048/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9341 - accuracy: 0.5234 - val_loss: 0.8426 - val_accuracy: 0.5250\n",
      "Epoch 1049/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.9297 - accuracy: 0.5701 - val_loss: 0.8356 - val_accuracy: 0.5375\n",
      "Epoch 1050/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9156 - accuracy: 0.5576 - val_loss: 0.8425 - val_accuracy: 0.5375\n",
      "Epoch 1051/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9523 - accuracy: 0.5358 - val_loss: 0.8456 - val_accuracy: 0.5250\n",
      "Epoch 1052/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9219 - accuracy: 0.5389 - val_loss: 0.8335 - val_accuracy: 0.5250\n",
      "Epoch 1053/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9634 - accuracy: 0.5421 - val_loss: 0.8492 - val_accuracy: 0.5250\n",
      "Epoch 1054/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.9589 - accuracy: 0.5483 - val_loss: 0.8559 - val_accuracy: 0.5250\n",
      "Epoch 1055/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9377 - accuracy: 0.5389 - val_loss: 0.8478 - val_accuracy: 0.5125\n",
      "Epoch 1056/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.9021 - accuracy: 0.5732 - val_loss: 0.8524 - val_accuracy: 0.5250\n",
      "Epoch 1057/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9443 - accuracy: 0.5389 - val_loss: 0.8589 - val_accuracy: 0.5125\n",
      "Epoch 1058/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9387 - accuracy: 0.5296 - val_loss: 0.8982 - val_accuracy: 0.4750\n",
      "Epoch 1059/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.9203 - accuracy: 0.5389 - val_loss: 0.8962 - val_accuracy: 0.4750\n",
      "Epoch 1060/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9518 - accuracy: 0.5358 - val_loss: 0.8596 - val_accuracy: 0.5250\n",
      "Epoch 1061/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.9286 - accuracy: 0.5607 - val_loss: 0.8613 - val_accuracy: 0.5125\n",
      "Epoch 1062/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.9251 - accuracy: 0.5545 - val_loss: 0.9213 - val_accuracy: 0.4750\n",
      "Epoch 1063/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.9224 - accuracy: 0.5576 - val_loss: 0.8518 - val_accuracy: 0.5000\n",
      "Epoch 1064/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.9440 - accuracy: 0.5514 - val_loss: 0.8608 - val_accuracy: 0.5375\n",
      "Epoch 1065/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.9620 - accuracy: 0.4984 - val_loss: 0.8803 - val_accuracy: 0.4875\n",
      "Epoch 1066/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.9025 - accuracy: 0.5639 - val_loss: 0.8648 - val_accuracy: 0.5375\n",
      "Epoch 1067/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.9423 - accuracy: 0.5545 - val_loss: 0.8479 - val_accuracy: 0.5250\n",
      "Epoch 1068/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.9469 - accuracy: 0.5545 - val_loss: 0.8601 - val_accuracy: 0.5250\n",
      "Epoch 1069/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9295 - accuracy: 0.5296 - val_loss: 0.8502 - val_accuracy: 0.5125\n",
      "Epoch 1070/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.9548 - accuracy: 0.5265 - val_loss: 0.8735 - val_accuracy: 0.5000\n",
      "Epoch 1071/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.9315 - accuracy: 0.5514 - val_loss: 0.8784 - val_accuracy: 0.5125\n",
      "Epoch 1072/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9402 - accuracy: 0.5545 - val_loss: 0.8716 - val_accuracy: 0.5000\n",
      "Epoch 1073/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9299 - accuracy: 0.5576 - val_loss: 0.8626 - val_accuracy: 0.5375\n",
      "Epoch 1074/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9294 - accuracy: 0.5265 - val_loss: 0.8590 - val_accuracy: 0.5375\n",
      "Epoch 1075/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9446 - accuracy: 0.5265 - val_loss: 0.8609 - val_accuracy: 0.5250\n",
      "Epoch 1076/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.9317 - accuracy: 0.5358 - val_loss: 0.8645 - val_accuracy: 0.5125\n",
      "Epoch 1077/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.9304 - accuracy: 0.5421 - val_loss: 0.8556 - val_accuracy: 0.5125\n",
      "Epoch 1078/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.9388 - accuracy: 0.5421 - val_loss: 0.8642 - val_accuracy: 0.5250\n",
      "Epoch 1079/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9287 - accuracy: 0.5607 - val_loss: 0.8732 - val_accuracy: 0.5000\n",
      "Epoch 1080/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.9466 - accuracy: 0.5514 - val_loss: 0.8750 - val_accuracy: 0.5000\n",
      "Epoch 1081/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.9707 - accuracy: 0.5078 - val_loss: 0.8664 - val_accuracy: 0.5250\n",
      "Epoch 1082/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9241 - accuracy: 0.5576 - val_loss: 0.8599 - val_accuracy: 0.5000\n",
      "Epoch 1083/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8961 - accuracy: 0.5701 - val_loss: 0.8628 - val_accuracy: 0.5250\n",
      "Epoch 1084/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.9447 - accuracy: 0.5265 - val_loss: 0.8630 - val_accuracy: 0.5250\n",
      "Epoch 1085/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.9199 - accuracy: 0.5452 - val_loss: 0.8758 - val_accuracy: 0.5125\n",
      "Epoch 1086/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.9288 - accuracy: 0.5452 - val_loss: 0.8571 - val_accuracy: 0.5250\n",
      "Epoch 1087/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.9441 - accuracy: 0.5545 - val_loss: 0.8711 - val_accuracy: 0.5000\n",
      "Epoch 1088/3000\n",
      "8/8 [==============================] - 1s 182ms/step - loss: 0.9497 - accuracy: 0.5358 - val_loss: 0.8484 - val_accuracy: 0.5125\n",
      "Epoch 1089/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.9459 - accuracy: 0.5389 - val_loss: 0.8743 - val_accuracy: 0.5000\n",
      "Epoch 1090/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9431 - accuracy: 0.5483 - val_loss: 0.8870 - val_accuracy: 0.4875\n",
      "Epoch 1091/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.9260 - accuracy: 0.5358 - val_loss: 0.8541 - val_accuracy: 0.5250\n",
      "Epoch 1092/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.9531 - accuracy: 0.5639 - val_loss: 0.8628 - val_accuracy: 0.5250\n",
      "Epoch 1093/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9579 - accuracy: 0.5265 - val_loss: 0.8586 - val_accuracy: 0.5250\n",
      "Epoch 1094/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8996 - accuracy: 0.5670 - val_loss: 0.8632 - val_accuracy: 0.5375\n",
      "Epoch 1095/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.9304 - accuracy: 0.5670 - val_loss: 0.8713 - val_accuracy: 0.5250\n",
      "Epoch 1096/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9403 - accuracy: 0.5234 - val_loss: 0.8640 - val_accuracy: 0.5250\n",
      "Epoch 1097/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.9408 - accuracy: 0.5576 - val_loss: 0.9020 - val_accuracy: 0.4875\n",
      "Epoch 1098/3000\n",
      "8/8 [==============================] - 1s 198ms/step - loss: 0.9421 - accuracy: 0.5327 - val_loss: 0.8661 - val_accuracy: 0.5250\n",
      "Epoch 1099/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.9396 - accuracy: 0.5358 - val_loss: 0.8631 - val_accuracy: 0.5250\n",
      "Epoch 1100/3000\n",
      "8/8 [==============================] - 1s 185ms/step - loss: 0.9291 - accuracy: 0.5421 - val_loss: 0.9046 - val_accuracy: 0.4750\n",
      "Epoch 1101/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.9695 - accuracy: 0.5296 - val_loss: 0.8728 - val_accuracy: 0.5250\n",
      "Epoch 1102/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.9191 - accuracy: 0.5452 - val_loss: 0.8695 - val_accuracy: 0.5125\n",
      "Epoch 1103/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.9255 - accuracy: 0.5514 - val_loss: 0.8557 - val_accuracy: 0.5125\n",
      "Epoch 1104/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.9537 - accuracy: 0.5452 - val_loss: 0.8499 - val_accuracy: 0.5125\n",
      "Epoch 1105/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.9287 - accuracy: 0.5421 - val_loss: 0.8748 - val_accuracy: 0.5125\n",
      "Epoch 1106/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9468 - accuracy: 0.5421 - val_loss: 0.8710 - val_accuracy: 0.5125\n",
      "Epoch 1107/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8878 - accuracy: 0.5732 - val_loss: 0.8595 - val_accuracy: 0.5375\n",
      "Epoch 1108/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.9482 - accuracy: 0.5358 - val_loss: 0.9166 - val_accuracy: 0.4875\n",
      "Epoch 1109/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.9517 - accuracy: 0.4984 - val_loss: 0.8562 - val_accuracy: 0.5125\n",
      "Epoch 1110/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.9290 - accuracy: 0.5701 - val_loss: 0.8604 - val_accuracy: 0.5375\n",
      "Epoch 1111/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.9125 - accuracy: 0.5639 - val_loss: 0.8534 - val_accuracy: 0.5375\n",
      "Epoch 1112/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9013 - accuracy: 0.5607 - val_loss: 0.8861 - val_accuracy: 0.4750\n",
      "Epoch 1113/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.9687 - accuracy: 0.5202 - val_loss: 0.8818 - val_accuracy: 0.5375\n",
      "Epoch 1114/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.9491 - accuracy: 0.5327 - val_loss: 0.8759 - val_accuracy: 0.5125\n",
      "Epoch 1115/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.9598 - accuracy: 0.5202 - val_loss: 0.8660 - val_accuracy: 0.5500\n",
      "Epoch 1116/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.9303 - accuracy: 0.5639 - val_loss: 0.8849 - val_accuracy: 0.4875\n",
      "Epoch 1117/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.9222 - accuracy: 0.5576 - val_loss: 0.8454 - val_accuracy: 0.5125\n",
      "Epoch 1118/3000\n",
      "8/8 [==============================] - 1s 186ms/step - loss: 0.9512 - accuracy: 0.5327 - val_loss: 0.8497 - val_accuracy: 0.5250\n",
      "Epoch 1119/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.9009 - accuracy: 0.5639 - val_loss: 0.9070 - val_accuracy: 0.4750\n",
      "Epoch 1120/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 0.9573 - accuracy: 0.5389 - val_loss: 0.8756 - val_accuracy: 0.5000\n",
      "Epoch 1121/3000\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.9472 - accuracy: 0.5483 - val_loss: 0.8479 - val_accuracy: 0.5125\n",
      "Epoch 1122/3000\n",
      "8/8 [==============================] - 1s 136ms/step - loss: 0.9493 - accuracy: 0.5639 - val_loss: 0.8439 - val_accuracy: 0.5250\n",
      "Epoch 1123/3000\n",
      "8/8 [==============================] - 1s 139ms/step - loss: 0.9441 - accuracy: 0.5514 - val_loss: 0.8616 - val_accuracy: 0.5125\n",
      "Epoch 1124/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9384 - accuracy: 0.5545 - val_loss: 0.8651 - val_accuracy: 0.5125\n",
      "Epoch 1125/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9370 - accuracy: 0.5452 - val_loss: 0.8738 - val_accuracy: 0.5000\n",
      "Epoch 1126/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.9960 - accuracy: 0.5327 - val_loss: 0.8608 - val_accuracy: 0.5500\n",
      "Epoch 1127/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9332 - accuracy: 0.5545 - val_loss: 0.8615 - val_accuracy: 0.5125\n",
      "Epoch 1128/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9392 - accuracy: 0.5576 - val_loss: 0.8889 - val_accuracy: 0.4875\n",
      "Epoch 1129/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9327 - accuracy: 0.5327 - val_loss: 0.8667 - val_accuracy: 0.5000\n",
      "Epoch 1130/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9632 - accuracy: 0.5171 - val_loss: 0.8679 - val_accuracy: 0.5250\n",
      "Epoch 1131/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9442 - accuracy: 0.5389 - val_loss: 0.8630 - val_accuracy: 0.5125\n",
      "Epoch 1132/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9444 - accuracy: 0.5327 - val_loss: 0.9046 - val_accuracy: 0.5000\n",
      "Epoch 1133/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9313 - accuracy: 0.5421 - val_loss: 0.8634 - val_accuracy: 0.5000\n",
      "Epoch 1134/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9119 - accuracy: 0.5639 - val_loss: 0.8541 - val_accuracy: 0.5250\n",
      "Epoch 1135/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9302 - accuracy: 0.5607 - val_loss: 0.8470 - val_accuracy: 0.5125\n",
      "Epoch 1136/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.9070 - accuracy: 0.5670 - val_loss: 0.8479 - val_accuracy: 0.5375\n",
      "Epoch 1137/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9477 - accuracy: 0.5265 - val_loss: 0.8485 - val_accuracy: 0.5250\n",
      "Epoch 1138/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9630 - accuracy: 0.5140 - val_loss: 0.8783 - val_accuracy: 0.5500\n",
      "Epoch 1139/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9479 - accuracy: 0.5171 - val_loss: 0.8883 - val_accuracy: 0.5500\n",
      "Epoch 1140/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9217 - accuracy: 0.5514 - val_loss: 0.8715 - val_accuracy: 0.4875\n",
      "Epoch 1141/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9243 - accuracy: 0.5452 - val_loss: 0.8938 - val_accuracy: 0.5250\n",
      "Epoch 1142/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.9562 - accuracy: 0.5265 - val_loss: 0.8459 - val_accuracy: 0.5250\n",
      "Epoch 1143/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.8890 - accuracy: 0.5639 - val_loss: 0.8624 - val_accuracy: 0.4750\n",
      "Epoch 1144/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.9059 - accuracy: 0.5639 - val_loss: 0.8638 - val_accuracy: 0.5000\n",
      "Epoch 1145/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9054 - accuracy: 0.5576 - val_loss: 0.8497 - val_accuracy: 0.5250\n",
      "Epoch 1146/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9428 - accuracy: 0.5389 - val_loss: 0.8572 - val_accuracy: 0.5000\n",
      "Epoch 1147/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9447 - accuracy: 0.5701 - val_loss: 0.8649 - val_accuracy: 0.5000\n",
      "Epoch 1148/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9143 - accuracy: 0.5826 - val_loss: 0.8566 - val_accuracy: 0.5500\n",
      "Epoch 1149/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9524 - accuracy: 0.5358 - val_loss: 0.8705 - val_accuracy: 0.5000\n",
      "Epoch 1150/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9089 - accuracy: 0.5576 - val_loss: 0.8601 - val_accuracy: 0.5375\n",
      "Epoch 1151/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9222 - accuracy: 0.5452 - val_loss: 0.8577 - val_accuracy: 0.5250\n",
      "Epoch 1152/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9246 - accuracy: 0.5514 - val_loss: 0.8642 - val_accuracy: 0.4875\n",
      "Epoch 1153/3000\n",
      "8/8 [==============================] - 1s 139ms/step - loss: 0.9457 - accuracy: 0.5358 - val_loss: 0.8577 - val_accuracy: 0.5125\n",
      "Epoch 1154/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9413 - accuracy: 0.5607 - val_loss: 0.8748 - val_accuracy: 0.5125\n",
      "Epoch 1155/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9409 - accuracy: 0.5389 - val_loss: 0.8629 - val_accuracy: 0.5250\n",
      "Epoch 1156/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9232 - accuracy: 0.5545 - val_loss: 0.8713 - val_accuracy: 0.5250\n",
      "Epoch 1157/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.9235 - accuracy: 0.5483 - val_loss: 0.8716 - val_accuracy: 0.5000\n",
      "Epoch 1158/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9254 - accuracy: 0.5296 - val_loss: 0.8601 - val_accuracy: 0.5375\n",
      "Epoch 1159/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9248 - accuracy: 0.5576 - val_loss: 0.8723 - val_accuracy: 0.4750\n",
      "Epoch 1160/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.9331 - accuracy: 0.5265 - val_loss: 0.8414 - val_accuracy: 0.5375\n",
      "Epoch 1161/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9291 - accuracy: 0.5639 - val_loss: 0.9047 - val_accuracy: 0.4625\n",
      "Epoch 1162/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 0.9068 - accuracy: 0.5794 - val_loss: 0.8464 - val_accuracy: 0.5375\n",
      "Epoch 1163/3000\n",
      "8/8 [==============================] - 1s 138ms/step - loss: 0.9353 - accuracy: 0.5421 - val_loss: 0.8434 - val_accuracy: 0.5375\n",
      "Epoch 1164/3000\n",
      "8/8 [==============================] - 1s 138ms/step - loss: 0.9354 - accuracy: 0.5421 - val_loss: 0.8541 - val_accuracy: 0.5125\n",
      "Epoch 1165/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 0.9190 - accuracy: 0.5639 - val_loss: 0.8632 - val_accuracy: 0.5375\n",
      "Epoch 1166/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8980 - accuracy: 0.5763 - val_loss: 0.8685 - val_accuracy: 0.5500\n",
      "Epoch 1167/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9396 - accuracy: 0.5389 - val_loss: 0.8501 - val_accuracy: 0.5000\n",
      "Epoch 1168/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9189 - accuracy: 0.5545 - val_loss: 0.8399 - val_accuracy: 0.5000\n",
      "Epoch 1169/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.8990 - accuracy: 0.5639 - val_loss: 0.8441 - val_accuracy: 0.5125\n",
      "Epoch 1170/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9280 - accuracy: 0.5514 - val_loss: 0.8451 - val_accuracy: 0.4875\n",
      "Epoch 1171/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 0.9414 - accuracy: 0.5421 - val_loss: 0.8411 - val_accuracy: 0.5000\n",
      "Epoch 1172/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9365 - accuracy: 0.5078 - val_loss: 0.8711 - val_accuracy: 0.5000\n",
      "Epoch 1173/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9432 - accuracy: 0.5514 - val_loss: 0.8463 - val_accuracy: 0.5000\n",
      "Epoch 1174/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9110 - accuracy: 0.5794 - val_loss: 0.8489 - val_accuracy: 0.5125\n",
      "Epoch 1175/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9136 - accuracy: 0.5576 - val_loss: 0.8467 - val_accuracy: 0.5000\n",
      "Epoch 1176/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9511 - accuracy: 0.5389 - val_loss: 0.8529 - val_accuracy: 0.5250\n",
      "Epoch 1177/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9305 - accuracy: 0.5358 - val_loss: 0.8616 - val_accuracy: 0.5250\n",
      "Epoch 1178/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9285 - accuracy: 0.5483 - val_loss: 0.8595 - val_accuracy: 0.5250\n",
      "Epoch 1179/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9502 - accuracy: 0.5140 - val_loss: 0.8604 - val_accuracy: 0.5500\n",
      "Epoch 1180/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9381 - accuracy: 0.5576 - val_loss: 0.8359 - val_accuracy: 0.5125\n",
      "Epoch 1181/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.9176 - accuracy: 0.5545 - val_loss: 0.8572 - val_accuracy: 0.5000\n",
      "Epoch 1182/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.9253 - accuracy: 0.5670 - val_loss: 0.8600 - val_accuracy: 0.5125\n",
      "Epoch 1183/3000\n",
      "8/8 [==============================] - 1s 139ms/step - loss: 0.9124 - accuracy: 0.5327 - val_loss: 0.8621 - val_accuracy: 0.5125\n",
      "Epoch 1184/3000\n",
      "8/8 [==============================] - 1s 138ms/step - loss: 0.9095 - accuracy: 0.5670 - val_loss: 0.8537 - val_accuracy: 0.5125\n",
      "Epoch 1185/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9515 - accuracy: 0.5452 - val_loss: 0.8955 - val_accuracy: 0.4750\n",
      "Epoch 1186/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9245 - accuracy: 0.5576 - val_loss: 0.8718 - val_accuracy: 0.5125\n",
      "Epoch 1187/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9290 - accuracy: 0.5607 - val_loss: 0.8568 - val_accuracy: 0.5000\n",
      "Epoch 1188/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9098 - accuracy: 0.5514 - val_loss: 0.8435 - val_accuracy: 0.5125\n",
      "Epoch 1189/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9041 - accuracy: 0.5296 - val_loss: 0.8877 - val_accuracy: 0.5000\n",
      "Epoch 1190/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.8986 - accuracy: 0.5670 - val_loss: 0.8576 - val_accuracy: 0.4875\n",
      "Epoch 1191/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.9482 - accuracy: 0.5234 - val_loss: 0.8582 - val_accuracy: 0.5125\n",
      "Epoch 1192/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9126 - accuracy: 0.5452 - val_loss: 0.8754 - val_accuracy: 0.5375\n",
      "Epoch 1193/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9348 - accuracy: 0.5296 - val_loss: 0.8770 - val_accuracy: 0.4750\n",
      "Epoch 1194/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 0.8994 - accuracy: 0.5607 - val_loss: 0.8565 - val_accuracy: 0.5375\n",
      "Epoch 1195/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.9448 - accuracy: 0.5483 - val_loss: 0.8677 - val_accuracy: 0.5375\n",
      "Epoch 1196/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9092 - accuracy: 0.5545 - val_loss: 0.8412 - val_accuracy: 0.5250\n",
      "Epoch 1197/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 0.9082 - accuracy: 0.5732 - val_loss: 0.8649 - val_accuracy: 0.5250\n",
      "Epoch 1198/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9388 - accuracy: 0.5483 - val_loss: 0.8798 - val_accuracy: 0.4750\n",
      "Epoch 1199/3000\n",
      "8/8 [==============================] - 1s 138ms/step - loss: 0.9226 - accuracy: 0.5389 - val_loss: 0.8558 - val_accuracy: 0.5375\n",
      "Epoch 1200/3000\n",
      "8/8 [==============================] - 1s 139ms/step - loss: 0.9391 - accuracy: 0.5452 - val_loss: 0.8731 - val_accuracy: 0.5375\n",
      "Epoch 1201/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9344 - accuracy: 0.5109 - val_loss: 0.8594 - val_accuracy: 0.5250\n",
      "Epoch 1202/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9161 - accuracy: 0.5576 - val_loss: 0.8528 - val_accuracy: 0.5375\n",
      "Epoch 1203/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9454 - accuracy: 0.5421 - val_loss: 0.8571 - val_accuracy: 0.5125\n",
      "Epoch 1204/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9380 - accuracy: 0.5327 - val_loss: 0.8618 - val_accuracy: 0.5375\n",
      "Epoch 1205/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9053 - accuracy: 0.5514 - val_loss: 0.8573 - val_accuracy: 0.5375\n",
      "Epoch 1206/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.8683 - accuracy: 0.5514 - val_loss: 0.8751 - val_accuracy: 0.5500\n",
      "Epoch 1207/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9269 - accuracy: 0.5607 - val_loss: 0.8446 - val_accuracy: 0.5000\n",
      "Epoch 1208/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9253 - accuracy: 0.5421 - val_loss: 0.8543 - val_accuracy: 0.5625\n",
      "Epoch 1209/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9152 - accuracy: 0.5576 - val_loss: 0.8547 - val_accuracy: 0.5125\n",
      "Epoch 1210/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.9146 - accuracy: 0.5576 - val_loss: 0.8584 - val_accuracy: 0.5125\n",
      "Epoch 1211/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9476 - accuracy: 0.5327 - val_loss: 0.8598 - val_accuracy: 0.5000\n",
      "Epoch 1212/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.8821 - accuracy: 0.5701 - val_loss: 0.9488 - val_accuracy: 0.4500\n",
      "Epoch 1213/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9183 - accuracy: 0.5483 - val_loss: 0.8582 - val_accuracy: 0.5250\n",
      "Epoch 1214/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9423 - accuracy: 0.5265 - val_loss: 0.8602 - val_accuracy: 0.5375\n",
      "Epoch 1215/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9510 - accuracy: 0.5171 - val_loss: 0.8533 - val_accuracy: 0.5250\n",
      "Epoch 1216/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9066 - accuracy: 0.5670 - val_loss: 0.8782 - val_accuracy: 0.4875\n",
      "Epoch 1217/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9384 - accuracy: 0.5389 - val_loss: 0.8624 - val_accuracy: 0.4875\n",
      "Epoch 1218/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9249 - accuracy: 0.5483 - val_loss: 0.8512 - val_accuracy: 0.5375\n",
      "Epoch 1219/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9457 - accuracy: 0.5483 - val_loss: 0.8787 - val_accuracy: 0.4875\n",
      "Epoch 1220/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.8989 - accuracy: 0.5670 - val_loss: 0.9106 - val_accuracy: 0.4750\n",
      "Epoch 1221/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9252 - accuracy: 0.5514 - val_loss: 0.8902 - val_accuracy: 0.5000\n",
      "Epoch 1222/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 0.9005 - accuracy: 0.5607 - val_loss: 0.8577 - val_accuracy: 0.5250\n",
      "Epoch 1223/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.8924 - accuracy: 0.5763 - val_loss: 0.8896 - val_accuracy: 0.4750\n",
      "Epoch 1224/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.9005 - accuracy: 0.5483 - val_loss: 0.9177 - val_accuracy: 0.4625\n",
      "Epoch 1225/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9486 - accuracy: 0.5296 - val_loss: 0.8692 - val_accuracy: 0.5000\n",
      "Epoch 1226/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.8989 - accuracy: 0.5607 - val_loss: 0.8540 - val_accuracy: 0.5250\n",
      "Epoch 1227/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9282 - accuracy: 0.5452 - val_loss: 0.8820 - val_accuracy: 0.5250\n",
      "Epoch 1228/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9305 - accuracy: 0.5701 - val_loss: 0.9022 - val_accuracy: 0.5250\n",
      "Epoch 1229/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9470 - accuracy: 0.5421 - val_loss: 0.8786 - val_accuracy: 0.5250\n",
      "Epoch 1230/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.9024 - accuracy: 0.5732 - val_loss: 0.8641 - val_accuracy: 0.5250\n",
      "Epoch 1231/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9202 - accuracy: 0.5327 - val_loss: 0.8791 - val_accuracy: 0.5250\n",
      "Epoch 1232/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9113 - accuracy: 0.5452 - val_loss: 0.9035 - val_accuracy: 0.5250\n",
      "Epoch 1233/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9315 - accuracy: 0.5421 - val_loss: 0.8785 - val_accuracy: 0.5125\n",
      "Epoch 1234/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9449 - accuracy: 0.5545 - val_loss: 0.8600 - val_accuracy: 0.5250\n",
      "Epoch 1235/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9298 - accuracy: 0.5358 - val_loss: 0.8691 - val_accuracy: 0.4875\n",
      "Epoch 1236/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9111 - accuracy: 0.5607 - val_loss: 0.8739 - val_accuracy: 0.5125\n",
      "Epoch 1237/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9433 - accuracy: 0.5171 - val_loss: 0.8564 - val_accuracy: 0.5250\n",
      "Epoch 1238/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9111 - accuracy: 0.5826 - val_loss: 0.8631 - val_accuracy: 0.5250\n",
      "Epoch 1239/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9338 - accuracy: 0.5389 - val_loss: 0.8909 - val_accuracy: 0.4750\n",
      "Epoch 1240/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9058 - accuracy: 0.5607 - val_loss: 0.8661 - val_accuracy: 0.5125\n",
      "Epoch 1241/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9040 - accuracy: 0.5607 - val_loss: 0.8492 - val_accuracy: 0.5250\n",
      "Epoch 1242/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9151 - accuracy: 0.5514 - val_loss: 0.8641 - val_accuracy: 0.5000\n",
      "Epoch 1243/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9002 - accuracy: 0.5607 - val_loss: 0.8687 - val_accuracy: 0.5125\n",
      "Epoch 1244/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9341 - accuracy: 0.5202 - val_loss: 0.9166 - val_accuracy: 0.4750\n",
      "Epoch 1245/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9210 - accuracy: 0.5327 - val_loss: 0.8571 - val_accuracy: 0.5125\n",
      "Epoch 1246/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9174 - accuracy: 0.5358 - val_loss: 0.8685 - val_accuracy: 0.4750\n",
      "Epoch 1247/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.8931 - accuracy: 0.5607 - val_loss: 0.9443 - val_accuracy: 0.4625\n",
      "Epoch 1248/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9459 - accuracy: 0.5202 - val_loss: 0.8652 - val_accuracy: 0.4750\n",
      "Epoch 1249/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 0.9140 - accuracy: 0.5545 - val_loss: 0.8908 - val_accuracy: 0.4625\n",
      "Epoch 1250/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9199 - accuracy: 0.5389 - val_loss: 0.8596 - val_accuracy: 0.5125\n",
      "Epoch 1251/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.8994 - accuracy: 0.5452 - val_loss: 0.9353 - val_accuracy: 0.4625\n",
      "Epoch 1252/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9439 - accuracy: 0.5514 - val_loss: 0.8512 - val_accuracy: 0.5250\n",
      "Epoch 1253/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9363 - accuracy: 0.5545 - val_loss: 0.8618 - val_accuracy: 0.5125\n",
      "Epoch 1254/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9030 - accuracy: 0.5483 - val_loss: 0.8672 - val_accuracy: 0.5250\n",
      "Epoch 1255/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9290 - accuracy: 0.5483 - val_loss: 0.8906 - val_accuracy: 0.5250\n",
      "Epoch 1256/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9162 - accuracy: 0.5607 - val_loss: 0.9526 - val_accuracy: 0.4750\n",
      "Epoch 1257/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9228 - accuracy: 0.5421 - val_loss: 0.8758 - val_accuracy: 0.5250\n",
      "Epoch 1258/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.9678 - accuracy: 0.5140 - val_loss: 0.8864 - val_accuracy: 0.4875\n",
      "Epoch 1259/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.9264 - accuracy: 0.5421 - val_loss: 0.8548 - val_accuracy: 0.5000\n",
      "Epoch 1260/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9054 - accuracy: 0.5794 - val_loss: 0.8581 - val_accuracy: 0.5125\n",
      "Epoch 1261/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.8925 - accuracy: 0.5701 - val_loss: 0.8774 - val_accuracy: 0.4750\n",
      "Epoch 1262/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9271 - accuracy: 0.5607 - val_loss: 0.8687 - val_accuracy: 0.5125\n",
      "Epoch 1263/3000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.8939 - accuracy: 0.5421 - val_loss: 0.9008 - val_accuracy: 0.4875\n",
      "Epoch 1264/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9187 - accuracy: 0.5639 - val_loss: 0.8462 - val_accuracy: 0.5500\n",
      "Epoch 1265/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9138 - accuracy: 0.5670 - val_loss: 0.8609 - val_accuracy: 0.5250\n",
      "Epoch 1266/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9122 - accuracy: 0.5639 - val_loss: 0.8615 - val_accuracy: 0.5125\n",
      "Epoch 1267/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9155 - accuracy: 0.5452 - val_loss: 0.8864 - val_accuracy: 0.5375\n",
      "Epoch 1268/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9356 - accuracy: 0.5358 - val_loss: 0.8748 - val_accuracy: 0.4875\n",
      "Epoch 1269/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9415 - accuracy: 0.5483 - val_loss: 0.8579 - val_accuracy: 0.5250\n",
      "Epoch 1270/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9061 - accuracy: 0.5545 - val_loss: 0.8529 - val_accuracy: 0.5125\n",
      "Epoch 1271/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.8947 - accuracy: 0.5857 - val_loss: 0.8553 - val_accuracy: 0.5250\n",
      "Epoch 1272/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 0.8973 - accuracy: 0.5857 - val_loss: 0.8857 - val_accuracy: 0.4625\n",
      "Epoch 1273/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.9108 - accuracy: 0.5514 - val_loss: 0.8468 - val_accuracy: 0.5250\n",
      "Epoch 1274/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.8800 - accuracy: 0.5514 - val_loss: 0.8548 - val_accuracy: 0.5000\n",
      "Epoch 1275/3000\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.9292 - accuracy: 0.5639 - val_loss: 0.8472 - val_accuracy: 0.5250\n",
      "Epoch 1276/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.9414 - accuracy: 0.5514 - val_loss: 0.8537 - val_accuracy: 0.5250\n",
      "Epoch 1277/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.8916 - accuracy: 0.5639 - val_loss: 0.8564 - val_accuracy: 0.4875\n",
      "Epoch 1278/3000\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.8961 - accuracy: 0.5826 - val_loss: 0.8883 - val_accuracy: 0.5000\n",
      "Epoch 1279/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9083 - accuracy: 0.5514 - val_loss: 0.8640 - val_accuracy: 0.5500\n",
      "Epoch 1280/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.9265 - accuracy: 0.5576 - val_loss: 0.8907 - val_accuracy: 0.4750\n",
      "Epoch 1281/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9068 - accuracy: 0.5701 - val_loss: 0.8769 - val_accuracy: 0.5500\n",
      "Epoch 1282/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9067 - accuracy: 0.5639 - val_loss: 0.8719 - val_accuracy: 0.4875\n",
      "Epoch 1283/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.8953 - accuracy: 0.5670 - val_loss: 0.8473 - val_accuracy: 0.5375\n",
      "Epoch 1284/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.9156 - accuracy: 0.5763 - val_loss: 0.8514 - val_accuracy: 0.4875\n",
      "Epoch 1285/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.9095 - accuracy: 0.5607 - val_loss: 0.8812 - val_accuracy: 0.4625\n",
      "Epoch 1286/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9355 - accuracy: 0.5607 - val_loss: 0.8544 - val_accuracy: 0.5375\n",
      "Epoch 1287/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.8975 - accuracy: 0.5639 - val_loss: 0.8711 - val_accuracy: 0.5125\n",
      "Epoch 1288/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.8671 - accuracy: 0.6012 - val_loss: 0.8989 - val_accuracy: 0.4625\n",
      "Epoch 1289/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 0.9451 - accuracy: 0.5389 - val_loss: 0.8679 - val_accuracy: 0.5125\n",
      "Epoch 1290/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9180 - accuracy: 0.5576 - val_loss: 0.8636 - val_accuracy: 0.5375\n",
      "Epoch 1291/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.9303 - accuracy: 0.5545 - val_loss: 0.8735 - val_accuracy: 0.5125\n",
      "Epoch 1292/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9438 - accuracy: 0.5358 - val_loss: 0.8671 - val_accuracy: 0.5000\n",
      "Epoch 1293/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9633 - accuracy: 0.5140 - val_loss: 0.8633 - val_accuracy: 0.5125\n",
      "Epoch 1294/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9040 - accuracy: 0.5576 - val_loss: 0.8493 - val_accuracy: 0.5000\n",
      "Epoch 1295/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9089 - accuracy: 0.5514 - val_loss: 0.8716 - val_accuracy: 0.5500\n",
      "Epoch 1296/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.9215 - accuracy: 0.5514 - val_loss: 0.8677 - val_accuracy: 0.5250\n",
      "Epoch 1297/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.8943 - accuracy: 0.5826 - val_loss: 0.8621 - val_accuracy: 0.4750\n",
      "Epoch 1298/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9119 - accuracy: 0.5358 - val_loss: 0.8590 - val_accuracy: 0.4875\n",
      "Epoch 1299/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9158 - accuracy: 0.5670 - val_loss: 0.8747 - val_accuracy: 0.5375\n",
      "Epoch 1300/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9546 - accuracy: 0.5452 - val_loss: 0.8758 - val_accuracy: 0.4875\n",
      "Epoch 1301/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9022 - accuracy: 0.5888 - val_loss: 0.8654 - val_accuracy: 0.5250\n",
      "Epoch 1302/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9596 - accuracy: 0.5296 - val_loss: 0.8855 - val_accuracy: 0.4750\n",
      "Epoch 1303/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.9215 - accuracy: 0.5607 - val_loss: 0.8646 - val_accuracy: 0.5125\n",
      "Epoch 1304/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.8996 - accuracy: 0.5670 - val_loss: 0.9055 - val_accuracy: 0.4625\n",
      "Epoch 1305/3000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.8835 - accuracy: 0.5389 - val_loss: 0.8698 - val_accuracy: 0.4875\n",
      "Epoch 1306/3000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 0.9079 - accuracy: 0.5763 - val_loss: 0.8771 - val_accuracy: 0.4750\n",
      "Epoch 1307/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.9055 - accuracy: 0.5732 - val_loss: 0.8779 - val_accuracy: 0.5000\n",
      "Epoch 1308/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9308 - accuracy: 0.5421 - val_loss: 0.8729 - val_accuracy: 0.5250\n",
      "Epoch 1309/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.8912 - accuracy: 0.5545 - val_loss: 0.8513 - val_accuracy: 0.5250\n",
      "Epoch 1310/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.9175 - accuracy: 0.5545 - val_loss: 0.8702 - val_accuracy: 0.5125\n",
      "Epoch 1311/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9128 - accuracy: 0.5452 - val_loss: 0.8623 - val_accuracy: 0.4875\n",
      "Epoch 1312/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9312 - accuracy: 0.5639 - val_loss: 0.8730 - val_accuracy: 0.5125\n",
      "Epoch 1313/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9081 - accuracy: 0.5545 - val_loss: 0.8714 - val_accuracy: 0.5125\n",
      "Epoch 1314/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9016 - accuracy: 0.5545 - val_loss: 0.8698 - val_accuracy: 0.5000\n",
      "Epoch 1315/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9009 - accuracy: 0.5607 - val_loss: 0.8625 - val_accuracy: 0.5250\n",
      "Epoch 1316/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.9166 - accuracy: 0.5514 - val_loss: 0.8539 - val_accuracy: 0.4875\n",
      "Epoch 1317/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.8950 - accuracy: 0.5545 - val_loss: 0.8898 - val_accuracy: 0.4500\n",
      "Epoch 1318/3000\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.9023 - accuracy: 0.5576 - val_loss: 0.8378 - val_accuracy: 0.4875\n",
      "Epoch 1319/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.8948 - accuracy: 0.5545 - val_loss: 0.8503 - val_accuracy: 0.4875\n",
      "Epoch 1320/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9212 - accuracy: 0.5732 - val_loss: 0.8894 - val_accuracy: 0.5000\n",
      "Epoch 1321/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9076 - accuracy: 0.5607 - val_loss: 0.8729 - val_accuracy: 0.4750\n",
      "Epoch 1322/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9066 - accuracy: 0.5639 - val_loss: 0.8709 - val_accuracy: 0.4875\n",
      "Epoch 1323/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9261 - accuracy: 0.5514 - val_loss: 0.8580 - val_accuracy: 0.5125\n",
      "Epoch 1324/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.9130 - accuracy: 0.5639 - val_loss: 0.8655 - val_accuracy: 0.5000\n",
      "Epoch 1325/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9122 - accuracy: 0.5514 - val_loss: 0.9001 - val_accuracy: 0.5500\n",
      "Epoch 1326/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9186 - accuracy: 0.5826 - val_loss: 0.8531 - val_accuracy: 0.5125\n",
      "Epoch 1327/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9001 - accuracy: 0.5545 - val_loss: 0.8775 - val_accuracy: 0.4750\n",
      "Epoch 1328/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9421 - accuracy: 0.5421 - val_loss: 0.8805 - val_accuracy: 0.5000\n",
      "Epoch 1329/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.9235 - accuracy: 0.5296 - val_loss: 0.8552 - val_accuracy: 0.5375\n",
      "Epoch 1330/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9060 - accuracy: 0.5763 - val_loss: 0.8567 - val_accuracy: 0.5125\n",
      "Epoch 1331/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9209 - accuracy: 0.5514 - val_loss: 0.8513 - val_accuracy: 0.5250\n",
      "Epoch 1332/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9192 - accuracy: 0.5576 - val_loss: 0.8523 - val_accuracy: 0.4875\n",
      "Epoch 1333/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9297 - accuracy: 0.5265 - val_loss: 0.8453 - val_accuracy: 0.5375\n",
      "Epoch 1334/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9446 - accuracy: 0.5483 - val_loss: 0.8608 - val_accuracy: 0.5375\n",
      "Epoch 1335/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9025 - accuracy: 0.5545 - val_loss: 0.8930 - val_accuracy: 0.4750\n",
      "Epoch 1336/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9236 - accuracy: 0.5576 - val_loss: 0.8874 - val_accuracy: 0.5500\n",
      "Epoch 1337/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9267 - accuracy: 0.5483 - val_loss: 0.8509 - val_accuracy: 0.5125\n",
      "Epoch 1338/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.9028 - accuracy: 0.5826 - val_loss: 0.8444 - val_accuracy: 0.5375\n",
      "Epoch 1339/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.8984 - accuracy: 0.5763 - val_loss: 0.8431 - val_accuracy: 0.5250\n",
      "Epoch 1340/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9265 - accuracy: 0.5545 - val_loss: 0.8756 - val_accuracy: 0.5375\n",
      "Epoch 1341/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9186 - accuracy: 0.5763 - val_loss: 0.8522 - val_accuracy: 0.5000\n",
      "Epoch 1342/3000\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.8809 - accuracy: 0.5514 - val_loss: 0.8698 - val_accuracy: 0.4750\n",
      "Epoch 1343/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9199 - accuracy: 0.5576 - val_loss: 0.9133 - val_accuracy: 0.4750\n",
      "Epoch 1344/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9290 - accuracy: 0.5265 - val_loss: 0.8876 - val_accuracy: 0.4750\n",
      "Epoch 1345/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.8797 - accuracy: 0.5732 - val_loss: 0.9077 - val_accuracy: 0.4750\n",
      "Epoch 1346/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.8896 - accuracy: 0.5888 - val_loss: 0.8452 - val_accuracy: 0.5250\n",
      "Epoch 1347/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9078 - accuracy: 0.5545 - val_loss: 0.8465 - val_accuracy: 0.5125\n",
      "Epoch 1348/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.8895 - accuracy: 0.5701 - val_loss: 0.8512 - val_accuracy: 0.5000\n",
      "Epoch 1349/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9378 - accuracy: 0.5545 - val_loss: 0.8594 - val_accuracy: 0.5125\n",
      "Epoch 1350/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9152 - accuracy: 0.5701 - val_loss: 0.9075 - val_accuracy: 0.4750\n",
      "Epoch 1351/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.9112 - accuracy: 0.5670 - val_loss: 0.8821 - val_accuracy: 0.4875\n",
      "Epoch 1352/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9194 - accuracy: 0.5452 - val_loss: 0.8623 - val_accuracy: 0.5125\n",
      "Epoch 1353/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9010 - accuracy: 0.5732 - val_loss: 0.8914 - val_accuracy: 0.4875\n",
      "Epoch 1354/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9205 - accuracy: 0.5763 - val_loss: 0.8748 - val_accuracy: 0.5125\n",
      "Epoch 1355/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9008 - accuracy: 0.5670 - val_loss: 0.8946 - val_accuracy: 0.4750\n",
      "Epoch 1356/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9191 - accuracy: 0.5452 - val_loss: 0.8506 - val_accuracy: 0.5375\n",
      "Epoch 1357/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9230 - accuracy: 0.5421 - val_loss: 0.8950 - val_accuracy: 0.5125\n",
      "Epoch 1358/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9126 - accuracy: 0.5514 - val_loss: 0.8725 - val_accuracy: 0.5125\n",
      "Epoch 1359/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9250 - accuracy: 0.5483 - val_loss: 0.9170 - val_accuracy: 0.4875\n",
      "Epoch 1360/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9184 - accuracy: 0.5763 - val_loss: 0.9063 - val_accuracy: 0.4875\n",
      "Epoch 1361/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.9149 - accuracy: 0.5670 - val_loss: 0.8597 - val_accuracy: 0.5250\n",
      "Epoch 1362/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.8993 - accuracy: 0.5701 - val_loss: 0.8472 - val_accuracy: 0.5500\n",
      "Epoch 1363/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.8783 - accuracy: 0.5888 - val_loss: 0.9126 - val_accuracy: 0.4625\n",
      "Epoch 1364/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9126 - accuracy: 0.5358 - val_loss: 0.8556 - val_accuracy: 0.5375\n",
      "Epoch 1365/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9456 - accuracy: 0.5607 - val_loss: 0.8546 - val_accuracy: 0.5125\n",
      "Epoch 1366/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9177 - accuracy: 0.5514 - val_loss: 0.8586 - val_accuracy: 0.5250\n",
      "Epoch 1367/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9041 - accuracy: 0.5452 - val_loss: 0.8522 - val_accuracy: 0.5125\n",
      "Epoch 1368/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9139 - accuracy: 0.5576 - val_loss: 0.8552 - val_accuracy: 0.5000\n",
      "Epoch 1369/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8738 - accuracy: 0.5857 - val_loss: 0.8802 - val_accuracy: 0.5375\n",
      "Epoch 1370/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9267 - accuracy: 0.5701 - val_loss: 0.8944 - val_accuracy: 0.4625\n",
      "Epoch 1371/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9399 - accuracy: 0.5545 - val_loss: 0.8976 - val_accuracy: 0.5250\n",
      "Epoch 1372/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.9337 - accuracy: 0.5545 - val_loss: 0.8624 - val_accuracy: 0.5250\n",
      "Epoch 1373/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.8773 - accuracy: 0.5888 - val_loss: 0.8555 - val_accuracy: 0.5500\n",
      "Epoch 1374/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9127 - accuracy: 0.5545 - val_loss: 0.8789 - val_accuracy: 0.5250\n",
      "Epoch 1375/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9094 - accuracy: 0.5670 - val_loss: 0.8796 - val_accuracy: 0.4875\n",
      "Epoch 1376/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9074 - accuracy: 0.5670 - val_loss: 0.8798 - val_accuracy: 0.5375\n",
      "Epoch 1377/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9441 - accuracy: 0.5421 - val_loss: 0.8805 - val_accuracy: 0.4875\n",
      "Epoch 1378/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9162 - accuracy: 0.5639 - val_loss: 0.8652 - val_accuracy: 0.5375\n",
      "Epoch 1379/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8715 - accuracy: 0.5701 - val_loss: 0.9084 - val_accuracy: 0.4375\n",
      "Epoch 1380/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.8870 - accuracy: 0.5607 - val_loss: 0.8354 - val_accuracy: 0.5125\n",
      "Epoch 1381/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9218 - accuracy: 0.5607 - val_loss: 0.8548 - val_accuracy: 0.5375\n",
      "Epoch 1382/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9292 - accuracy: 0.5607 - val_loss: 0.8651 - val_accuracy: 0.5000\n",
      "Epoch 1383/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9474 - accuracy: 0.5358 - val_loss: 0.8598 - val_accuracy: 0.5125\n",
      "Epoch 1384/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.9205 - accuracy: 0.5545 - val_loss: 0.8410 - val_accuracy: 0.5125\n",
      "Epoch 1385/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9003 - accuracy: 0.5732 - val_loss: 0.8720 - val_accuracy: 0.5000\n",
      "Epoch 1386/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8769 - accuracy: 0.5763 - val_loss: 0.8556 - val_accuracy: 0.5125\n",
      "Epoch 1387/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9132 - accuracy: 0.5545 - val_loss: 0.8737 - val_accuracy: 0.5250\n",
      "Epoch 1388/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9243 - accuracy: 0.5545 - val_loss: 0.8718 - val_accuracy: 0.5125\n",
      "Epoch 1389/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9015 - accuracy: 0.5732 - val_loss: 0.8573 - val_accuracy: 0.5250\n",
      "Epoch 1390/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8782 - accuracy: 0.5857 - val_loss: 0.8576 - val_accuracy: 0.5250\n",
      "Epoch 1391/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.8971 - accuracy: 0.5732 - val_loss: 0.8495 - val_accuracy: 0.5375\n",
      "Epoch 1392/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9056 - accuracy: 0.5483 - val_loss: 0.8668 - val_accuracy: 0.5250\n",
      "Epoch 1393/3000\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.9115 - accuracy: 0.5545 - val_loss: 0.8637 - val_accuracy: 0.5125\n",
      "Epoch 1394/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8934 - accuracy: 0.5794 - val_loss: 0.8636 - val_accuracy: 0.5250\n",
      "Epoch 1395/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9168 - accuracy: 0.5826 - val_loss: 0.8735 - val_accuracy: 0.5125\n",
      "Epoch 1396/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8771 - accuracy: 0.5763 - val_loss: 0.8497 - val_accuracy: 0.5000\n",
      "Epoch 1397/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9444 - accuracy: 0.5202 - val_loss: 0.9127 - val_accuracy: 0.4750\n",
      "Epoch 1398/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9146 - accuracy: 0.5452 - val_loss: 0.8516 - val_accuracy: 0.5375\n",
      "Epoch 1399/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.8920 - accuracy: 0.5607 - val_loss: 0.8606 - val_accuracy: 0.5375\n",
      "Epoch 1400/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9194 - accuracy: 0.5607 - val_loss: 0.8651 - val_accuracy: 0.5125\n",
      "Epoch 1401/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.8955 - accuracy: 0.5670 - val_loss: 0.9056 - val_accuracy: 0.4500\n",
      "Epoch 1402/3000\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.9084 - accuracy: 0.5607 - val_loss: 0.8593 - val_accuracy: 0.5250\n",
      "Epoch 1403/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9013 - accuracy: 0.5576 - val_loss: 0.8483 - val_accuracy: 0.5000\n",
      "Epoch 1404/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9038 - accuracy: 0.5701 - val_loss: 0.8674 - val_accuracy: 0.4750\n",
      "Epoch 1405/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8953 - accuracy: 0.5639 - val_loss: 0.8787 - val_accuracy: 0.4875\n",
      "Epoch 1406/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9073 - accuracy: 0.5576 - val_loss: 0.8874 - val_accuracy: 0.4375\n",
      "Epoch 1407/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9138 - accuracy: 0.5576 - val_loss: 0.8503 - val_accuracy: 0.5000\n",
      "Epoch 1408/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9252 - accuracy: 0.5639 - val_loss: 0.8567 - val_accuracy: 0.4875\n",
      "Epoch 1409/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.9324 - accuracy: 0.5389 - val_loss: 0.8803 - val_accuracy: 0.5125\n",
      "Epoch 1410/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9131 - accuracy: 0.5639 - val_loss: 0.8925 - val_accuracy: 0.5000\n",
      "Epoch 1411/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9406 - accuracy: 0.5389 - val_loss: 0.8765 - val_accuracy: 0.5125\n",
      "Epoch 1412/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8852 - accuracy: 0.5732 - val_loss: 0.8638 - val_accuracy: 0.5375\n",
      "Epoch 1413/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.8973 - accuracy: 0.5576 - val_loss: 0.8619 - val_accuracy: 0.5250\n",
      "Epoch 1414/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8852 - accuracy: 0.5888 - val_loss: 0.8668 - val_accuracy: 0.5125\n",
      "Epoch 1415/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8592 - accuracy: 0.5607 - val_loss: 0.8424 - val_accuracy: 0.4875\n",
      "Epoch 1416/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9276 - accuracy: 0.5389 - val_loss: 0.8583 - val_accuracy: 0.5250\n",
      "Epoch 1417/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9111 - accuracy: 0.5576 - val_loss: 0.8753 - val_accuracy: 0.4875\n",
      "Epoch 1418/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9523 - accuracy: 0.5576 - val_loss: 0.8885 - val_accuracy: 0.5500\n",
      "Epoch 1419/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9206 - accuracy: 0.5296 - val_loss: 0.8671 - val_accuracy: 0.5250\n",
      "Epoch 1420/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8789 - accuracy: 0.5701 - val_loss: 0.8801 - val_accuracy: 0.5375\n",
      "Epoch 1421/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8779 - accuracy: 0.5919 - val_loss: 0.8562 - val_accuracy: 0.5000\n",
      "Epoch 1422/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9101 - accuracy: 0.5514 - val_loss: 0.9056 - val_accuracy: 0.4625\n",
      "Epoch 1423/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9081 - accuracy: 0.5701 - val_loss: 0.8830 - val_accuracy: 0.5375\n",
      "Epoch 1424/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.8878 - accuracy: 0.5919 - val_loss: 0.8576 - val_accuracy: 0.5000\n",
      "Epoch 1425/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9165 - accuracy: 0.5327 - val_loss: 0.8709 - val_accuracy: 0.5375\n",
      "Epoch 1426/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9067 - accuracy: 0.5514 - val_loss: 0.8766 - val_accuracy: 0.5250\n",
      "Epoch 1427/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.9286 - accuracy: 0.5327 - val_loss: 0.8783 - val_accuracy: 0.5000\n",
      "Epoch 1428/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9226 - accuracy: 0.5265 - val_loss: 0.8610 - val_accuracy: 0.5000\n",
      "Epoch 1429/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8963 - accuracy: 0.5670 - val_loss: 0.8500 - val_accuracy: 0.5125\n",
      "Epoch 1430/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.8787 - accuracy: 0.5826 - val_loss: 0.8938 - val_accuracy: 0.4875\n",
      "Epoch 1431/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9199 - accuracy: 0.5857 - val_loss: 0.8949 - val_accuracy: 0.5125\n",
      "Epoch 1432/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9090 - accuracy: 0.5140 - val_loss: 0.8445 - val_accuracy: 0.5000\n",
      "Epoch 1433/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9048 - accuracy: 0.5732 - val_loss: 0.8381 - val_accuracy: 0.5000\n",
      "Epoch 1434/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9113 - accuracy: 0.5483 - val_loss: 0.9253 - val_accuracy: 0.4500\n",
      "Epoch 1435/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9260 - accuracy: 0.5140 - val_loss: 0.9072 - val_accuracy: 0.4625\n",
      "Epoch 1436/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.9357 - accuracy: 0.5421 - val_loss: 0.8908 - val_accuracy: 0.5000\n",
      "Epoch 1437/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9082 - accuracy: 0.5202 - val_loss: 0.8510 - val_accuracy: 0.5250\n",
      "Epoch 1438/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.8894 - accuracy: 0.5576 - val_loss: 0.8630 - val_accuracy: 0.5250\n",
      "Epoch 1439/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.8904 - accuracy: 0.5857 - val_loss: 0.8542 - val_accuracy: 0.5250\n",
      "Epoch 1440/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9295 - accuracy: 0.5421 - val_loss: 0.8495 - val_accuracy: 0.4875\n",
      "Epoch 1441/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.8812 - accuracy: 0.5794 - val_loss: 0.8818 - val_accuracy: 0.5000\n",
      "Epoch 1442/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.8919 - accuracy: 0.5389 - val_loss: 0.8599 - val_accuracy: 0.4875\n",
      "Epoch 1443/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9004 - accuracy: 0.5452 - val_loss: 0.8975 - val_accuracy: 0.5375\n",
      "Epoch 1444/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.9232 - accuracy: 0.5576 - val_loss: 0.8845 - val_accuracy: 0.5500\n",
      "Epoch 1445/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9016 - accuracy: 0.5389 - val_loss: 0.8836 - val_accuracy: 0.5000\n",
      "Epoch 1446/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9266 - accuracy: 0.5514 - val_loss: 0.8595 - val_accuracy: 0.5000\n",
      "Epoch 1447/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8793 - accuracy: 0.5670 - val_loss: 0.8605 - val_accuracy: 0.5125\n",
      "Epoch 1448/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.9039 - accuracy: 0.5826 - val_loss: 0.8433 - val_accuracy: 0.5000\n",
      "Epoch 1449/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9065 - accuracy: 0.5794 - val_loss: 0.8619 - val_accuracy: 0.5250\n",
      "Epoch 1450/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9024 - accuracy: 0.5514 - val_loss: 0.8482 - val_accuracy: 0.5000\n",
      "Epoch 1451/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9393 - accuracy: 0.5421 - val_loss: 0.8613 - val_accuracy: 0.5000\n",
      "Epoch 1452/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9165 - accuracy: 0.5607 - val_loss: 0.8915 - val_accuracy: 0.5500\n",
      "Epoch 1453/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9058 - accuracy: 0.5670 - val_loss: 0.8532 - val_accuracy: 0.5250\n",
      "Epoch 1454/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9246 - accuracy: 0.5576 - val_loss: 0.8598 - val_accuracy: 0.5125\n",
      "Epoch 1455/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9373 - accuracy: 0.5670 - val_loss: 0.8522 - val_accuracy: 0.5000\n",
      "Epoch 1456/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9198 - accuracy: 0.5763 - val_loss: 0.8781 - val_accuracy: 0.5625\n",
      "Epoch 1457/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9502 - accuracy: 0.5234 - val_loss: 0.8634 - val_accuracy: 0.5125\n",
      "Epoch 1458/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9247 - accuracy: 0.5639 - val_loss: 0.8808 - val_accuracy: 0.5250\n",
      "Epoch 1459/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8827 - accuracy: 0.5794 - val_loss: 0.9049 - val_accuracy: 0.4500\n",
      "Epoch 1460/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9165 - accuracy: 0.5545 - val_loss: 0.9029 - val_accuracy: 0.4625\n",
      "Epoch 1461/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9118 - accuracy: 0.5545 - val_loss: 0.8679 - val_accuracy: 0.5125\n",
      "Epoch 1462/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9194 - accuracy: 0.5826 - val_loss: 0.8678 - val_accuracy: 0.5500\n",
      "Epoch 1463/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.8647 - accuracy: 0.5857 - val_loss: 0.8285 - val_accuracy: 0.5250\n",
      "Epoch 1464/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.8802 - accuracy: 0.5826 - val_loss: 0.8585 - val_accuracy: 0.5250\n",
      "Epoch 1465/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9154 - accuracy: 0.5576 - val_loss: 0.8674 - val_accuracy: 0.5250\n",
      "Epoch 1466/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9149 - accuracy: 0.5545 - val_loss: 0.8831 - val_accuracy: 0.4875\n",
      "Epoch 1467/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.8355 - accuracy: 0.5888 - val_loss: 0.8634 - val_accuracy: 0.5125\n",
      "Epoch 1468/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.9028 - accuracy: 0.5452 - val_loss: 0.8513 - val_accuracy: 0.5125\n",
      "Epoch 1469/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9093 - accuracy: 0.5670 - val_loss: 0.8486 - val_accuracy: 0.5000\n",
      "Epoch 1470/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8762 - accuracy: 0.5826 - val_loss: 0.8486 - val_accuracy: 0.5000\n",
      "Epoch 1471/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9122 - accuracy: 0.5545 - val_loss: 0.8609 - val_accuracy: 0.5500\n",
      "Epoch 1472/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8632 - accuracy: 0.5826 - val_loss: 0.8600 - val_accuracy: 0.5125\n",
      "Epoch 1473/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8712 - accuracy: 0.5857 - val_loss: 0.8490 - val_accuracy: 0.5125\n",
      "Epoch 1474/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.8844 - accuracy: 0.5545 - val_loss: 0.8513 - val_accuracy: 0.5125\n",
      "Epoch 1475/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9105 - accuracy: 0.5327 - val_loss: 0.8197 - val_accuracy: 0.5000\n",
      "Epoch 1476/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9038 - accuracy: 0.5452 - val_loss: 0.8607 - val_accuracy: 0.4625\n",
      "Epoch 1477/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9057 - accuracy: 0.5358 - val_loss: 0.8543 - val_accuracy: 0.5250\n",
      "Epoch 1478/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8808 - accuracy: 0.5732 - val_loss: 0.8532 - val_accuracy: 0.5500\n",
      "Epoch 1479/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.9006 - accuracy: 0.5607 - val_loss: 0.8612 - val_accuracy: 0.5125\n",
      "Epoch 1480/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.8866 - accuracy: 0.5670 - val_loss: 0.8613 - val_accuracy: 0.4875\n",
      "Epoch 1481/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.8840 - accuracy: 0.5794 - val_loss: 0.8515 - val_accuracy: 0.5625\n",
      "Epoch 1482/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9137 - accuracy: 0.5389 - val_loss: 0.8493 - val_accuracy: 0.5125\n",
      "Epoch 1483/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9011 - accuracy: 0.5514 - val_loss: 0.8736 - val_accuracy: 0.4875\n",
      "Epoch 1484/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9351 - accuracy: 0.5452 - val_loss: 0.8760 - val_accuracy: 0.5000\n",
      "Epoch 1485/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9148 - accuracy: 0.5452 - val_loss: 0.9057 - val_accuracy: 0.4375\n",
      "Epoch 1486/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9092 - accuracy: 0.5576 - val_loss: 0.8573 - val_accuracy: 0.5125\n",
      "Epoch 1487/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8885 - accuracy: 0.5732 - val_loss: 0.9193 - val_accuracy: 0.4625\n",
      "Epoch 1488/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9041 - accuracy: 0.5483 - val_loss: 0.8344 - val_accuracy: 0.5250\n",
      "Epoch 1489/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.9272 - accuracy: 0.5452 - val_loss: 0.8580 - val_accuracy: 0.4875\n",
      "Epoch 1490/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.8755 - accuracy: 0.5981 - val_loss: 0.8836 - val_accuracy: 0.5250\n",
      "Epoch 1491/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9056 - accuracy: 0.5514 - val_loss: 0.8760 - val_accuracy: 0.5500\n",
      "Epoch 1492/3000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9248 - accuracy: 0.5389 - val_loss: 0.8635 - val_accuracy: 0.5250\n",
      "Epoch 1493/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8824 - accuracy: 0.5794 - val_loss: 0.8556 - val_accuracy: 0.5250\n",
      "Epoch 1494/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.8832 - accuracy: 0.5763 - val_loss: 0.8465 - val_accuracy: 0.5250\n",
      "Epoch 1495/3000\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.9034 - accuracy: 0.5607 - val_loss: 0.8701 - val_accuracy: 0.5375\n",
      "Epoch 1496/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8585 - accuracy: 0.5919 - val_loss: 0.9156 - val_accuracy: 0.5625\n",
      "Epoch 1497/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.8935 - accuracy: 0.5981 - val_loss: 0.8484 - val_accuracy: 0.5000\n",
      "Epoch 1498/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.8794 - accuracy: 0.5919 - val_loss: 0.8748 - val_accuracy: 0.4875\n",
      "Epoch 1499/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9094 - accuracy: 0.5670 - val_loss: 0.8626 - val_accuracy: 0.4875\n",
      "Epoch 1500/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9002 - accuracy: 0.5670 - val_loss: 0.8323 - val_accuracy: 0.5500\n",
      "Epoch 1501/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8774 - accuracy: 0.5794 - val_loss: 0.9976 - val_accuracy: 0.5250\n",
      "Epoch 1502/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.9413 - accuracy: 0.5763 - val_loss: 0.8610 - val_accuracy: 0.5250\n",
      "Epoch 1503/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.8829 - accuracy: 0.5607 - val_loss: 0.8600 - val_accuracy: 0.5000\n",
      "Epoch 1504/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9322 - accuracy: 0.5421 - val_loss: 0.8677 - val_accuracy: 0.5250\n",
      "Epoch 1505/3000\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.9027 - accuracy: 0.5763 - val_loss: 0.8486 - val_accuracy: 0.5000\n",
      "Epoch 1506/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8702 - accuracy: 0.5763 - val_loss: 0.8861 - val_accuracy: 0.5375\n",
      "Epoch 1507/3000\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.9145 - accuracy: 0.5483 - val_loss: 0.8670 - val_accuracy: 0.4750\n",
      "Epoch 1508/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.8944 - accuracy: 0.5701 - val_loss: 0.8696 - val_accuracy: 0.5250\n",
      "Epoch 1509/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8918 - accuracy: 0.5545 - val_loss: 0.8825 - val_accuracy: 0.5000\n",
      "Epoch 1510/3000\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.8941 - accuracy: 0.5981 - val_loss: 0.8962 - val_accuracy: 0.5250\n",
      "Epoch 1511/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8707 - accuracy: 0.6106 - val_loss: 0.8673 - val_accuracy: 0.5500\n",
      "Epoch 1512/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9115 - accuracy: 0.5545 - val_loss: 0.8545 - val_accuracy: 0.5000\n",
      "Epoch 1513/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9149 - accuracy: 0.5452 - val_loss: 0.8809 - val_accuracy: 0.4875\n",
      "Epoch 1514/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9077 - accuracy: 0.5452 - val_loss: 0.8670 - val_accuracy: 0.5625\n",
      "Epoch 1515/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9140 - accuracy: 0.5732 - val_loss: 0.8574 - val_accuracy: 0.5125\n",
      "Epoch 1516/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9313 - accuracy: 0.5421 - val_loss: 0.8404 - val_accuracy: 0.5000\n",
      "Epoch 1517/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.8689 - accuracy: 0.5763 - val_loss: 0.8610 - val_accuracy: 0.5125\n",
      "Epoch 1518/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8630 - accuracy: 0.6012 - val_loss: 0.8522 - val_accuracy: 0.5000\n",
      "Epoch 1519/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9391 - accuracy: 0.5202 - val_loss: 0.8424 - val_accuracy: 0.5125\n",
      "Epoch 1520/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9093 - accuracy: 0.5576 - val_loss: 0.9119 - val_accuracy: 0.5000\n",
      "Epoch 1521/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8871 - accuracy: 0.5670 - val_loss: 0.8521 - val_accuracy: 0.5000\n",
      "Epoch 1522/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.9192 - accuracy: 0.5701 - val_loss: 0.8487 - val_accuracy: 0.5500\n",
      "Epoch 1523/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9347 - accuracy: 0.5670 - val_loss: 0.9154 - val_accuracy: 0.4750\n",
      "Epoch 1524/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8977 - accuracy: 0.5826 - val_loss: 0.8506 - val_accuracy: 0.5125\n",
      "Epoch 1525/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9191 - accuracy: 0.5670 - val_loss: 0.8714 - val_accuracy: 0.5000\n",
      "Epoch 1526/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9396 - accuracy: 0.5421 - val_loss: 0.8508 - val_accuracy: 0.5375\n",
      "Epoch 1527/3000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.8995 - accuracy: 0.5701 - val_loss: 0.8722 - val_accuracy: 0.4875\n",
      "Epoch 1528/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9225 - accuracy: 0.5452 - val_loss: 0.8515 - val_accuracy: 0.5500\n",
      "Epoch 1529/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8978 - accuracy: 0.5670 - val_loss: 0.8599 - val_accuracy: 0.5625\n",
      "Epoch 1530/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8913 - accuracy: 0.5794 - val_loss: 0.8347 - val_accuracy: 0.5375\n",
      "Epoch 1531/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8952 - accuracy: 0.5514 - val_loss: 0.8307 - val_accuracy: 0.5000\n",
      "Epoch 1532/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8994 - accuracy: 0.5576 - val_loss: 0.8660 - val_accuracy: 0.5125\n",
      "Epoch 1533/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9085 - accuracy: 0.5483 - val_loss: 0.8645 - val_accuracy: 0.4875\n",
      "Epoch 1534/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8866 - accuracy: 0.5857 - val_loss: 0.8611 - val_accuracy: 0.5375\n",
      "Epoch 1535/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8559 - accuracy: 0.5639 - val_loss: 0.8370 - val_accuracy: 0.5250\n",
      "Epoch 1536/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9060 - accuracy: 0.5607 - val_loss: 0.8806 - val_accuracy: 0.5750\n",
      "Epoch 1537/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9274 - accuracy: 0.5358 - val_loss: 0.8478 - val_accuracy: 0.5000\n",
      "Epoch 1538/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.8819 - accuracy: 0.5794 - val_loss: 0.8581 - val_accuracy: 0.5125\n",
      "Epoch 1539/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9365 - accuracy: 0.5576 - val_loss: 0.8623 - val_accuracy: 0.5000\n",
      "Epoch 1540/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9004 - accuracy: 0.5888 - val_loss: 0.8699 - val_accuracy: 0.5750\n",
      "Epoch 1541/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8858 - accuracy: 0.5794 - val_loss: 0.8855 - val_accuracy: 0.5500\n",
      "Epoch 1542/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9056 - accuracy: 0.5545 - val_loss: 0.8744 - val_accuracy: 0.5375\n",
      "Epoch 1543/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.8915 - accuracy: 0.5763 - val_loss: 0.8733 - val_accuracy: 0.5375\n",
      "Epoch 1544/3000\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.8727 - accuracy: 0.5763 - val_loss: 0.8421 - val_accuracy: 0.5250\n",
      "Epoch 1545/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8846 - accuracy: 0.5763 - val_loss: 0.8602 - val_accuracy: 0.5375\n",
      "Epoch 1546/3000\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.8964 - accuracy: 0.5421 - val_loss: 0.8544 - val_accuracy: 0.5125\n",
      "Epoch 1547/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8827 - accuracy: 0.5857 - val_loss: 0.8891 - val_accuracy: 0.4875\n",
      "Epoch 1548/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8503 - accuracy: 0.5919 - val_loss: 0.8743 - val_accuracy: 0.5250\n",
      "Epoch 1549/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8851 - accuracy: 0.5950 - val_loss: 0.8351 - val_accuracy: 0.5250\n",
      "Epoch 1550/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9259 - accuracy: 0.5670 - val_loss: 0.8398 - val_accuracy: 0.5250\n",
      "Epoch 1551/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9002 - accuracy: 0.5670 - val_loss: 0.8458 - val_accuracy: 0.5125\n",
      "Epoch 1552/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8789 - accuracy: 0.5763 - val_loss: 0.8521 - val_accuracy: 0.5125\n",
      "Epoch 1553/3000\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.8894 - accuracy: 0.5763 - val_loss: 0.8595 - val_accuracy: 0.5500\n",
      "Epoch 1554/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9057 - accuracy: 0.5670 - val_loss: 0.8976 - val_accuracy: 0.5250\n",
      "Epoch 1555/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9191 - accuracy: 0.5639 - val_loss: 0.9077 - val_accuracy: 0.5125\n",
      "Epoch 1556/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9182 - accuracy: 0.5421 - val_loss: 0.8643 - val_accuracy: 0.5500\n",
      "Epoch 1557/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9190 - accuracy: 0.5452 - val_loss: 0.8710 - val_accuracy: 0.5625\n",
      "Epoch 1558/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9424 - accuracy: 0.5202 - val_loss: 0.8716 - val_accuracy: 0.5125\n",
      "Epoch 1559/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.9164 - accuracy: 0.5639 - val_loss: 0.8647 - val_accuracy: 0.5250\n",
      "Epoch 1560/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8899 - accuracy: 0.5701 - val_loss: 0.8523 - val_accuracy: 0.5000\n",
      "Epoch 1561/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8899 - accuracy: 0.5794 - val_loss: 0.8669 - val_accuracy: 0.5375\n",
      "Epoch 1562/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9216 - accuracy: 0.5483 - val_loss: 0.8584 - val_accuracy: 0.5250\n",
      "Epoch 1563/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9132 - accuracy: 0.5576 - val_loss: 0.8663 - val_accuracy: 0.5375\n",
      "Epoch 1564/3000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.8765 - accuracy: 0.5888 - val_loss: 0.8637 - val_accuracy: 0.5625\n",
      "Epoch 1565/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9090 - accuracy: 0.5670 - val_loss: 0.8522 - val_accuracy: 0.5125\n",
      "Epoch 1566/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8932 - accuracy: 0.5607 - val_loss: 0.8816 - val_accuracy: 0.5375\n",
      "Epoch 1567/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8364 - accuracy: 0.6075 - val_loss: 0.8425 - val_accuracy: 0.5500\n",
      "Epoch 1568/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9331 - accuracy: 0.5857 - val_loss: 0.8502 - val_accuracy: 0.5000\n",
      "Epoch 1569/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8809 - accuracy: 0.5857 - val_loss: 0.8826 - val_accuracy: 0.5250\n",
      "Epoch 1570/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.9065 - accuracy: 0.5670 - val_loss: 0.8470 - val_accuracy: 0.5500\n",
      "Epoch 1571/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8885 - accuracy: 0.5826 - val_loss: 0.8483 - val_accuracy: 0.5250\n",
      "Epoch 1572/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8727 - accuracy: 0.5763 - val_loss: 0.8450 - val_accuracy: 0.5125\n",
      "Epoch 1573/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.8950 - accuracy: 0.5826 - val_loss: 0.8903 - val_accuracy: 0.5250\n",
      "Epoch 1574/3000\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.9262 - accuracy: 0.5607 - val_loss: 0.8638 - val_accuracy: 0.5125\n",
      "Epoch 1575/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9215 - accuracy: 0.5732 - val_loss: 0.8657 - val_accuracy: 0.5625\n",
      "Epoch 1576/3000\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.9033 - accuracy: 0.5607 - val_loss: 0.8550 - val_accuracy: 0.5625\n",
      "Epoch 1577/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8937 - accuracy: 0.5732 - val_loss: 0.8663 - val_accuracy: 0.5375\n",
      "Epoch 1578/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8628 - accuracy: 0.5826 - val_loss: 0.9054 - val_accuracy: 0.4875\n",
      "Epoch 1579/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8943 - accuracy: 0.5857 - val_loss: 0.8592 - val_accuracy: 0.5500\n",
      "Epoch 1580/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8968 - accuracy: 0.5576 - val_loss: 0.8707 - val_accuracy: 0.5375\n",
      "Epoch 1581/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9003 - accuracy: 0.5826 - val_loss: 0.8367 - val_accuracy: 0.5375\n",
      "Epoch 1582/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8390 - accuracy: 0.5981 - val_loss: 0.8438 - val_accuracy: 0.5375\n",
      "Epoch 1583/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8956 - accuracy: 0.5919 - val_loss: 0.8738 - val_accuracy: 0.5375\n",
      "Epoch 1584/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.9232 - accuracy: 0.5545 - val_loss: 0.8469 - val_accuracy: 0.5375\n",
      "Epoch 1585/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8682 - accuracy: 0.5763 - val_loss: 0.8439 - val_accuracy: 0.5500\n",
      "Epoch 1586/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9389 - accuracy: 0.5732 - val_loss: 0.8493 - val_accuracy: 0.5500\n",
      "Epoch 1587/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8734 - accuracy: 0.5701 - val_loss: 0.9614 - val_accuracy: 0.4750\n",
      "Epoch 1588/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9141 - accuracy: 0.5545 - val_loss: 0.9024 - val_accuracy: 0.4875\n",
      "Epoch 1589/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8604 - accuracy: 0.5794 - val_loss: 0.8717 - val_accuracy: 0.5125\n",
      "Epoch 1590/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8873 - accuracy: 0.5639 - val_loss: 0.8517 - val_accuracy: 0.5125\n",
      "Epoch 1591/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8671 - accuracy: 0.5794 - val_loss: 0.9388 - val_accuracy: 0.5000\n",
      "Epoch 1592/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8754 - accuracy: 0.5763 - val_loss: 0.8358 - val_accuracy: 0.5125\n",
      "Epoch 1593/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9386 - accuracy: 0.5358 - val_loss: 0.8676 - val_accuracy: 0.5625\n",
      "Epoch 1594/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9093 - accuracy: 0.5576 - val_loss: 0.8480 - val_accuracy: 0.5125\n",
      "Epoch 1595/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9026 - accuracy: 0.5950 - val_loss: 0.8322 - val_accuracy: 0.5125\n",
      "Epoch 1596/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8833 - accuracy: 0.5763 - val_loss: 0.8380 - val_accuracy: 0.5375\n",
      "Epoch 1597/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8667 - accuracy: 0.5919 - val_loss: 0.8387 - val_accuracy: 0.5750\n",
      "Epoch 1598/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8866 - accuracy: 0.5763 - val_loss: 0.8862 - val_accuracy: 0.5250\n",
      "Epoch 1599/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8731 - accuracy: 0.6012 - val_loss: 0.8400 - val_accuracy: 0.5250\n",
      "Epoch 1600/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8588 - accuracy: 0.5794 - val_loss: 0.9028 - val_accuracy: 0.5250\n",
      "Epoch 1601/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9051 - accuracy: 0.5670 - val_loss: 0.9092 - val_accuracy: 0.4750\n",
      "Epoch 1602/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9250 - accuracy: 0.5670 - val_loss: 0.8527 - val_accuracy: 0.5250\n",
      "Epoch 1603/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8706 - accuracy: 0.5826 - val_loss: 0.8705 - val_accuracy: 0.5250\n",
      "Epoch 1604/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8763 - accuracy: 0.5857 - val_loss: 0.8844 - val_accuracy: 0.5375\n",
      "Epoch 1605/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8859 - accuracy: 0.5857 - val_loss: 0.8540 - val_accuracy: 0.5250\n",
      "Epoch 1606/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9180 - accuracy: 0.5327 - val_loss: 0.8544 - val_accuracy: 0.5250\n",
      "Epoch 1607/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9077 - accuracy: 0.5514 - val_loss: 0.8594 - val_accuracy: 0.5250\n",
      "Epoch 1608/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8810 - accuracy: 0.5826 - val_loss: 0.8314 - val_accuracy: 0.5250\n",
      "Epoch 1609/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8600 - accuracy: 0.5826 - val_loss: 0.8538 - val_accuracy: 0.5500\n",
      "Epoch 1610/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8913 - accuracy: 0.5576 - val_loss: 0.8528 - val_accuracy: 0.5500\n",
      "Epoch 1611/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8449 - accuracy: 0.6044 - val_loss: 0.8539 - val_accuracy: 0.5500\n",
      "Epoch 1612/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9057 - accuracy: 0.5639 - val_loss: 0.8354 - val_accuracy: 0.5125\n",
      "Epoch 1613/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9149 - accuracy: 0.5857 - val_loss: 0.8365 - val_accuracy: 0.5125\n",
      "Epoch 1614/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8872 - accuracy: 0.5888 - val_loss: 0.8526 - val_accuracy: 0.5125\n",
      "Epoch 1615/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8627 - accuracy: 0.5919 - val_loss: 0.8331 - val_accuracy: 0.5375\n",
      "Epoch 1616/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8898 - accuracy: 0.5670 - val_loss: 0.8521 - val_accuracy: 0.5375\n",
      "Epoch 1617/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8865 - accuracy: 0.5857 - val_loss: 0.8939 - val_accuracy: 0.5375\n",
      "Epoch 1618/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8564 - accuracy: 0.5639 - val_loss: 0.8331 - val_accuracy: 0.5000\n",
      "Epoch 1619/3000\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.8880 - accuracy: 0.5576 - val_loss: 0.8340 - val_accuracy: 0.5625\n",
      "Epoch 1620/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8856 - accuracy: 0.5826 - val_loss: 0.8554 - val_accuracy: 0.5625\n",
      "Epoch 1621/3000\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.8791 - accuracy: 0.5919 - val_loss: 0.8336 - val_accuracy: 0.5250\n",
      "Epoch 1622/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.9040 - accuracy: 0.5701 - val_loss: 0.8568 - val_accuracy: 0.5125\n",
      "Epoch 1623/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8879 - accuracy: 0.5670 - val_loss: 0.8471 - val_accuracy: 0.5375\n",
      "Epoch 1624/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8890 - accuracy: 0.5981 - val_loss: 0.8609 - val_accuracy: 0.5375\n",
      "Epoch 1625/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.9043 - accuracy: 0.5514 - val_loss: 0.8519 - val_accuracy: 0.4875\n",
      "Epoch 1626/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8767 - accuracy: 0.5950 - val_loss: 0.8248 - val_accuracy: 0.5000\n",
      "Epoch 1627/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8441 - accuracy: 0.6137 - val_loss: 0.8359 - val_accuracy: 0.5500\n",
      "Epoch 1628/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8848 - accuracy: 0.5794 - val_loss: 0.8764 - val_accuracy: 0.5375\n",
      "Epoch 1629/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9010 - accuracy: 0.5421 - val_loss: 0.8298 - val_accuracy: 0.5500\n",
      "Epoch 1630/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8553 - accuracy: 0.6044 - val_loss: 0.8491 - val_accuracy: 0.5250\n",
      "Epoch 1631/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8667 - accuracy: 0.6044 - val_loss: 0.8375 - val_accuracy: 0.5250\n",
      "Epoch 1632/3000\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.8819 - accuracy: 0.5732 - val_loss: 0.8557 - val_accuracy: 0.5375\n",
      "Epoch 1633/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8947 - accuracy: 0.5794 - val_loss: 0.8415 - val_accuracy: 0.5375\n",
      "Epoch 1634/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9081 - accuracy: 0.5452 - val_loss: 0.8629 - val_accuracy: 0.5625\n",
      "Epoch 1635/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8639 - accuracy: 0.5763 - val_loss: 0.8630 - val_accuracy: 0.5500\n",
      "Epoch 1636/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8941 - accuracy: 0.5483 - val_loss: 0.8564 - val_accuracy: 0.4750\n",
      "Epoch 1637/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8356 - accuracy: 0.5950 - val_loss: 0.8341 - val_accuracy: 0.4875\n",
      "Epoch 1638/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8997 - accuracy: 0.5950 - val_loss: 0.8431 - val_accuracy: 0.5125\n",
      "Epoch 1639/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.8821 - accuracy: 0.5701 - val_loss: 0.9362 - val_accuracy: 0.5250\n",
      "Epoch 1640/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9249 - accuracy: 0.5265 - val_loss: 0.8541 - val_accuracy: 0.5375\n",
      "Epoch 1641/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8645 - accuracy: 0.6044 - val_loss: 0.8401 - val_accuracy: 0.5125\n",
      "Epoch 1642/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9025 - accuracy: 0.5763 - val_loss: 0.8713 - val_accuracy: 0.5375\n",
      "Epoch 1643/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9005 - accuracy: 0.5607 - val_loss: 0.8444 - val_accuracy: 0.5375\n",
      "Epoch 1644/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8771 - accuracy: 0.5576 - val_loss: 0.8469 - val_accuracy: 0.5250\n",
      "Epoch 1645/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.8826 - accuracy: 0.5763 - val_loss: 0.8344 - val_accuracy: 0.5375\n",
      "Epoch 1646/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8901 - accuracy: 0.5763 - val_loss: 0.8522 - val_accuracy: 0.5500\n",
      "Epoch 1647/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.8765 - accuracy: 0.5857 - val_loss: 0.8530 - val_accuracy: 0.5125\n",
      "Epoch 1648/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8346 - accuracy: 0.5857 - val_loss: 0.8380 - val_accuracy: 0.5250\n",
      "Epoch 1649/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8869 - accuracy: 0.5857 - val_loss: 0.8366 - val_accuracy: 0.5250\n",
      "Epoch 1650/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.8831 - accuracy: 0.5670 - val_loss: 0.8476 - val_accuracy: 0.5750\n",
      "Epoch 1651/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9125 - accuracy: 0.5607 - val_loss: 0.8375 - val_accuracy: 0.5500\n",
      "Epoch 1652/3000\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.8956 - accuracy: 0.5826 - val_loss: 0.8929 - val_accuracy: 0.5625\n",
      "Epoch 1653/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8769 - accuracy: 0.5701 - val_loss: 0.9012 - val_accuracy: 0.5500\n",
      "Epoch 1654/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9321 - accuracy: 0.5358 - val_loss: 0.8832 - val_accuracy: 0.5375\n",
      "Epoch 1655/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8654 - accuracy: 0.6012 - val_loss: 0.8606 - val_accuracy: 0.5500\n",
      "Epoch 1656/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9128 - accuracy: 0.5452 - val_loss: 0.8871 - val_accuracy: 0.4625\n",
      "Epoch 1657/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8302 - accuracy: 0.6012 - val_loss: 0.8348 - val_accuracy: 0.5625\n",
      "Epoch 1658/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8890 - accuracy: 0.5919 - val_loss: 0.8249 - val_accuracy: 0.5625\n",
      "Epoch 1659/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8752 - accuracy: 0.5919 - val_loss: 0.8824 - val_accuracy: 0.5125\n",
      "Epoch 1660/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8841 - accuracy: 0.5763 - val_loss: 0.8346 - val_accuracy: 0.5500\n",
      "Epoch 1661/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9163 - accuracy: 0.5639 - val_loss: 0.8667 - val_accuracy: 0.5625\n",
      "Epoch 1662/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8969 - accuracy: 0.5701 - val_loss: 0.8928 - val_accuracy: 0.5625\n",
      "Epoch 1663/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8727 - accuracy: 0.5763 - val_loss: 0.9632 - val_accuracy: 0.4625\n",
      "Epoch 1664/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9212 - accuracy: 0.5576 - val_loss: 0.8518 - val_accuracy: 0.5625\n",
      "Epoch 1665/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9139 - accuracy: 0.5607 - val_loss: 0.8394 - val_accuracy: 0.5500\n",
      "Epoch 1666/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8859 - accuracy: 0.5826 - val_loss: 0.8586 - val_accuracy: 0.5250\n",
      "Epoch 1667/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8579 - accuracy: 0.6324 - val_loss: 0.8591 - val_accuracy: 0.5750\n",
      "Epoch 1668/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8828 - accuracy: 0.5981 - val_loss: 0.8674 - val_accuracy: 0.5500\n",
      "Epoch 1669/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.8613 - accuracy: 0.5794 - val_loss: 0.8407 - val_accuracy: 0.5250\n",
      "Epoch 1670/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9199 - accuracy: 0.5701 - val_loss: 0.8548 - val_accuracy: 0.5750\n",
      "Epoch 1671/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8976 - accuracy: 0.5981 - val_loss: 0.8618 - val_accuracy: 0.5250\n",
      "Epoch 1672/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8604 - accuracy: 0.5888 - val_loss: 0.8438 - val_accuracy: 0.5500\n",
      "Epoch 1673/3000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.8491 - accuracy: 0.6044 - val_loss: 0.8451 - val_accuracy: 0.5625\n",
      "Epoch 1674/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.9184 - accuracy: 0.5950 - val_loss: 0.8615 - val_accuracy: 0.5500\n",
      "Epoch 1675/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8741 - accuracy: 0.5826 - val_loss: 0.8558 - val_accuracy: 0.5750\n",
      "Epoch 1676/3000\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.9049 - accuracy: 0.5732 - val_loss: 0.8424 - val_accuracy: 0.5250\n",
      "Epoch 1677/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8880 - accuracy: 0.5794 - val_loss: 0.8555 - val_accuracy: 0.5625\n",
      "Epoch 1678/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8728 - accuracy: 0.5763 - val_loss: 0.8640 - val_accuracy: 0.4875\n",
      "Epoch 1679/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.8316 - accuracy: 0.6137 - val_loss: 0.9053 - val_accuracy: 0.4875\n",
      "Epoch 1680/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8733 - accuracy: 0.5732 - val_loss: 0.8407 - val_accuracy: 0.5875\n",
      "Epoch 1681/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8620 - accuracy: 0.5701 - val_loss: 0.8243 - val_accuracy: 0.5375\n",
      "Epoch 1682/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.9258 - accuracy: 0.5514 - val_loss: 0.8442 - val_accuracy: 0.5500\n",
      "Epoch 1683/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8982 - accuracy: 0.5576 - val_loss: 0.8678 - val_accuracy: 0.5250\n",
      "Epoch 1684/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8390 - accuracy: 0.5919 - val_loss: 0.8473 - val_accuracy: 0.5750\n",
      "Epoch 1685/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8856 - accuracy: 0.5794 - val_loss: 0.8468 - val_accuracy: 0.5750\n",
      "Epoch 1686/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.9162 - accuracy: 0.5639 - val_loss: 0.8346 - val_accuracy: 0.5500\n",
      "Epoch 1687/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8731 - accuracy: 0.5826 - val_loss: 0.9287 - val_accuracy: 0.4625\n",
      "Epoch 1688/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.9293 - accuracy: 0.5701 - val_loss: 0.8378 - val_accuracy: 0.5125\n",
      "Epoch 1689/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8879 - accuracy: 0.5794 - val_loss: 0.9063 - val_accuracy: 0.5000\n",
      "Epoch 1690/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8784 - accuracy: 0.5670 - val_loss: 0.8335 - val_accuracy: 0.5750\n",
      "Epoch 1691/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9093 - accuracy: 0.5794 - val_loss: 0.8423 - val_accuracy: 0.5500\n",
      "Epoch 1692/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8594 - accuracy: 0.5857 - val_loss: 0.8240 - val_accuracy: 0.5875\n",
      "Epoch 1693/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8405 - accuracy: 0.5888 - val_loss: 0.8505 - val_accuracy: 0.5125\n",
      "Epoch 1694/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8822 - accuracy: 0.5857 - val_loss: 0.8680 - val_accuracy: 0.5375\n",
      "Epoch 1695/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8597 - accuracy: 0.5950 - val_loss: 0.8448 - val_accuracy: 0.5875\n",
      "Epoch 1696/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9314 - accuracy: 0.5514 - val_loss: 0.8547 - val_accuracy: 0.5500\n",
      "Epoch 1697/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8718 - accuracy: 0.5701 - val_loss: 0.8656 - val_accuracy: 0.5500\n",
      "Epoch 1698/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8782 - accuracy: 0.5545 - val_loss: 0.8378 - val_accuracy: 0.5375\n",
      "Epoch 1699/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9000 - accuracy: 0.5794 - val_loss: 0.8819 - val_accuracy: 0.5250\n",
      "Epoch 1700/3000\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 0.8686 - accuracy: 0.5639 - val_loss: 0.8413 - val_accuracy: 0.5250\n",
      "Epoch 1701/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8825 - accuracy: 0.5576 - val_loss: 0.8526 - val_accuracy: 0.5375\n",
      "Epoch 1702/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8295 - accuracy: 0.6231 - val_loss: 0.8658 - val_accuracy: 0.5375\n",
      "Epoch 1703/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8547 - accuracy: 0.6137 - val_loss: 0.8618 - val_accuracy: 0.5250\n",
      "Epoch 1704/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.8996 - accuracy: 0.5826 - val_loss: 0.8721 - val_accuracy: 0.5250\n",
      "Epoch 1705/3000\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.9006 - accuracy: 0.5514 - val_loss: 0.8762 - val_accuracy: 0.5250\n",
      "Epoch 1706/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8685 - accuracy: 0.5888 - val_loss: 0.8934 - val_accuracy: 0.5250\n",
      "Epoch 1707/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9090 - accuracy: 0.5607 - val_loss: 0.8666 - val_accuracy: 0.5625\n",
      "Epoch 1708/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.8529 - accuracy: 0.5981 - val_loss: 0.8405 - val_accuracy: 0.5375\n",
      "Epoch 1709/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9008 - accuracy: 0.5421 - val_loss: 0.8916 - val_accuracy: 0.5000\n",
      "Epoch 1710/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9093 - accuracy: 0.5421 - val_loss: 0.8626 - val_accuracy: 0.5375\n",
      "Epoch 1711/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8729 - accuracy: 0.5607 - val_loss: 0.8355 - val_accuracy: 0.5375\n",
      "Epoch 1712/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.8816 - accuracy: 0.5950 - val_loss: 0.8650 - val_accuracy: 0.5500\n",
      "Epoch 1713/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.9063 - accuracy: 0.5514 - val_loss: 0.8792 - val_accuracy: 0.5125\n",
      "Epoch 1714/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8951 - accuracy: 0.5826 - val_loss: 0.8440 - val_accuracy: 0.5250\n",
      "Epoch 1715/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8727 - accuracy: 0.5950 - val_loss: 0.8945 - val_accuracy: 0.5000\n",
      "Epoch 1716/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8812 - accuracy: 0.5763 - val_loss: 0.8929 - val_accuracy: 0.5000\n",
      "Epoch 1717/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.8696 - accuracy: 0.5607 - val_loss: 0.8493 - val_accuracy: 0.5375\n",
      "Epoch 1718/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8902 - accuracy: 0.5732 - val_loss: 0.8667 - val_accuracy: 0.5625\n",
      "Epoch 1719/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8949 - accuracy: 0.5452 - val_loss: 0.8721 - val_accuracy: 0.5250\n",
      "Epoch 1720/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8929 - accuracy: 0.5732 - val_loss: 0.8615 - val_accuracy: 0.5250\n",
      "Epoch 1721/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8733 - accuracy: 0.5794 - val_loss: 0.8984 - val_accuracy: 0.5000\n",
      "Epoch 1722/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.8723 - accuracy: 0.6199 - val_loss: 0.8603 - val_accuracy: 0.5250\n",
      "Epoch 1723/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8735 - accuracy: 0.5732 - val_loss: 0.8468 - val_accuracy: 0.5375\n",
      "Epoch 1724/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8703 - accuracy: 0.5826 - val_loss: 0.8817 - val_accuracy: 0.5625\n",
      "Epoch 1725/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.9105 - accuracy: 0.5670 - val_loss: 0.8537 - val_accuracy: 0.5750\n",
      "Epoch 1726/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8510 - accuracy: 0.5857 - val_loss: 0.8592 - val_accuracy: 0.5000\n",
      "Epoch 1727/3000\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.8449 - accuracy: 0.5950 - val_loss: 0.8902 - val_accuracy: 0.5500\n",
      "Epoch 1728/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9031 - accuracy: 0.5732 - val_loss: 0.8657 - val_accuracy: 0.5625\n",
      "Epoch 1729/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8763 - accuracy: 0.5919 - val_loss: 0.8593 - val_accuracy: 0.5125\n",
      "Epoch 1730/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.9015 - accuracy: 0.5701 - val_loss: 0.8521 - val_accuracy: 0.5125\n",
      "Epoch 1731/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8812 - accuracy: 0.5732 - val_loss: 0.8541 - val_accuracy: 0.5375\n",
      "Epoch 1732/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8491 - accuracy: 0.5732 - val_loss: 0.8237 - val_accuracy: 0.5750\n",
      "Epoch 1733/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8468 - accuracy: 0.6168 - val_loss: 0.8502 - val_accuracy: 0.5500\n",
      "Epoch 1734/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8756 - accuracy: 0.5576 - val_loss: 0.8722 - val_accuracy: 0.5250\n",
      "Epoch 1735/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8651 - accuracy: 0.6012 - val_loss: 0.8599 - val_accuracy: 0.5250\n",
      "Epoch 1736/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8460 - accuracy: 0.5826 - val_loss: 0.8356 - val_accuracy: 0.5500\n",
      "Epoch 1737/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8816 - accuracy: 0.5701 - val_loss: 0.8343 - val_accuracy: 0.5000\n",
      "Epoch 1738/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8712 - accuracy: 0.5981 - val_loss: 0.8351 - val_accuracy: 0.5375\n",
      "Epoch 1739/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8587 - accuracy: 0.6106 - val_loss: 0.8887 - val_accuracy: 0.5250\n",
      "Epoch 1740/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8948 - accuracy: 0.5701 - val_loss: 0.8744 - val_accuracy: 0.5125\n",
      "Epoch 1741/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8534 - accuracy: 0.6137 - val_loss: 0.8570 - val_accuracy: 0.5125\n",
      "Epoch 1742/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8687 - accuracy: 0.5794 - val_loss: 0.8747 - val_accuracy: 0.5250\n",
      "Epoch 1743/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8493 - accuracy: 0.6106 - val_loss: 0.8474 - val_accuracy: 0.5750\n",
      "Epoch 1744/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8738 - accuracy: 0.5794 - val_loss: 0.8500 - val_accuracy: 0.5250\n",
      "Epoch 1745/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.9440 - accuracy: 0.5452 - val_loss: 0.8764 - val_accuracy: 0.5500\n",
      "Epoch 1746/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.8503 - accuracy: 0.5919 - val_loss: 0.8391 - val_accuracy: 0.5500\n",
      "Epoch 1747/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.9123 - accuracy: 0.5296 - val_loss: 0.8640 - val_accuracy: 0.5500\n",
      "Epoch 1748/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8451 - accuracy: 0.6044 - val_loss: 0.9134 - val_accuracy: 0.5250\n",
      "Epoch 1749/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8911 - accuracy: 0.5981 - val_loss: 0.8438 - val_accuracy: 0.5125\n",
      "Epoch 1750/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8431 - accuracy: 0.5763 - val_loss: 0.8190 - val_accuracy: 0.5500\n",
      "Epoch 1751/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8879 - accuracy: 0.5794 - val_loss: 0.8492 - val_accuracy: 0.5625\n",
      "Epoch 1752/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8915 - accuracy: 0.5950 - val_loss: 0.8387 - val_accuracy: 0.5500\n",
      "Epoch 1753/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8952 - accuracy: 0.5670 - val_loss: 0.8519 - val_accuracy: 0.5625\n",
      "Epoch 1754/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8766 - accuracy: 0.5576 - val_loss: 0.8442 - val_accuracy: 0.5375\n",
      "Epoch 1755/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.9051 - accuracy: 0.5732 - val_loss: 0.8560 - val_accuracy: 0.5500\n",
      "Epoch 1756/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8773 - accuracy: 0.5732 - val_loss: 0.8269 - val_accuracy: 0.5500\n",
      "Epoch 1757/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.8804 - accuracy: 0.6106 - val_loss: 0.8357 - val_accuracy: 0.5750\n",
      "Epoch 1758/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8663 - accuracy: 0.6012 - val_loss: 0.8623 - val_accuracy: 0.5625\n",
      "Epoch 1759/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8648 - accuracy: 0.5888 - val_loss: 0.8755 - val_accuracy: 0.5250\n",
      "Epoch 1760/3000\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.8640 - accuracy: 0.5981 - val_loss: 0.8548 - val_accuracy: 0.5750\n",
      "Epoch 1761/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8561 - accuracy: 0.5981 - val_loss: 0.8488 - val_accuracy: 0.5250\n",
      "Epoch 1762/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8517 - accuracy: 0.5888 - val_loss: 0.8222 - val_accuracy: 0.5500\n",
      "Epoch 1763/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8660 - accuracy: 0.6012 - val_loss: 0.8425 - val_accuracy: 0.5375\n",
      "Epoch 1764/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8593 - accuracy: 0.6044 - val_loss: 0.8591 - val_accuracy: 0.5625\n",
      "Epoch 1765/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.8969 - accuracy: 0.5483 - val_loss: 0.8802 - val_accuracy: 0.4875\n",
      "Epoch 1766/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8563 - accuracy: 0.5950 - val_loss: 0.8679 - val_accuracy: 0.5125\n",
      "Epoch 1767/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8685 - accuracy: 0.5826 - val_loss: 0.8525 - val_accuracy: 0.5375\n",
      "Epoch 1768/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8729 - accuracy: 0.5701 - val_loss: 0.8441 - val_accuracy: 0.5500\n",
      "Epoch 1769/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8610 - accuracy: 0.5981 - val_loss: 0.8678 - val_accuracy: 0.5375\n",
      "Epoch 1770/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8599 - accuracy: 0.5701 - val_loss: 0.8368 - val_accuracy: 0.5625\n",
      "Epoch 1771/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.8790 - accuracy: 0.5919 - val_loss: 0.8860 - val_accuracy: 0.5375\n",
      "Epoch 1772/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8977 - accuracy: 0.5888 - val_loss: 0.8503 - val_accuracy: 0.5625\n",
      "Epoch 1773/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8749 - accuracy: 0.5826 - val_loss: 0.8649 - val_accuracy: 0.5125\n",
      "Epoch 1774/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8675 - accuracy: 0.5919 - val_loss: 0.8510 - val_accuracy: 0.5750\n",
      "Epoch 1775/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8710 - accuracy: 0.5763 - val_loss: 0.8368 - val_accuracy: 0.5375\n",
      "Epoch 1776/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8270 - accuracy: 0.6012 - val_loss: 0.8500 - val_accuracy: 0.5125\n",
      "Epoch 1777/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8868 - accuracy: 0.6075 - val_loss: 0.8947 - val_accuracy: 0.5625\n",
      "Epoch 1778/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8946 - accuracy: 0.5794 - val_loss: 0.8265 - val_accuracy: 0.5500\n",
      "Epoch 1779/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8421 - accuracy: 0.6012 - val_loss: 0.8169 - val_accuracy: 0.5500\n",
      "Epoch 1780/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.8977 - accuracy: 0.5826 - val_loss: 0.8366 - val_accuracy: 0.5125\n",
      "Epoch 1781/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8511 - accuracy: 0.5950 - val_loss: 0.9109 - val_accuracy: 0.5000\n",
      "Epoch 1782/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8655 - accuracy: 0.5919 - val_loss: 0.8262 - val_accuracy: 0.5500\n",
      "Epoch 1783/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8712 - accuracy: 0.5826 - val_loss: 0.8356 - val_accuracy: 0.5375\n",
      "Epoch 1784/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8987 - accuracy: 0.5701 - val_loss: 0.8791 - val_accuracy: 0.5250\n",
      "Epoch 1785/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8742 - accuracy: 0.5763 - val_loss: 0.8564 - val_accuracy: 0.5500\n",
      "Epoch 1786/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8642 - accuracy: 0.6012 - val_loss: 0.8440 - val_accuracy: 0.5625\n",
      "Epoch 1787/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8519 - accuracy: 0.6168 - val_loss: 0.8630 - val_accuracy: 0.5375\n",
      "Epoch 1788/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8548 - accuracy: 0.5919 - val_loss: 0.8142 - val_accuracy: 0.5625\n",
      "Epoch 1789/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9071 - accuracy: 0.5670 - val_loss: 0.8493 - val_accuracy: 0.5250\n",
      "Epoch 1790/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8764 - accuracy: 0.5950 - val_loss: 0.8498 - val_accuracy: 0.5250\n",
      "Epoch 1791/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8792 - accuracy: 0.5857 - val_loss: 0.8949 - val_accuracy: 0.4875\n",
      "Epoch 1792/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.9274 - accuracy: 0.5670 - val_loss: 0.8643 - val_accuracy: 0.5250\n",
      "Epoch 1793/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8441 - accuracy: 0.6044 - val_loss: 0.8745 - val_accuracy: 0.5000\n",
      "Epoch 1794/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8684 - accuracy: 0.5732 - val_loss: 0.8481 - val_accuracy: 0.5500\n",
      "Epoch 1795/3000\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.8806 - accuracy: 0.5826 - val_loss: 0.8880 - val_accuracy: 0.5500\n",
      "Epoch 1796/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.8393 - accuracy: 0.5794 - val_loss: 0.8698 - val_accuracy: 0.5500\n",
      "Epoch 1797/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8712 - accuracy: 0.6012 - val_loss: 0.8717 - val_accuracy: 0.5125\n",
      "Epoch 1798/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8548 - accuracy: 0.6012 - val_loss: 0.8608 - val_accuracy: 0.5125\n",
      "Epoch 1799/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9176 - accuracy: 0.5545 - val_loss: 0.8695 - val_accuracy: 0.5500\n",
      "Epoch 1800/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8719 - accuracy: 0.6044 - val_loss: 0.8551 - val_accuracy: 0.5125\n",
      "Epoch 1801/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9277 - accuracy: 0.5483 - val_loss: 0.8501 - val_accuracy: 0.5375\n",
      "Epoch 1802/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8618 - accuracy: 0.5826 - val_loss: 0.8241 - val_accuracy: 0.5375\n",
      "Epoch 1803/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8406 - accuracy: 0.5981 - val_loss: 0.8412 - val_accuracy: 0.5125\n",
      "Epoch 1804/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8494 - accuracy: 0.5826 - val_loss: 0.8274 - val_accuracy: 0.5250\n",
      "Epoch 1805/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.8915 - accuracy: 0.5857 - val_loss: 0.8597 - val_accuracy: 0.5500\n",
      "Epoch 1806/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8771 - accuracy: 0.5763 - val_loss: 0.8527 - val_accuracy: 0.5500\n",
      "Epoch 1807/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8937 - accuracy: 0.5888 - val_loss: 0.8533 - val_accuracy: 0.5500\n",
      "Epoch 1808/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9433 - accuracy: 0.5545 - val_loss: 0.8371 - val_accuracy: 0.5375\n",
      "Epoch 1809/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8811 - accuracy: 0.5826 - val_loss: 0.8410 - val_accuracy: 0.5375\n",
      "Epoch 1810/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8659 - accuracy: 0.6012 - val_loss: 0.8547 - val_accuracy: 0.5375\n",
      "Epoch 1811/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.9086 - accuracy: 0.5670 - val_loss: 0.8436 - val_accuracy: 0.5500\n",
      "Epoch 1812/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8327 - accuracy: 0.6106 - val_loss: 0.8385 - val_accuracy: 0.5375\n",
      "Epoch 1813/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8495 - accuracy: 0.5981 - val_loss: 0.9182 - val_accuracy: 0.5125\n",
      "Epoch 1814/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8704 - accuracy: 0.5919 - val_loss: 0.9049 - val_accuracy: 0.4875\n",
      "Epoch 1815/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8910 - accuracy: 0.5576 - val_loss: 0.8343 - val_accuracy: 0.5875\n",
      "Epoch 1816/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8608 - accuracy: 0.5950 - val_loss: 0.8396 - val_accuracy: 0.5375\n",
      "Epoch 1817/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9109 - accuracy: 0.5639 - val_loss: 0.8417 - val_accuracy: 0.5875\n",
      "Epoch 1818/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8718 - accuracy: 0.5794 - val_loss: 0.9075 - val_accuracy: 0.4625\n",
      "Epoch 1819/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9149 - accuracy: 0.5483 - val_loss: 0.8470 - val_accuracy: 0.5750\n",
      "Epoch 1820/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8606 - accuracy: 0.5919 - val_loss: 0.8355 - val_accuracy: 0.5250\n",
      "Epoch 1821/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8566 - accuracy: 0.5794 - val_loss: 0.8837 - val_accuracy: 0.5250\n",
      "Epoch 1822/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8804 - accuracy: 0.5919 - val_loss: 0.8228 - val_accuracy: 0.5375\n",
      "Epoch 1823/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8725 - accuracy: 0.5888 - val_loss: 0.8353 - val_accuracy: 0.5500\n",
      "Epoch 1824/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8631 - accuracy: 0.5919 - val_loss: 0.8358 - val_accuracy: 0.5375\n",
      "Epoch 1825/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8949 - accuracy: 0.5919 - val_loss: 0.9193 - val_accuracy: 0.5000\n",
      "Epoch 1826/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9034 - accuracy: 0.5670 - val_loss: 0.8961 - val_accuracy: 0.5250\n",
      "Epoch 1827/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8817 - accuracy: 0.5826 - val_loss: 0.8538 - val_accuracy: 0.5375\n",
      "Epoch 1828/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8499 - accuracy: 0.6168 - val_loss: 0.8535 - val_accuracy: 0.5000\n",
      "Epoch 1829/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8303 - accuracy: 0.6137 - val_loss: 0.9131 - val_accuracy: 0.4750\n",
      "Epoch 1830/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8898 - accuracy: 0.5732 - val_loss: 0.8428 - val_accuracy: 0.5125\n",
      "Epoch 1831/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8630 - accuracy: 0.5950 - val_loss: 0.8430 - val_accuracy: 0.6000\n",
      "Epoch 1832/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8602 - accuracy: 0.5701 - val_loss: 0.8220 - val_accuracy: 0.5250\n",
      "Epoch 1833/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8316 - accuracy: 0.6075 - val_loss: 0.8247 - val_accuracy: 0.5625\n",
      "Epoch 1834/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8839 - accuracy: 0.5639 - val_loss: 0.8655 - val_accuracy: 0.5250\n",
      "Epoch 1835/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.8418 - accuracy: 0.5919 - val_loss: 0.8293 - val_accuracy: 0.5625\n",
      "Epoch 1836/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8464 - accuracy: 0.6012 - val_loss: 0.8445 - val_accuracy: 0.5250\n",
      "Epoch 1837/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8602 - accuracy: 0.6106 - val_loss: 0.8663 - val_accuracy: 0.5375\n",
      "Epoch 1838/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8841 - accuracy: 0.5919 - val_loss: 0.8315 - val_accuracy: 0.5625\n",
      "Epoch 1839/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.9578 - accuracy: 0.5452 - val_loss: 0.8713 - val_accuracy: 0.5250\n",
      "Epoch 1840/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8501 - accuracy: 0.5826 - val_loss: 0.8630 - val_accuracy: 0.5375\n",
      "Epoch 1841/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8291 - accuracy: 0.5950 - val_loss: 0.9017 - val_accuracy: 0.5625\n",
      "Epoch 1842/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8966 - accuracy: 0.5888 - val_loss: 0.8494 - val_accuracy: 0.5500\n",
      "Epoch 1843/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8683 - accuracy: 0.5857 - val_loss: 0.8385 - val_accuracy: 0.5250\n",
      "Epoch 1844/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8796 - accuracy: 0.5607 - val_loss: 0.8424 - val_accuracy: 0.5375\n",
      "Epoch 1845/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8575 - accuracy: 0.6012 - val_loss: 0.8373 - val_accuracy: 0.5250\n",
      "Epoch 1846/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8666 - accuracy: 0.5826 - val_loss: 0.8348 - val_accuracy: 0.5375\n",
      "Epoch 1847/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8319 - accuracy: 0.6044 - val_loss: 0.8216 - val_accuracy: 0.5250\n",
      "Epoch 1848/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.8151 - accuracy: 0.6231 - val_loss: 0.8299 - val_accuracy: 0.5250\n",
      "Epoch 1849/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8638 - accuracy: 0.5857 - val_loss: 0.8450 - val_accuracy: 0.5375\n",
      "Epoch 1850/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8581 - accuracy: 0.5639 - val_loss: 0.8786 - val_accuracy: 0.4875\n",
      "Epoch 1851/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8623 - accuracy: 0.5950 - val_loss: 0.8354 - val_accuracy: 0.5625\n",
      "Epoch 1852/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8461 - accuracy: 0.5950 - val_loss: 0.8273 - val_accuracy: 0.5750\n",
      "Epoch 1853/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8805 - accuracy: 0.5826 - val_loss: 0.8352 - val_accuracy: 0.5375\n",
      "Epoch 1854/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8516 - accuracy: 0.5919 - val_loss: 0.8226 - val_accuracy: 0.5625\n",
      "Epoch 1855/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8646 - accuracy: 0.6137 - val_loss: 0.8343 - val_accuracy: 0.5500\n",
      "Epoch 1856/3000\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.8781 - accuracy: 0.5639 - val_loss: 0.9391 - val_accuracy: 0.5125\n",
      "Epoch 1857/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8635 - accuracy: 0.6262 - val_loss: 0.8703 - val_accuracy: 0.5250\n",
      "Epoch 1858/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8381 - accuracy: 0.5950 - val_loss: 0.8540 - val_accuracy: 0.5125\n",
      "Epoch 1859/3000\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.8317 - accuracy: 0.5888 - val_loss: 0.8586 - val_accuracy: 0.5250\n",
      "Epoch 1860/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8979 - accuracy: 0.5576 - val_loss: 0.8561 - val_accuracy: 0.5500\n",
      "Epoch 1861/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.9022 - accuracy: 0.5763 - val_loss: 0.8665 - val_accuracy: 0.5375\n",
      "Epoch 1862/3000\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 0.8530 - accuracy: 0.6075 - val_loss: 0.8479 - val_accuracy: 0.5625\n",
      "Epoch 1863/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8186 - accuracy: 0.6168 - val_loss: 0.9563 - val_accuracy: 0.5250\n",
      "Epoch 1864/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8550 - accuracy: 0.5639 - val_loss: 0.8257 - val_accuracy: 0.5625\n",
      "Epoch 1865/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.8119 - accuracy: 0.6044 - val_loss: 0.8346 - val_accuracy: 0.5375\n",
      "Epoch 1866/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8751 - accuracy: 0.6012 - val_loss: 0.9322 - val_accuracy: 0.5125\n",
      "Epoch 1867/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.9083 - accuracy: 0.5389 - val_loss: 0.8351 - val_accuracy: 0.5375\n",
      "Epoch 1868/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8630 - accuracy: 0.5981 - val_loss: 0.8282 - val_accuracy: 0.5625\n",
      "Epoch 1869/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.9102 - accuracy: 0.5483 - val_loss: 0.8611 - val_accuracy: 0.5375\n",
      "Epoch 1870/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8468 - accuracy: 0.5950 - val_loss: 0.8223 - val_accuracy: 0.5375\n",
      "Epoch 1871/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8560 - accuracy: 0.5981 - val_loss: 0.8697 - val_accuracy: 0.5250\n",
      "Epoch 1872/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8719 - accuracy: 0.5950 - val_loss: 0.8356 - val_accuracy: 0.5500\n",
      "Epoch 1873/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.8116 - accuracy: 0.6012 - val_loss: 0.9099 - val_accuracy: 0.5750\n",
      "Epoch 1874/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.8807 - accuracy: 0.6012 - val_loss: 0.8724 - val_accuracy: 0.5500\n",
      "Epoch 1875/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8711 - accuracy: 0.5701 - val_loss: 0.8488 - val_accuracy: 0.5500\n",
      "Epoch 1876/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8425 - accuracy: 0.6137 - val_loss: 0.8572 - val_accuracy: 0.5250\n",
      "Epoch 1877/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8339 - accuracy: 0.6106 - val_loss: 0.8563 - val_accuracy: 0.5375\n",
      "Epoch 1878/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8622 - accuracy: 0.5794 - val_loss: 0.8994 - val_accuracy: 0.5500\n",
      "Epoch 1879/3000\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.8754 - accuracy: 0.5763 - val_loss: 0.8311 - val_accuracy: 0.5375\n",
      "Epoch 1880/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8302 - accuracy: 0.6231 - val_loss: 0.8261 - val_accuracy: 0.5500\n",
      "Epoch 1881/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8826 - accuracy: 0.5607 - val_loss: 0.8843 - val_accuracy: 0.5375\n",
      "Epoch 1882/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8499 - accuracy: 0.5919 - val_loss: 0.8730 - val_accuracy: 0.5750\n",
      "Epoch 1883/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8196 - accuracy: 0.5950 - val_loss: 0.8907 - val_accuracy: 0.5500\n",
      "Epoch 1884/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8582 - accuracy: 0.6168 - val_loss: 0.8293 - val_accuracy: 0.5375\n",
      "Epoch 1885/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8258 - accuracy: 0.6075 - val_loss: 0.8654 - val_accuracy: 0.5500\n",
      "Epoch 1886/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8280 - accuracy: 0.5981 - val_loss: 0.8315 - val_accuracy: 0.5375\n",
      "Epoch 1887/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8823 - accuracy: 0.6106 - val_loss: 0.9660 - val_accuracy: 0.5250\n",
      "Epoch 1888/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8219 - accuracy: 0.6199 - val_loss: 0.8459 - val_accuracy: 0.5750\n",
      "Epoch 1889/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8755 - accuracy: 0.5483 - val_loss: 0.8587 - val_accuracy: 0.5375\n",
      "Epoch 1890/3000\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.9244 - accuracy: 0.5576 - val_loss: 0.8411 - val_accuracy: 0.5500\n",
      "Epoch 1891/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8621 - accuracy: 0.5981 - val_loss: 0.8538 - val_accuracy: 0.5250\n",
      "Epoch 1892/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8694 - accuracy: 0.5919 - val_loss: 0.8927 - val_accuracy: 0.5250\n",
      "Epoch 1893/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8499 - accuracy: 0.6044 - val_loss: 0.8542 - val_accuracy: 0.5625\n",
      "Epoch 1894/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8532 - accuracy: 0.5826 - val_loss: 0.8501 - val_accuracy: 0.5625\n",
      "Epoch 1895/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8622 - accuracy: 0.5888 - val_loss: 0.8331 - val_accuracy: 0.5625\n",
      "Epoch 1896/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8584 - accuracy: 0.6137 - val_loss: 0.8650 - val_accuracy: 0.5625\n",
      "Epoch 1897/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.8649 - accuracy: 0.6044 - val_loss: 0.8466 - val_accuracy: 0.5500\n",
      "Epoch 1898/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8539 - accuracy: 0.5950 - val_loss: 0.8310 - val_accuracy: 0.5500\n",
      "Epoch 1899/3000\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.8531 - accuracy: 0.5763 - val_loss: 0.8344 - val_accuracy: 0.5625\n",
      "Epoch 1900/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8442 - accuracy: 0.6075 - val_loss: 0.8628 - val_accuracy: 0.5375\n",
      "Epoch 1901/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.9206 - accuracy: 0.5576 - val_loss: 0.8615 - val_accuracy: 0.5875\n",
      "Epoch 1902/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8359 - accuracy: 0.5950 - val_loss: 0.9406 - val_accuracy: 0.4750\n",
      "Epoch 1903/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8584 - accuracy: 0.5888 - val_loss: 0.8040 - val_accuracy: 0.5625\n",
      "Epoch 1904/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8670 - accuracy: 0.5950 - val_loss: 0.8492 - val_accuracy: 0.5625\n",
      "Epoch 1905/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8222 - accuracy: 0.6012 - val_loss: 0.8887 - val_accuracy: 0.5375\n",
      "Epoch 1906/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8646 - accuracy: 0.5919 - val_loss: 0.8222 - val_accuracy: 0.5625\n",
      "Epoch 1907/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8817 - accuracy: 0.5857 - val_loss: 0.8284 - val_accuracy: 0.5500\n",
      "Epoch 1908/3000\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.8452 - accuracy: 0.6106 - val_loss: 0.8429 - val_accuracy: 0.5750\n",
      "Epoch 1909/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8436 - accuracy: 0.5981 - val_loss: 0.9173 - val_accuracy: 0.5500\n",
      "Epoch 1910/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8438 - accuracy: 0.5919 - val_loss: 0.8409 - val_accuracy: 0.5500\n",
      "Epoch 1911/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8544 - accuracy: 0.6075 - val_loss: 0.8447 - val_accuracy: 0.5750\n",
      "Epoch 1912/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8617 - accuracy: 0.6106 - val_loss: 0.9016 - val_accuracy: 0.5250\n",
      "Epoch 1913/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8385 - accuracy: 0.6137 - val_loss: 0.9565 - val_accuracy: 0.5250\n",
      "Epoch 1914/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.8798 - accuracy: 0.5794 - val_loss: 0.8462 - val_accuracy: 0.5625\n",
      "Epoch 1915/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8744 - accuracy: 0.5981 - val_loss: 0.8824 - val_accuracy: 0.5625\n",
      "Epoch 1916/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8670 - accuracy: 0.5639 - val_loss: 0.8469 - val_accuracy: 0.5625\n",
      "Epoch 1917/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8283 - accuracy: 0.6075 - val_loss: 0.8443 - val_accuracy: 0.5375\n",
      "Epoch 1918/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8528 - accuracy: 0.5794 - val_loss: 0.8645 - val_accuracy: 0.5375\n",
      "Epoch 1919/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.8442 - accuracy: 0.6355 - val_loss: 0.8418 - val_accuracy: 0.5625\n",
      "Epoch 1920/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8419 - accuracy: 0.5888 - val_loss: 0.8814 - val_accuracy: 0.5500\n",
      "Epoch 1921/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8524 - accuracy: 0.6137 - val_loss: 0.8568 - val_accuracy: 0.5375\n",
      "Epoch 1922/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.9115 - accuracy: 0.5701 - val_loss: 0.8465 - val_accuracy: 0.5250\n",
      "Epoch 1923/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8483 - accuracy: 0.5826 - val_loss: 0.8628 - val_accuracy: 0.5625\n",
      "Epoch 1924/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8205 - accuracy: 0.6199 - val_loss: 0.8428 - val_accuracy: 0.5750\n",
      "Epoch 1925/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.8286 - accuracy: 0.6199 - val_loss: 0.8383 - val_accuracy: 0.5375\n",
      "Epoch 1926/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8824 - accuracy: 0.5919 - val_loss: 0.8534 - val_accuracy: 0.5375\n",
      "Epoch 1927/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8266 - accuracy: 0.5950 - val_loss: 0.9176 - val_accuracy: 0.5500\n",
      "Epoch 1928/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8676 - accuracy: 0.5919 - val_loss: 0.8666 - val_accuracy: 0.5250\n",
      "Epoch 1929/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8485 - accuracy: 0.5857 - val_loss: 0.8986 - val_accuracy: 0.5000\n",
      "Epoch 1930/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8758 - accuracy: 0.5732 - val_loss: 0.8300 - val_accuracy: 0.5500\n",
      "Epoch 1931/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8284 - accuracy: 0.6075 - val_loss: 0.8595 - val_accuracy: 0.5250\n",
      "Epoch 1932/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8682 - accuracy: 0.5732 - val_loss: 0.9278 - val_accuracy: 0.5125\n",
      "Epoch 1933/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8667 - accuracy: 0.5826 - val_loss: 0.8629 - val_accuracy: 0.5250\n",
      "Epoch 1934/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8345 - accuracy: 0.6231 - val_loss: 0.8819 - val_accuracy: 0.5750\n",
      "Epoch 1935/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8220 - accuracy: 0.6075 - val_loss: 0.8444 - val_accuracy: 0.5625\n",
      "Epoch 1936/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8453 - accuracy: 0.6012 - val_loss: 0.8152 - val_accuracy: 0.5500\n",
      "Epoch 1937/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.8874 - accuracy: 0.6012 - val_loss: 0.8302 - val_accuracy: 0.5625\n",
      "Epoch 1938/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8736 - accuracy: 0.5763 - val_loss: 0.8573 - val_accuracy: 0.5500\n",
      "Epoch 1939/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.8304 - accuracy: 0.5981 - val_loss: 0.8529 - val_accuracy: 0.5500\n",
      "Epoch 1940/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8757 - accuracy: 0.5888 - val_loss: 0.8280 - val_accuracy: 0.5625\n",
      "Epoch 1941/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.8792 - accuracy: 0.5763 - val_loss: 0.9079 - val_accuracy: 0.5000\n",
      "Epoch 1942/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8767 - accuracy: 0.5826 - val_loss: 0.8228 - val_accuracy: 0.5750\n",
      "Epoch 1943/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8300 - accuracy: 0.6293 - val_loss: 0.8232 - val_accuracy: 0.5500\n",
      "Epoch 1944/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.8327 - accuracy: 0.6106 - val_loss: 0.8640 - val_accuracy: 0.5500\n",
      "Epoch 1945/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8603 - accuracy: 0.5919 - val_loss: 0.8398 - val_accuracy: 0.5750\n",
      "Epoch 1946/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.8367 - accuracy: 0.6137 - val_loss: 0.8511 - val_accuracy: 0.5500\n",
      "Epoch 1947/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.9067 - accuracy: 0.5576 - val_loss: 0.8512 - val_accuracy: 0.5500\n",
      "Epoch 1948/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8918 - accuracy: 0.5732 - val_loss: 0.8366 - val_accuracy: 0.5750\n",
      "Epoch 1949/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.8840 - accuracy: 0.6075 - val_loss: 0.8520 - val_accuracy: 0.5875\n",
      "Epoch 1950/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.8418 - accuracy: 0.6137 - val_loss: 0.8426 - val_accuracy: 0.5625\n",
      "Epoch 1951/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8440 - accuracy: 0.5857 - val_loss: 0.8470 - val_accuracy: 0.5625\n",
      "Epoch 1952/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8411 - accuracy: 0.6044 - val_loss: 0.8829 - val_accuracy: 0.5375\n",
      "Epoch 1953/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.8820 - accuracy: 0.5639 - val_loss: 0.8484 - val_accuracy: 0.5750\n",
      "Epoch 1954/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9023 - accuracy: 0.5794 - val_loss: 0.8422 - val_accuracy: 0.5875\n",
      "Epoch 1955/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8368 - accuracy: 0.5950 - val_loss: 0.8504 - val_accuracy: 0.5750\n",
      "Epoch 1956/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8082 - accuracy: 0.6106 - val_loss: 0.9189 - val_accuracy: 0.5500\n",
      "Epoch 1957/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.8702 - accuracy: 0.5826 - val_loss: 0.8220 - val_accuracy: 0.5750\n",
      "Epoch 1958/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7949 - accuracy: 0.6231 - val_loss: 0.8441 - val_accuracy: 0.5500\n",
      "Epoch 1959/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8442 - accuracy: 0.6168 - val_loss: 0.8725 - val_accuracy: 0.5500\n",
      "Epoch 1960/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8595 - accuracy: 0.5857 - val_loss: 0.8204 - val_accuracy: 0.5625\n",
      "Epoch 1961/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8402 - accuracy: 0.6012 - val_loss: 0.8123 - val_accuracy: 0.5750\n",
      "Epoch 1962/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8777 - accuracy: 0.5794 - val_loss: 0.9040 - val_accuracy: 0.5500\n",
      "Epoch 1963/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8511 - accuracy: 0.6044 - val_loss: 0.8233 - val_accuracy: 0.5625\n",
      "Epoch 1964/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8497 - accuracy: 0.5794 - val_loss: 0.8233 - val_accuracy: 0.5625\n",
      "Epoch 1965/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8180 - accuracy: 0.6168 - val_loss: 0.8491 - val_accuracy: 0.5625\n",
      "Epoch 1966/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8008 - accuracy: 0.6386 - val_loss: 0.8384 - val_accuracy: 0.5625\n",
      "Epoch 1967/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8756 - accuracy: 0.5607 - val_loss: 0.9013 - val_accuracy: 0.5500\n",
      "Epoch 1968/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8524 - accuracy: 0.6012 - val_loss: 0.8565 - val_accuracy: 0.5500\n",
      "Epoch 1969/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.8328 - accuracy: 0.6106 - val_loss: 0.8215 - val_accuracy: 0.5625\n",
      "Epoch 1970/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8843 - accuracy: 0.5732 - val_loss: 0.8506 - val_accuracy: 0.5750\n",
      "Epoch 1971/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8516 - accuracy: 0.6262 - val_loss: 0.8197 - val_accuracy: 0.5750\n",
      "Epoch 1972/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8686 - accuracy: 0.5857 - val_loss: 0.9118 - val_accuracy: 0.5375\n",
      "Epoch 1973/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.8386 - accuracy: 0.6075 - val_loss: 0.8610 - val_accuracy: 0.5125\n",
      "Epoch 1974/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8507 - accuracy: 0.5919 - val_loss: 0.8145 - val_accuracy: 0.5750\n",
      "Epoch 1975/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8571 - accuracy: 0.5888 - val_loss: 0.9466 - val_accuracy: 0.5250\n",
      "Epoch 1976/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8541 - accuracy: 0.5950 - val_loss: 0.8359 - val_accuracy: 0.5625\n",
      "Epoch 1977/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8363 - accuracy: 0.6012 - val_loss: 0.8122 - val_accuracy: 0.5625\n",
      "Epoch 1978/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8156 - accuracy: 0.6044 - val_loss: 0.8465 - val_accuracy: 0.5750\n",
      "Epoch 1979/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8907 - accuracy: 0.5794 - val_loss: 0.8125 - val_accuracy: 0.5500\n",
      "Epoch 1980/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8285 - accuracy: 0.5950 - val_loss: 0.8762 - val_accuracy: 0.5375\n",
      "Epoch 1981/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8316 - accuracy: 0.5981 - val_loss: 0.8148 - val_accuracy: 0.5500\n",
      "Epoch 1982/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8271 - accuracy: 0.6137 - val_loss: 0.8198 - val_accuracy: 0.5500\n",
      "Epoch 1983/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8777 - accuracy: 0.5670 - val_loss: 0.8614 - val_accuracy: 0.5500\n",
      "Epoch 1984/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8410 - accuracy: 0.6012 - val_loss: 0.8577 - val_accuracy: 0.5625\n",
      "Epoch 1985/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8128 - accuracy: 0.6231 - val_loss: 0.8746 - val_accuracy: 0.5125\n",
      "Epoch 1986/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8429 - accuracy: 0.5981 - val_loss: 0.8808 - val_accuracy: 0.5500\n",
      "Epoch 1987/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8756 - accuracy: 0.5732 - val_loss: 0.8633 - val_accuracy: 0.5750\n",
      "Epoch 1988/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8490 - accuracy: 0.6044 - val_loss: 0.8501 - val_accuracy: 0.5500\n",
      "Epoch 1989/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8433 - accuracy: 0.5857 - val_loss: 0.8582 - val_accuracy: 0.5625\n",
      "Epoch 1990/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8569 - accuracy: 0.5857 - val_loss: 0.8271 - val_accuracy: 0.5750\n",
      "Epoch 1991/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8364 - accuracy: 0.6199 - val_loss: 0.8932 - val_accuracy: 0.5625\n",
      "Epoch 1992/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8682 - accuracy: 0.5857 - val_loss: 0.8434 - val_accuracy: 0.5500\n",
      "Epoch 1993/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8350 - accuracy: 0.6075 - val_loss: 0.8326 - val_accuracy: 0.5625\n",
      "Epoch 1994/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8425 - accuracy: 0.5981 - val_loss: 0.8577 - val_accuracy: 0.5750\n",
      "Epoch 1995/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8228 - accuracy: 0.5981 - val_loss: 0.8560 - val_accuracy: 0.5250\n",
      "Epoch 1996/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8224 - accuracy: 0.6075 - val_loss: 0.8456 - val_accuracy: 0.5875\n",
      "Epoch 1997/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8064 - accuracy: 0.6262 - val_loss: 0.8513 - val_accuracy: 0.5875\n",
      "Epoch 1998/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8532 - accuracy: 0.5607 - val_loss: 0.8626 - val_accuracy: 0.5500\n",
      "Epoch 1999/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8239 - accuracy: 0.5826 - val_loss: 0.8715 - val_accuracy: 0.5500\n",
      "Epoch 2000/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8077 - accuracy: 0.6231 - val_loss: 0.8465 - val_accuracy: 0.5375\n",
      "Epoch 2001/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8059 - accuracy: 0.6106 - val_loss: 0.8203 - val_accuracy: 0.5625\n",
      "Epoch 2002/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8398 - accuracy: 0.5981 - val_loss: 0.8312 - val_accuracy: 0.5750\n",
      "Epoch 2003/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8273 - accuracy: 0.6044 - val_loss: 0.8399 - val_accuracy: 0.5625\n",
      "Epoch 2004/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8962 - accuracy: 0.5576 - val_loss: 0.8307 - val_accuracy: 0.6000\n",
      "Epoch 2005/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8350 - accuracy: 0.5919 - val_loss: 0.9057 - val_accuracy: 0.5500\n",
      "Epoch 2006/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8496 - accuracy: 0.6262 - val_loss: 0.8353 - val_accuracy: 0.5875\n",
      "Epoch 2007/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8840 - accuracy: 0.5826 - val_loss: 0.8380 - val_accuracy: 0.5625\n",
      "Epoch 2008/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8380 - accuracy: 0.5950 - val_loss: 0.8364 - val_accuracy: 0.6000\n",
      "Epoch 2009/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8738 - accuracy: 0.5607 - val_loss: 0.8698 - val_accuracy: 0.5625\n",
      "Epoch 2010/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8825 - accuracy: 0.5919 - val_loss: 0.8377 - val_accuracy: 0.6000\n",
      "Epoch 2011/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8648 - accuracy: 0.5857 - val_loss: 0.8366 - val_accuracy: 0.6000\n",
      "Epoch 2012/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8916 - accuracy: 0.5794 - val_loss: 0.8329 - val_accuracy: 0.5750\n",
      "Epoch 2013/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8561 - accuracy: 0.6075 - val_loss: 0.8387 - val_accuracy: 0.5875\n",
      "Epoch 2014/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8840 - accuracy: 0.5826 - val_loss: 0.8393 - val_accuracy: 0.5500\n",
      "Epoch 2015/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8628 - accuracy: 0.5888 - val_loss: 0.8585 - val_accuracy: 0.5625\n",
      "Epoch 2016/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8300 - accuracy: 0.5919 - val_loss: 0.8479 - val_accuracy: 0.5375\n",
      "Epoch 2017/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8770 - accuracy: 0.5763 - val_loss: 0.8340 - val_accuracy: 0.5625\n",
      "Epoch 2018/3000\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.8606 - accuracy: 0.6137 - val_loss: 0.8386 - val_accuracy: 0.5875\n",
      "Epoch 2019/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8173 - accuracy: 0.6106 - val_loss: 0.8802 - val_accuracy: 0.5375\n",
      "Epoch 2020/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8765 - accuracy: 0.5826 - val_loss: 0.8778 - val_accuracy: 0.5750\n",
      "Epoch 2021/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8485 - accuracy: 0.5919 - val_loss: 0.8515 - val_accuracy: 0.5500\n",
      "Epoch 2022/3000\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.8456 - accuracy: 0.5919 - val_loss: 0.8448 - val_accuracy: 0.5750\n",
      "Epoch 2023/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.8010 - accuracy: 0.6199 - val_loss: 0.8217 - val_accuracy: 0.5500\n",
      "Epoch 2024/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8506 - accuracy: 0.5794 - val_loss: 0.8550 - val_accuracy: 0.5750\n",
      "Epoch 2025/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8351 - accuracy: 0.5732 - val_loss: 0.8865 - val_accuracy: 0.5625\n",
      "Epoch 2026/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7761 - accuracy: 0.6449 - val_loss: 0.8483 - val_accuracy: 0.5625\n",
      "Epoch 2027/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.9010 - accuracy: 0.5670 - val_loss: 0.8417 - val_accuracy: 0.6000\n",
      "Epoch 2028/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8329 - accuracy: 0.6199 - val_loss: 0.8425 - val_accuracy: 0.5625\n",
      "Epoch 2029/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8651 - accuracy: 0.5981 - val_loss: 0.9234 - val_accuracy: 0.5000\n",
      "Epoch 2030/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.8425 - accuracy: 0.6075 - val_loss: 0.8431 - val_accuracy: 0.5750\n",
      "Epoch 2031/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8172 - accuracy: 0.6168 - val_loss: 0.8491 - val_accuracy: 0.5375\n",
      "Epoch 2032/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8322 - accuracy: 0.6012 - val_loss: 0.9024 - val_accuracy: 0.5375\n",
      "Epoch 2033/3000\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8439 - accuracy: 0.6012 - val_loss: 0.8566 - val_accuracy: 0.5500\n",
      "Epoch 2034/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.8358 - accuracy: 0.5794 - val_loss: 0.8748 - val_accuracy: 0.5500\n",
      "Epoch 2035/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.8282 - accuracy: 0.6106 - val_loss: 0.8375 - val_accuracy: 0.5500\n",
      "Epoch 2036/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7948 - accuracy: 0.6417 - val_loss: 0.8115 - val_accuracy: 0.5750\n",
      "Epoch 2037/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8722 - accuracy: 0.5950 - val_loss: 0.8954 - val_accuracy: 0.5500\n",
      "Epoch 2038/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8135 - accuracy: 0.6137 - val_loss: 0.8527 - val_accuracy: 0.5875\n",
      "Epoch 2039/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8069 - accuracy: 0.6012 - val_loss: 0.8505 - val_accuracy: 0.5750\n",
      "Epoch 2040/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8624 - accuracy: 0.5857 - val_loss: 0.8648 - val_accuracy: 0.5625\n",
      "Epoch 2041/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.8254 - accuracy: 0.6137 - val_loss: 0.8588 - val_accuracy: 0.5875\n",
      "Epoch 2042/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8250 - accuracy: 0.5950 - val_loss: 0.9176 - val_accuracy: 0.5250\n",
      "Epoch 2043/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8316 - accuracy: 0.5981 - val_loss: 0.9221 - val_accuracy: 0.5250\n",
      "Epoch 2044/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8116 - accuracy: 0.6262 - val_loss: 0.8343 - val_accuracy: 0.5750\n",
      "Epoch 2045/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.7816 - accuracy: 0.6231 - val_loss: 0.8225 - val_accuracy: 0.5750\n",
      "Epoch 2046/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.8068 - accuracy: 0.6262 - val_loss: 0.9248 - val_accuracy: 0.5625\n",
      "Epoch 2047/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8164 - accuracy: 0.6199 - val_loss: 0.8574 - val_accuracy: 0.5875\n",
      "Epoch 2048/3000\n",
      "8/8 [==============================] - 1s 181ms/step - loss: 0.8415 - accuracy: 0.5981 - val_loss: 0.8458 - val_accuracy: 0.5625\n",
      "Epoch 2049/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8627 - accuracy: 0.5763 - val_loss: 0.8466 - val_accuracy: 0.5625\n",
      "Epoch 2050/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.8725 - accuracy: 0.5763 - val_loss: 0.8561 - val_accuracy: 0.5375\n",
      "Epoch 2051/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8529 - accuracy: 0.5888 - val_loss: 0.8326 - val_accuracy: 0.5500\n",
      "Epoch 2052/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8621 - accuracy: 0.6012 - val_loss: 0.8277 - val_accuracy: 0.6000\n",
      "Epoch 2053/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.8501 - accuracy: 0.5950 - val_loss: 0.8168 - val_accuracy: 0.5625\n",
      "Epoch 2054/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8150 - accuracy: 0.6199 - val_loss: 0.8292 - val_accuracy: 0.5625\n",
      "Epoch 2055/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.8216 - accuracy: 0.5888 - val_loss: 0.8758 - val_accuracy: 0.5875\n",
      "Epoch 2056/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8291 - accuracy: 0.6075 - val_loss: 0.9575 - val_accuracy: 0.4875\n",
      "Epoch 2057/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.9304 - accuracy: 0.5514 - val_loss: 0.8220 - val_accuracy: 0.5875\n",
      "Epoch 2058/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8582 - accuracy: 0.6199 - val_loss: 0.8271 - val_accuracy: 0.5875\n",
      "Epoch 2059/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8023 - accuracy: 0.6199 - val_loss: 0.8393 - val_accuracy: 0.5625\n",
      "Epoch 2060/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8902 - accuracy: 0.5981 - val_loss: 0.8933 - val_accuracy: 0.5750\n",
      "Epoch 2061/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8293 - accuracy: 0.6012 - val_loss: 0.8321 - val_accuracy: 0.5625\n",
      "Epoch 2062/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8589 - accuracy: 0.6044 - val_loss: 0.8219 - val_accuracy: 0.5875\n",
      "Epoch 2063/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.8852 - accuracy: 0.5857 - val_loss: 0.8373 - val_accuracy: 0.6000\n",
      "Epoch 2064/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8308 - accuracy: 0.6231 - val_loss: 0.8980 - val_accuracy: 0.5500\n",
      "Epoch 2065/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.8393 - accuracy: 0.6137 - val_loss: 0.8242 - val_accuracy: 0.5750\n",
      "Epoch 2066/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8408 - accuracy: 0.6137 - val_loss: 0.8473 - val_accuracy: 0.5500\n",
      "Epoch 2067/3000\n",
      "8/8 [==============================] - 1s 189ms/step - loss: 0.8450 - accuracy: 0.6075 - val_loss: 0.8349 - val_accuracy: 0.5375\n",
      "Epoch 2068/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8247 - accuracy: 0.5794 - val_loss: 0.8548 - val_accuracy: 0.5875\n",
      "Epoch 2069/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7797 - accuracy: 0.6449 - val_loss: 0.8307 - val_accuracy: 0.5625\n",
      "Epoch 2070/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8336 - accuracy: 0.5981 - val_loss: 0.8259 - val_accuracy: 0.5750\n",
      "Epoch 2071/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8805 - accuracy: 0.5981 - val_loss: 0.8785 - val_accuracy: 0.5375\n",
      "Epoch 2072/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.9297 - accuracy: 0.5452 - val_loss: 0.8336 - val_accuracy: 0.5750\n",
      "Epoch 2073/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8554 - accuracy: 0.5919 - val_loss: 0.8136 - val_accuracy: 0.5625\n",
      "Epoch 2074/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8418 - accuracy: 0.5888 - val_loss: 0.8723 - val_accuracy: 0.5500\n",
      "Epoch 2075/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8147 - accuracy: 0.6511 - val_loss: 0.8821 - val_accuracy: 0.5375\n",
      "Epoch 2076/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8179 - accuracy: 0.6199 - val_loss: 0.8281 - val_accuracy: 0.5625\n",
      "Epoch 2077/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.8783 - accuracy: 0.5794 - val_loss: 0.8122 - val_accuracy: 0.5875\n",
      "Epoch 2078/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8269 - accuracy: 0.5919 - val_loss: 0.8533 - val_accuracy: 0.5625\n",
      "Epoch 2079/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8565 - accuracy: 0.6075 - val_loss: 0.8379 - val_accuracy: 0.6125\n",
      "Epoch 2080/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.8595 - accuracy: 0.6137 - val_loss: 0.8545 - val_accuracy: 0.5500\n",
      "Epoch 2081/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7884 - accuracy: 0.6417 - val_loss: 0.9915 - val_accuracy: 0.5125\n",
      "Epoch 2082/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.9198 - accuracy: 0.5919 - val_loss: 0.8534 - val_accuracy: 0.6000\n",
      "Epoch 2083/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8578 - accuracy: 0.5857 - val_loss: 0.8447 - val_accuracy: 0.6250\n",
      "Epoch 2084/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.8606 - accuracy: 0.6137 - val_loss: 0.8735 - val_accuracy: 0.5625\n",
      "Epoch 2085/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8484 - accuracy: 0.6262 - val_loss: 0.8435 - val_accuracy: 0.5750\n",
      "Epoch 2086/3000\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.8605 - accuracy: 0.6012 - val_loss: 0.8092 - val_accuracy: 0.5875\n",
      "Epoch 2087/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.8373 - accuracy: 0.6075 - val_loss: 0.8104 - val_accuracy: 0.5875\n",
      "Epoch 2088/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.8434 - accuracy: 0.6012 - val_loss: 0.8106 - val_accuracy: 0.5750\n",
      "Epoch 2089/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.8286 - accuracy: 0.6075 - val_loss: 0.8019 - val_accuracy: 0.6000\n",
      "Epoch 2090/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8423 - accuracy: 0.6075 - val_loss: 0.7902 - val_accuracy: 0.5875\n",
      "Epoch 2091/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8505 - accuracy: 0.6044 - val_loss: 0.8211 - val_accuracy: 0.5750\n",
      "Epoch 2092/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8391 - accuracy: 0.5981 - val_loss: 0.7964 - val_accuracy: 0.6125\n",
      "Epoch 2093/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8493 - accuracy: 0.5950 - val_loss: 0.8248 - val_accuracy: 0.5750\n",
      "Epoch 2094/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.7907 - accuracy: 0.6199 - val_loss: 0.8783 - val_accuracy: 0.5625\n",
      "Epoch 2095/3000\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.8263 - accuracy: 0.6168 - val_loss: 0.8236 - val_accuracy: 0.5875\n",
      "Epoch 2096/3000\n",
      "8/8 [==============================] - 1s 188ms/step - loss: 0.8092 - accuracy: 0.5950 - val_loss: 0.8004 - val_accuracy: 0.5875\n",
      "Epoch 2097/3000\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 0.8351 - accuracy: 0.6293 - val_loss: 0.8848 - val_accuracy: 0.5375\n",
      "Epoch 2098/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8083 - accuracy: 0.6449 - val_loss: 0.7957 - val_accuracy: 0.5750\n",
      "Epoch 2099/3000\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 0.8211 - accuracy: 0.6199 - val_loss: 0.8621 - val_accuracy: 0.5625\n",
      "Epoch 2100/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8067 - accuracy: 0.6355 - val_loss: 0.9375 - val_accuracy: 0.5375\n",
      "Epoch 2101/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8242 - accuracy: 0.6324 - val_loss: 0.8311 - val_accuracy: 0.5750\n",
      "Epoch 2102/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8597 - accuracy: 0.5732 - val_loss: 0.8849 - val_accuracy: 0.5750\n",
      "Epoch 2103/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8751 - accuracy: 0.5826 - val_loss: 0.8144 - val_accuracy: 0.5750\n",
      "Epoch 2104/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8291 - accuracy: 0.5950 - val_loss: 0.8767 - val_accuracy: 0.5625\n",
      "Epoch 2105/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8391 - accuracy: 0.6199 - val_loss: 0.8663 - val_accuracy: 0.5750\n",
      "Epoch 2106/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.8589 - accuracy: 0.6044 - val_loss: 0.8707 - val_accuracy: 0.5625\n",
      "Epoch 2107/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8918 - accuracy: 0.5794 - val_loss: 0.8567 - val_accuracy: 0.5625\n",
      "Epoch 2108/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8552 - accuracy: 0.5919 - val_loss: 0.8606 - val_accuracy: 0.5375\n",
      "Epoch 2109/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.7950 - accuracy: 0.6106 - val_loss: 0.8399 - val_accuracy: 0.5125\n",
      "Epoch 2110/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8185 - accuracy: 0.6231 - val_loss: 0.8299 - val_accuracy: 0.5625\n",
      "Epoch 2111/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8269 - accuracy: 0.6168 - val_loss: 0.9182 - val_accuracy: 0.5375\n",
      "Epoch 2112/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8476 - accuracy: 0.6075 - val_loss: 0.8305 - val_accuracy: 0.6000\n",
      "Epoch 2113/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8446 - accuracy: 0.6012 - val_loss: 0.8003 - val_accuracy: 0.6000\n",
      "Epoch 2114/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8215 - accuracy: 0.6044 - val_loss: 0.8344 - val_accuracy: 0.6000\n",
      "Epoch 2115/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.9518 - accuracy: 0.5483 - val_loss: 0.8187 - val_accuracy: 0.6125\n",
      "Epoch 2116/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.8161 - accuracy: 0.6168 - val_loss: 0.8237 - val_accuracy: 0.5750\n",
      "Epoch 2117/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8352 - accuracy: 0.6012 - val_loss: 0.8792 - val_accuracy: 0.5750\n",
      "Epoch 2118/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8803 - accuracy: 0.5701 - val_loss: 0.8409 - val_accuracy: 0.5625\n",
      "Epoch 2119/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7975 - accuracy: 0.6324 - val_loss: 0.8052 - val_accuracy: 0.5625\n",
      "Epoch 2120/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8185 - accuracy: 0.6137 - val_loss: 0.8193 - val_accuracy: 0.5750\n",
      "Epoch 2121/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7992 - accuracy: 0.6324 - val_loss: 0.8192 - val_accuracy: 0.5875\n",
      "Epoch 2122/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7926 - accuracy: 0.6137 - val_loss: 0.7932 - val_accuracy: 0.5875\n",
      "Epoch 2123/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8134 - accuracy: 0.6106 - val_loss: 0.9322 - val_accuracy: 0.5625\n",
      "Epoch 2124/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8827 - accuracy: 0.5950 - val_loss: 0.8139 - val_accuracy: 0.5750\n",
      "Epoch 2125/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8645 - accuracy: 0.5857 - val_loss: 0.8534 - val_accuracy: 0.5875\n",
      "Epoch 2126/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8606 - accuracy: 0.5919 - val_loss: 0.7959 - val_accuracy: 0.6000\n",
      "Epoch 2127/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8206 - accuracy: 0.6044 - val_loss: 0.8173 - val_accuracy: 0.5750\n",
      "Epoch 2128/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7920 - accuracy: 0.6262 - val_loss: 0.9162 - val_accuracy: 0.5125\n",
      "Epoch 2129/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8570 - accuracy: 0.6075 - val_loss: 0.8282 - val_accuracy: 0.5750\n",
      "Epoch 2130/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8373 - accuracy: 0.6106 - val_loss: 0.8131 - val_accuracy: 0.5625\n",
      "Epoch 2131/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8351 - accuracy: 0.5888 - val_loss: 0.8286 - val_accuracy: 0.5875\n",
      "Epoch 2132/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8412 - accuracy: 0.5950 - val_loss: 0.8244 - val_accuracy: 0.5750\n",
      "Epoch 2133/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8522 - accuracy: 0.5981 - val_loss: 0.8129 - val_accuracy: 0.5875\n",
      "Epoch 2134/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8196 - accuracy: 0.6355 - val_loss: 0.8681 - val_accuracy: 0.5500\n",
      "Epoch 2135/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8473 - accuracy: 0.6075 - val_loss: 0.8684 - val_accuracy: 0.5750\n",
      "Epoch 2136/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8167 - accuracy: 0.6262 - val_loss: 0.8076 - val_accuracy: 0.6000\n",
      "Epoch 2137/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8511 - accuracy: 0.5919 - val_loss: 0.8130 - val_accuracy: 0.5875\n",
      "Epoch 2138/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8332 - accuracy: 0.5919 - val_loss: 0.8147 - val_accuracy: 0.6000\n",
      "Epoch 2139/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7832 - accuracy: 0.6386 - val_loss: 0.8230 - val_accuracy: 0.5625\n",
      "Epoch 2140/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8647 - accuracy: 0.6012 - val_loss: 0.8148 - val_accuracy: 0.5750\n",
      "Epoch 2141/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8473 - accuracy: 0.5919 - val_loss: 0.8100 - val_accuracy: 0.5500\n",
      "Epoch 2142/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8212 - accuracy: 0.5919 - val_loss: 0.8236 - val_accuracy: 0.5750\n",
      "Epoch 2143/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8135 - accuracy: 0.6293 - val_loss: 0.8136 - val_accuracy: 0.5750\n",
      "Epoch 2144/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8519 - accuracy: 0.5763 - val_loss: 0.8565 - val_accuracy: 0.6000\n",
      "Epoch 2145/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8256 - accuracy: 0.6137 - val_loss: 0.8099 - val_accuracy: 0.6000\n",
      "Epoch 2146/3000\n",
      "8/8 [==============================] - 1s 180ms/step - loss: 0.7846 - accuracy: 0.6199 - val_loss: 0.8400 - val_accuracy: 0.5625\n",
      "Epoch 2147/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8162 - accuracy: 0.6199 - val_loss: 0.8143 - val_accuracy: 0.6125\n",
      "Epoch 2148/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.8611 - accuracy: 0.5732 - val_loss: 0.9008 - val_accuracy: 0.5875\n",
      "Epoch 2149/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8580 - accuracy: 0.5919 - val_loss: 0.8294 - val_accuracy: 0.5875\n",
      "Epoch 2150/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8614 - accuracy: 0.6106 - val_loss: 0.8236 - val_accuracy: 0.6000\n",
      "Epoch 2151/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.8296 - accuracy: 0.6106 - val_loss: 0.8536 - val_accuracy: 0.5625\n",
      "Epoch 2152/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8199 - accuracy: 0.6324 - val_loss: 0.8353 - val_accuracy: 0.5750\n",
      "Epoch 2153/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8315 - accuracy: 0.6012 - val_loss: 0.8829 - val_accuracy: 0.5375\n",
      "Epoch 2154/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8351 - accuracy: 0.6137 - val_loss: 0.8210 - val_accuracy: 0.6000\n",
      "Epoch 2155/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8021 - accuracy: 0.5950 - val_loss: 0.8645 - val_accuracy: 0.5625\n",
      "Epoch 2156/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8260 - accuracy: 0.6293 - val_loss: 0.8091 - val_accuracy: 0.5625\n",
      "Epoch 2157/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8178 - accuracy: 0.6199 - val_loss: 0.8847 - val_accuracy: 0.5500\n",
      "Epoch 2158/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8514 - accuracy: 0.6012 - val_loss: 0.8049 - val_accuracy: 0.6125\n",
      "Epoch 2159/3000\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 0.8726 - accuracy: 0.6012 - val_loss: 0.8759 - val_accuracy: 0.5625\n",
      "Epoch 2160/3000\n",
      "8/8 [==============================] - 1s 180ms/step - loss: 0.8409 - accuracy: 0.6044 - val_loss: 0.8518 - val_accuracy: 0.5500\n",
      "Epoch 2161/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.8191 - accuracy: 0.6137 - val_loss: 0.9036 - val_accuracy: 0.5875\n",
      "Epoch 2162/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8338 - accuracy: 0.6199 - val_loss: 0.8700 - val_accuracy: 0.5625\n",
      "Epoch 2163/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8102 - accuracy: 0.6293 - val_loss: 0.9346 - val_accuracy: 0.5625\n",
      "Epoch 2164/3000\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 0.8241 - accuracy: 0.6075 - val_loss: 0.8345 - val_accuracy: 0.5500\n",
      "Epoch 2165/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8089 - accuracy: 0.6199 - val_loss: 0.8449 - val_accuracy: 0.5750\n",
      "Epoch 2166/3000\n",
      "8/8 [==============================] - 1s 181ms/step - loss: 0.8314 - accuracy: 0.5826 - val_loss: 0.8341 - val_accuracy: 0.5750\n",
      "Epoch 2167/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8133 - accuracy: 0.6199 - val_loss: 0.8474 - val_accuracy: 0.5750\n",
      "Epoch 2168/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8078 - accuracy: 0.6106 - val_loss: 0.8305 - val_accuracy: 0.5750\n",
      "Epoch 2169/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7875 - accuracy: 0.6106 - val_loss: 0.8522 - val_accuracy: 0.5625\n",
      "Epoch 2170/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.7909 - accuracy: 0.5981 - val_loss: 0.8646 - val_accuracy: 0.5875\n",
      "Epoch 2171/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8382 - accuracy: 0.6293 - val_loss: 0.8222 - val_accuracy: 0.6125\n",
      "Epoch 2172/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8518 - accuracy: 0.5826 - val_loss: 0.8229 - val_accuracy: 0.5625\n",
      "Epoch 2173/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8229 - accuracy: 0.6012 - val_loss: 0.8919 - val_accuracy: 0.5625\n",
      "Epoch 2174/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8672 - accuracy: 0.5919 - val_loss: 0.8509 - val_accuracy: 0.5750\n",
      "Epoch 2175/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.8260 - accuracy: 0.6012 - val_loss: 0.8483 - val_accuracy: 0.6000\n",
      "Epoch 2176/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7962 - accuracy: 0.6168 - val_loss: 0.8642 - val_accuracy: 0.5875\n",
      "Epoch 2177/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8347 - accuracy: 0.6075 - val_loss: 0.8312 - val_accuracy: 0.5750\n",
      "Epoch 2178/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8056 - accuracy: 0.6137 - val_loss: 0.8413 - val_accuracy: 0.5750\n",
      "Epoch 2179/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8237 - accuracy: 0.6044 - val_loss: 0.8866 - val_accuracy: 0.6000\n",
      "Epoch 2180/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8454 - accuracy: 0.5950 - val_loss: 0.8846 - val_accuracy: 0.5375\n",
      "Epoch 2181/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8553 - accuracy: 0.6137 - val_loss: 0.8150 - val_accuracy: 0.5750\n",
      "Epoch 2182/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.8157 - accuracy: 0.6231 - val_loss: 0.8611 - val_accuracy: 0.5750\n",
      "Epoch 2183/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8227 - accuracy: 0.6262 - val_loss: 0.8226 - val_accuracy: 0.5750\n",
      "Epoch 2184/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.8387 - accuracy: 0.6012 - val_loss: 0.8079 - val_accuracy: 0.6000\n",
      "Epoch 2185/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7805 - accuracy: 0.6604 - val_loss: 0.8250 - val_accuracy: 0.5750\n",
      "Epoch 2186/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8554 - accuracy: 0.6044 - val_loss: 0.8274 - val_accuracy: 0.6000\n",
      "Epoch 2187/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.8036 - accuracy: 0.6324 - val_loss: 0.8624 - val_accuracy: 0.5875\n",
      "Epoch 2188/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.8312 - accuracy: 0.6075 - val_loss: 0.8234 - val_accuracy: 0.6250\n",
      "Epoch 2189/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8377 - accuracy: 0.6168 - val_loss: 0.8347 - val_accuracy: 0.5750\n",
      "Epoch 2190/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7986 - accuracy: 0.6106 - val_loss: 0.7989 - val_accuracy: 0.5875\n",
      "Epoch 2191/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8310 - accuracy: 0.5857 - val_loss: 0.8383 - val_accuracy: 0.5875\n",
      "Epoch 2192/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8508 - accuracy: 0.5950 - val_loss: 0.8273 - val_accuracy: 0.6125\n",
      "Epoch 2193/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7880 - accuracy: 0.6137 - val_loss: 0.8351 - val_accuracy: 0.5500\n",
      "Epoch 2194/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.7836 - accuracy: 0.6293 - val_loss: 0.8220 - val_accuracy: 0.5625\n",
      "Epoch 2195/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8229 - accuracy: 0.6106 - val_loss: 0.8209 - val_accuracy: 0.5750\n",
      "Epoch 2196/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7620 - accuracy: 0.6293 - val_loss: 0.8441 - val_accuracy: 0.6125\n",
      "Epoch 2197/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8412 - accuracy: 0.5919 - val_loss: 0.8237 - val_accuracy: 0.6125\n",
      "Epoch 2198/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8327 - accuracy: 0.6231 - val_loss: 0.8287 - val_accuracy: 0.5875\n",
      "Epoch 2199/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8133 - accuracy: 0.6106 - val_loss: 0.8288 - val_accuracy: 0.6000\n",
      "Epoch 2200/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8173 - accuracy: 0.6137 - val_loss: 0.8003 - val_accuracy: 0.6000\n",
      "Epoch 2201/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7505 - accuracy: 0.6573 - val_loss: 0.8410 - val_accuracy: 0.6000\n",
      "Epoch 2202/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8430 - accuracy: 0.6012 - val_loss: 0.8375 - val_accuracy: 0.5750\n",
      "Epoch 2203/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8378 - accuracy: 0.6075 - val_loss: 0.8431 - val_accuracy: 0.5875\n",
      "Epoch 2204/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.8281 - accuracy: 0.5981 - val_loss: 0.8370 - val_accuracy: 0.6000\n",
      "Epoch 2205/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8261 - accuracy: 0.6262 - val_loss: 0.8588 - val_accuracy: 0.5750\n",
      "Epoch 2206/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8339 - accuracy: 0.6106 - val_loss: 0.8568 - val_accuracy: 0.5875\n",
      "Epoch 2207/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.8395 - accuracy: 0.6231 - val_loss: 0.8550 - val_accuracy: 0.6000\n",
      "Epoch 2208/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8065 - accuracy: 0.6386 - val_loss: 0.8178 - val_accuracy: 0.5875\n",
      "Epoch 2209/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.7950 - accuracy: 0.6293 - val_loss: 0.8309 - val_accuracy: 0.5875\n",
      "Epoch 2210/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.7892 - accuracy: 0.6168 - val_loss: 0.8072 - val_accuracy: 0.5875\n",
      "Epoch 2211/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8156 - accuracy: 0.6075 - val_loss: 0.8082 - val_accuracy: 0.5625\n",
      "Epoch 2212/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8500 - accuracy: 0.6075 - val_loss: 0.8210 - val_accuracy: 0.6125\n",
      "Epoch 2213/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8222 - accuracy: 0.5950 - val_loss: 0.8078 - val_accuracy: 0.6000\n",
      "Epoch 2214/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.9023 - accuracy: 0.5857 - val_loss: 0.7990 - val_accuracy: 0.5875\n",
      "Epoch 2215/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8151 - accuracy: 0.6355 - val_loss: 0.8424 - val_accuracy: 0.5500\n",
      "Epoch 2216/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.8652 - accuracy: 0.5981 - val_loss: 0.8235 - val_accuracy: 0.5875\n",
      "Epoch 2217/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8598 - accuracy: 0.5794 - val_loss: 0.8323 - val_accuracy: 0.6250\n",
      "Epoch 2218/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8657 - accuracy: 0.6012 - val_loss: 0.8056 - val_accuracy: 0.5750\n",
      "Epoch 2219/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8377 - accuracy: 0.6075 - val_loss: 0.9259 - val_accuracy: 0.5375\n",
      "Epoch 2220/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8916 - accuracy: 0.5670 - val_loss: 0.8376 - val_accuracy: 0.6000\n",
      "Epoch 2221/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8048 - accuracy: 0.6199 - val_loss: 0.8951 - val_accuracy: 0.5500\n",
      "Epoch 2222/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7748 - accuracy: 0.6449 - val_loss: 0.7962 - val_accuracy: 0.5875\n",
      "Epoch 2223/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8208 - accuracy: 0.6106 - val_loss: 0.8087 - val_accuracy: 0.6000\n",
      "Epoch 2224/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8595 - accuracy: 0.6199 - val_loss: 0.8126 - val_accuracy: 0.5625\n",
      "Epoch 2225/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8189 - accuracy: 0.6106 - val_loss: 0.8436 - val_accuracy: 0.5625\n",
      "Epoch 2226/3000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.8043 - accuracy: 0.6199 - val_loss: 0.8325 - val_accuracy: 0.5875\n",
      "Epoch 2227/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.8231 - accuracy: 0.6044 - val_loss: 0.7952 - val_accuracy: 0.5875\n",
      "Epoch 2228/3000\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.8482 - accuracy: 0.6044 - val_loss: 0.8742 - val_accuracy: 0.5625\n",
      "Epoch 2229/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8409 - accuracy: 0.6012 - val_loss: 0.8330 - val_accuracy: 0.5750\n",
      "Epoch 2230/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.8059 - accuracy: 0.6137 - val_loss: 0.8269 - val_accuracy: 0.5875\n",
      "Epoch 2231/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.8208 - accuracy: 0.6075 - val_loss: 0.8106 - val_accuracy: 0.5750\n",
      "Epoch 2232/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8302 - accuracy: 0.6075 - val_loss: 0.8352 - val_accuracy: 0.5875\n",
      "Epoch 2233/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.8271 - accuracy: 0.6199 - val_loss: 0.8342 - val_accuracy: 0.5750\n",
      "Epoch 2234/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.7919 - accuracy: 0.6386 - val_loss: 0.8048 - val_accuracy: 0.5875\n",
      "Epoch 2235/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8105 - accuracy: 0.6106 - val_loss: 0.8438 - val_accuracy: 0.6250\n",
      "Epoch 2236/3000\n",
      "8/8 [==============================] - 1s 181ms/step - loss: 0.8582 - accuracy: 0.5732 - val_loss: 0.8368 - val_accuracy: 0.5750\n",
      "Epoch 2237/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8224 - accuracy: 0.6075 - val_loss: 0.8993 - val_accuracy: 0.5875\n",
      "Epoch 2238/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8501 - accuracy: 0.6012 - val_loss: 0.7766 - val_accuracy: 0.5750\n",
      "Epoch 2239/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8304 - accuracy: 0.6231 - val_loss: 0.8224 - val_accuracy: 0.5750\n",
      "Epoch 2240/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8238 - accuracy: 0.5888 - val_loss: 0.7833 - val_accuracy: 0.5750\n",
      "Epoch 2241/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.8381 - accuracy: 0.6012 - val_loss: 0.8181 - val_accuracy: 0.5750\n",
      "Epoch 2242/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8207 - accuracy: 0.6044 - val_loss: 0.8013 - val_accuracy: 0.5875\n",
      "Epoch 2243/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8080 - accuracy: 0.6262 - val_loss: 0.8167 - val_accuracy: 0.6125\n",
      "Epoch 2244/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8644 - accuracy: 0.6168 - val_loss: 0.8341 - val_accuracy: 0.5750\n",
      "Epoch 2245/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7652 - accuracy: 0.6417 - val_loss: 0.7962 - val_accuracy: 0.5750\n",
      "Epoch 2246/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8186 - accuracy: 0.6075 - val_loss: 0.7968 - val_accuracy: 0.5875\n",
      "Epoch 2247/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.7888 - accuracy: 0.6324 - val_loss: 0.8459 - val_accuracy: 0.5875\n",
      "Epoch 2248/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7971 - accuracy: 0.6137 - val_loss: 0.7995 - val_accuracy: 0.6000\n",
      "Epoch 2249/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8415 - accuracy: 0.6262 - val_loss: 0.8187 - val_accuracy: 0.5875\n",
      "Epoch 2250/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8088 - accuracy: 0.6324 - val_loss: 0.8339 - val_accuracy: 0.6000\n",
      "Epoch 2251/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7646 - accuracy: 0.6480 - val_loss: 0.8113 - val_accuracy: 0.6125\n",
      "Epoch 2252/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8532 - accuracy: 0.5919 - val_loss: 0.8574 - val_accuracy: 0.5875\n",
      "Epoch 2253/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.8327 - accuracy: 0.5701 - val_loss: 0.8149 - val_accuracy: 0.6000\n",
      "Epoch 2254/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8338 - accuracy: 0.6168 - val_loss: 0.7990 - val_accuracy: 0.5875\n",
      "Epoch 2255/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7841 - accuracy: 0.6106 - val_loss: 0.8277 - val_accuracy: 0.6000\n",
      "Epoch 2256/3000\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 0.8803 - accuracy: 0.5701 - val_loss: 0.7936 - val_accuracy: 0.5750\n",
      "Epoch 2257/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8263 - accuracy: 0.6012 - val_loss: 0.8171 - val_accuracy: 0.5875\n",
      "Epoch 2258/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8149 - accuracy: 0.6199 - val_loss: 0.8546 - val_accuracy: 0.5875\n",
      "Epoch 2259/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8174 - accuracy: 0.6199 - val_loss: 0.8546 - val_accuracy: 0.5875\n",
      "Epoch 2260/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7789 - accuracy: 0.6293 - val_loss: 0.8668 - val_accuracy: 0.5875\n",
      "Epoch 2261/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8000 - accuracy: 0.6293 - val_loss: 0.7979 - val_accuracy: 0.5625\n",
      "Epoch 2262/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.7796 - accuracy: 0.6293 - val_loss: 0.8114 - val_accuracy: 0.6000\n",
      "Epoch 2263/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.8000 - accuracy: 0.6449 - val_loss: 0.8219 - val_accuracy: 0.6125\n",
      "Epoch 2264/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8499 - accuracy: 0.6075 - val_loss: 0.8756 - val_accuracy: 0.6000\n",
      "Epoch 2265/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.8445 - accuracy: 0.5888 - val_loss: 0.8340 - val_accuracy: 0.5875\n",
      "Epoch 2266/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7914 - accuracy: 0.6604 - val_loss: 0.8165 - val_accuracy: 0.6000\n",
      "Epoch 2267/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8118 - accuracy: 0.6168 - val_loss: 0.8189 - val_accuracy: 0.6125\n",
      "Epoch 2268/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8341 - accuracy: 0.6199 - val_loss: 0.8362 - val_accuracy: 0.6125\n",
      "Epoch 2269/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7781 - accuracy: 0.6324 - val_loss: 0.8137 - val_accuracy: 0.6125\n",
      "Epoch 2270/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8198 - accuracy: 0.6449 - val_loss: 0.8086 - val_accuracy: 0.5875\n",
      "Epoch 2271/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8206 - accuracy: 0.6449 - val_loss: 0.8031 - val_accuracy: 0.5750\n",
      "Epoch 2272/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.8331 - accuracy: 0.6168 - val_loss: 0.8189 - val_accuracy: 0.6125\n",
      "Epoch 2273/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8089 - accuracy: 0.6293 - val_loss: 0.8315 - val_accuracy: 0.5875\n",
      "Epoch 2274/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8527 - accuracy: 0.6075 - val_loss: 0.7985 - val_accuracy: 0.5875\n",
      "Epoch 2275/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8623 - accuracy: 0.6044 - val_loss: 0.8459 - val_accuracy: 0.5750\n",
      "Epoch 2276/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8232 - accuracy: 0.6044 - val_loss: 0.8061 - val_accuracy: 0.6000\n",
      "Epoch 2277/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8157 - accuracy: 0.6106 - val_loss: 0.8530 - val_accuracy: 0.5500\n",
      "Epoch 2278/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.8123 - accuracy: 0.6106 - val_loss: 0.8227 - val_accuracy: 0.6000\n",
      "Epoch 2279/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8010 - accuracy: 0.6355 - val_loss: 0.8059 - val_accuracy: 0.5750\n",
      "Epoch 2280/3000\n",
      "8/8 [==============================] - 1s 180ms/step - loss: 0.8328 - accuracy: 0.6137 - val_loss: 0.8393 - val_accuracy: 0.5500\n",
      "Epoch 2281/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8527 - accuracy: 0.5857 - val_loss: 0.8408 - val_accuracy: 0.6000\n",
      "Epoch 2282/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8556 - accuracy: 0.6106 - val_loss: 0.8615 - val_accuracy: 0.5875\n",
      "Epoch 2283/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.8435 - accuracy: 0.6106 - val_loss: 0.8340 - val_accuracy: 0.5750\n",
      "Epoch 2284/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7821 - accuracy: 0.6293 - val_loss: 0.8221 - val_accuracy: 0.6000\n",
      "Epoch 2285/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7966 - accuracy: 0.6542 - val_loss: 0.8080 - val_accuracy: 0.6000\n",
      "Epoch 2286/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8258 - accuracy: 0.6324 - val_loss: 0.8420 - val_accuracy: 0.5875\n",
      "Epoch 2287/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8123 - accuracy: 0.6449 - val_loss: 0.8427 - val_accuracy: 0.5750\n",
      "Epoch 2288/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8106 - accuracy: 0.6012 - val_loss: 0.8155 - val_accuracy: 0.5750\n",
      "Epoch 2289/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8413 - accuracy: 0.5950 - val_loss: 0.8622 - val_accuracy: 0.5500\n",
      "Epoch 2290/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8059 - accuracy: 0.6417 - val_loss: 0.8010 - val_accuracy: 0.5750\n",
      "Epoch 2291/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8715 - accuracy: 0.5607 - val_loss: 0.8088 - val_accuracy: 0.5750\n",
      "Epoch 2292/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.8127 - accuracy: 0.6012 - val_loss: 0.8236 - val_accuracy: 0.6000\n",
      "Epoch 2293/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8076 - accuracy: 0.6199 - val_loss: 0.8573 - val_accuracy: 0.6000\n",
      "Epoch 2294/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8370 - accuracy: 0.5981 - val_loss: 0.8276 - val_accuracy: 0.5625\n",
      "Epoch 2295/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7712 - accuracy: 0.6480 - val_loss: 0.7980 - val_accuracy: 0.5500\n",
      "Epoch 2296/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8047 - accuracy: 0.6293 - val_loss: 0.8067 - val_accuracy: 0.5750\n",
      "Epoch 2297/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8225 - accuracy: 0.6293 - val_loss: 0.8064 - val_accuracy: 0.5875\n",
      "Epoch 2298/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8647 - accuracy: 0.5919 - val_loss: 0.8659 - val_accuracy: 0.5875\n",
      "Epoch 2299/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8281 - accuracy: 0.6293 - val_loss: 0.8295 - val_accuracy: 0.6000\n",
      "Epoch 2300/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8367 - accuracy: 0.5794 - val_loss: 0.8155 - val_accuracy: 0.5750\n",
      "Epoch 2301/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.8033 - accuracy: 0.6542 - val_loss: 0.8302 - val_accuracy: 0.5750\n",
      "Epoch 2302/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7741 - accuracy: 0.6417 - val_loss: 0.8038 - val_accuracy: 0.6000\n",
      "Epoch 2303/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7320 - accuracy: 0.6573 - val_loss: 0.8338 - val_accuracy: 0.6000\n",
      "Epoch 2304/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8092 - accuracy: 0.6075 - val_loss: 0.7868 - val_accuracy: 0.5750\n",
      "Epoch 2305/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8768 - accuracy: 0.5950 - val_loss: 0.8167 - val_accuracy: 0.6125\n",
      "Epoch 2306/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8114 - accuracy: 0.6199 - val_loss: 0.7984 - val_accuracy: 0.6000\n",
      "Epoch 2307/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.8038 - accuracy: 0.5888 - val_loss: 0.8207 - val_accuracy: 0.6000\n",
      "Epoch 2308/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7441 - accuracy: 0.6573 - val_loss: 0.7822 - val_accuracy: 0.6000\n",
      "Epoch 2309/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8338 - accuracy: 0.6231 - val_loss: 0.8606 - val_accuracy: 0.5750\n",
      "Epoch 2310/3000\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.8264 - accuracy: 0.5981 - val_loss: 0.7904 - val_accuracy: 0.6000\n",
      "Epoch 2311/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7692 - accuracy: 0.6449 - val_loss: 0.8416 - val_accuracy: 0.5875\n",
      "Epoch 2312/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7962 - accuracy: 0.6417 - val_loss: 0.8239 - val_accuracy: 0.5875\n",
      "Epoch 2313/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8113 - accuracy: 0.6137 - val_loss: 0.8211 - val_accuracy: 0.6000\n",
      "Epoch 2314/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.8538 - accuracy: 0.5950 - val_loss: 0.8458 - val_accuracy: 0.6000\n",
      "Epoch 2315/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8010 - accuracy: 0.6449 - val_loss: 0.8251 - val_accuracy: 0.5750\n",
      "Epoch 2316/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7605 - accuracy: 0.6667 - val_loss: 0.8645 - val_accuracy: 0.6000\n",
      "Epoch 2317/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8199 - accuracy: 0.6075 - val_loss: 0.8090 - val_accuracy: 0.6000\n",
      "Epoch 2318/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7749 - accuracy: 0.6511 - val_loss: 0.8278 - val_accuracy: 0.5750\n",
      "Epoch 2319/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8099 - accuracy: 0.6231 - val_loss: 0.8629 - val_accuracy: 0.5875\n",
      "Epoch 2320/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8157 - accuracy: 0.6262 - val_loss: 0.8043 - val_accuracy: 0.5750\n",
      "Epoch 2321/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8325 - accuracy: 0.6106 - val_loss: 0.8240 - val_accuracy: 0.6250\n",
      "Epoch 2322/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7909 - accuracy: 0.6293 - val_loss: 0.8549 - val_accuracy: 0.6000\n",
      "Epoch 2323/3000\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 0.8080 - accuracy: 0.6324 - val_loss: 0.8268 - val_accuracy: 0.6125\n",
      "Epoch 2324/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7944 - accuracy: 0.6324 - val_loss: 0.8149 - val_accuracy: 0.6250\n",
      "Epoch 2325/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8076 - accuracy: 0.6231 - val_loss: 0.8300 - val_accuracy: 0.6000\n",
      "Epoch 2326/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.7923 - accuracy: 0.6199 - val_loss: 0.8435 - val_accuracy: 0.6250\n",
      "Epoch 2327/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.8582 - accuracy: 0.5888 - val_loss: 0.8371 - val_accuracy: 0.5750\n",
      "Epoch 2328/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.8175 - accuracy: 0.6324 - val_loss: 0.8555 - val_accuracy: 0.6000\n",
      "Epoch 2329/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8012 - accuracy: 0.6199 - val_loss: 0.7803 - val_accuracy: 0.5875\n",
      "Epoch 2330/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.7955 - accuracy: 0.6355 - val_loss: 0.8188 - val_accuracy: 0.6250\n",
      "Epoch 2331/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7446 - accuracy: 0.6604 - val_loss: 0.8255 - val_accuracy: 0.6000\n",
      "Epoch 2332/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8074 - accuracy: 0.6168 - val_loss: 0.8658 - val_accuracy: 0.5750\n",
      "Epoch 2333/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8010 - accuracy: 0.6262 - val_loss: 0.7840 - val_accuracy: 0.6125\n",
      "Epoch 2334/3000\n",
      "8/8 [==============================] - 1s 180ms/step - loss: 0.8025 - accuracy: 0.6262 - val_loss: 0.8325 - val_accuracy: 0.6000\n",
      "Epoch 2335/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7979 - accuracy: 0.6199 - val_loss: 0.8462 - val_accuracy: 0.5750\n",
      "Epoch 2336/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7762 - accuracy: 0.6324 - val_loss: 0.8397 - val_accuracy: 0.6000\n",
      "Epoch 2337/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8341 - accuracy: 0.5826 - val_loss: 0.9012 - val_accuracy: 0.5375\n",
      "Epoch 2338/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8140 - accuracy: 0.6044 - val_loss: 0.8461 - val_accuracy: 0.6125\n",
      "Epoch 2339/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8113 - accuracy: 0.6355 - val_loss: 0.8066 - val_accuracy: 0.5750\n",
      "Epoch 2340/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7991 - accuracy: 0.6137 - val_loss: 0.8079 - val_accuracy: 0.6000\n",
      "Epoch 2341/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.8097 - accuracy: 0.6075 - val_loss: 0.8723 - val_accuracy: 0.5625\n",
      "Epoch 2342/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7729 - accuracy: 0.6137 - val_loss: 0.8873 - val_accuracy: 0.5625\n",
      "Epoch 2343/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.8094 - accuracy: 0.6044 - val_loss: 0.8705 - val_accuracy: 0.5750\n",
      "Epoch 2344/3000\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 0.8112 - accuracy: 0.6262 - val_loss: 0.8236 - val_accuracy: 0.5750\n",
      "Epoch 2345/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8277 - accuracy: 0.6324 - val_loss: 0.8529 - val_accuracy: 0.6000\n",
      "Epoch 2346/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8635 - accuracy: 0.6012 - val_loss: 0.8284 - val_accuracy: 0.5625\n",
      "Epoch 2347/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8172 - accuracy: 0.6075 - val_loss: 0.8524 - val_accuracy: 0.5500\n",
      "Epoch 2348/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8341 - accuracy: 0.6106 - val_loss: 0.8147 - val_accuracy: 0.5750\n",
      "Epoch 2349/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7702 - accuracy: 0.6199 - val_loss: 0.7986 - val_accuracy: 0.6125\n",
      "Epoch 2350/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8021 - accuracy: 0.6231 - val_loss: 0.8209 - val_accuracy: 0.6000\n",
      "Epoch 2351/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8337 - accuracy: 0.6199 - val_loss: 0.8468 - val_accuracy: 0.5875\n",
      "Epoch 2352/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.8144 - accuracy: 0.5919 - val_loss: 0.8430 - val_accuracy: 0.6250\n",
      "Epoch 2353/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7794 - accuracy: 0.6386 - val_loss: 0.8067 - val_accuracy: 0.6375\n",
      "Epoch 2354/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7667 - accuracy: 0.6293 - val_loss: 0.8135 - val_accuracy: 0.6000\n",
      "Epoch 2355/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8408 - accuracy: 0.6075 - val_loss: 0.8304 - val_accuracy: 0.5875\n",
      "Epoch 2356/3000\n",
      "8/8 [==============================] - 1s 183ms/step - loss: 0.8025 - accuracy: 0.6044 - val_loss: 0.8201 - val_accuracy: 0.6125\n",
      "Epoch 2357/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7683 - accuracy: 0.6106 - val_loss: 0.8489 - val_accuracy: 0.6125\n",
      "Epoch 2358/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7765 - accuracy: 0.6480 - val_loss: 0.8348 - val_accuracy: 0.6250\n",
      "Epoch 2359/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7844 - accuracy: 0.6293 - val_loss: 0.8485 - val_accuracy: 0.6125\n",
      "Epoch 2360/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7724 - accuracy: 0.6324 - val_loss: 0.7955 - val_accuracy: 0.6125\n",
      "Epoch 2361/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.8005 - accuracy: 0.6417 - val_loss: 0.7825 - val_accuracy: 0.6125\n",
      "Epoch 2362/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.8252 - accuracy: 0.6262 - val_loss: 0.7955 - val_accuracy: 0.6250\n",
      "Epoch 2363/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7695 - accuracy: 0.6386 - val_loss: 0.8399 - val_accuracy: 0.5875\n",
      "Epoch 2364/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7934 - accuracy: 0.6262 - val_loss: 0.7998 - val_accuracy: 0.5875\n",
      "Epoch 2365/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8181 - accuracy: 0.6106 - val_loss: 0.7960 - val_accuracy: 0.5875\n",
      "Epoch 2366/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7791 - accuracy: 0.6355 - val_loss: 0.8022 - val_accuracy: 0.5875\n",
      "Epoch 2367/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8309 - accuracy: 0.6137 - val_loss: 0.8875 - val_accuracy: 0.5875\n",
      "Epoch 2368/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8454 - accuracy: 0.6106 - val_loss: 0.8191 - val_accuracy: 0.6125\n",
      "Epoch 2369/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7558 - accuracy: 0.6573 - val_loss: 0.8020 - val_accuracy: 0.6250\n",
      "Epoch 2370/3000\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 0.9045 - accuracy: 0.5919 - val_loss: 0.8327 - val_accuracy: 0.5875\n",
      "Epoch 2371/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8027 - accuracy: 0.6106 - val_loss: 0.8333 - val_accuracy: 0.5875\n",
      "Epoch 2372/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7810 - accuracy: 0.6604 - val_loss: 0.7975 - val_accuracy: 0.6000\n",
      "Epoch 2373/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8071 - accuracy: 0.5950 - val_loss: 0.8019 - val_accuracy: 0.6250\n",
      "Epoch 2374/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8229 - accuracy: 0.6106 - val_loss: 0.7755 - val_accuracy: 0.6000\n",
      "Epoch 2375/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8033 - accuracy: 0.6480 - val_loss: 0.7968 - val_accuracy: 0.6125\n",
      "Epoch 2376/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.8278 - accuracy: 0.6137 - val_loss: 0.8150 - val_accuracy: 0.5875\n",
      "Epoch 2377/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7965 - accuracy: 0.6137 - val_loss: 0.7860 - val_accuracy: 0.6000\n",
      "Epoch 2378/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8170 - accuracy: 0.6293 - val_loss: 0.8076 - val_accuracy: 0.5875\n",
      "Epoch 2379/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7676 - accuracy: 0.6386 - val_loss: 0.8378 - val_accuracy: 0.6000\n",
      "Epoch 2380/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.7479 - accuracy: 0.6667 - val_loss: 0.8089 - val_accuracy: 0.5875\n",
      "Epoch 2381/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8171 - accuracy: 0.6231 - val_loss: 0.8304 - val_accuracy: 0.5750\n",
      "Epoch 2382/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.8285 - accuracy: 0.5826 - val_loss: 0.8095 - val_accuracy: 0.5625\n",
      "Epoch 2383/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8529 - accuracy: 0.6137 - val_loss: 0.8240 - val_accuracy: 0.5875\n",
      "Epoch 2384/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8012 - accuracy: 0.6293 - val_loss: 0.8243 - val_accuracy: 0.5875\n",
      "Epoch 2385/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8028 - accuracy: 0.6137 - val_loss: 0.8331 - val_accuracy: 0.6000\n",
      "Epoch 2386/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7532 - accuracy: 0.6355 - val_loss: 0.8459 - val_accuracy: 0.6125\n",
      "Epoch 2387/3000\n",
      "8/8 [==============================] - 1s 184ms/step - loss: 0.7912 - accuracy: 0.6417 - val_loss: 0.7855 - val_accuracy: 0.5750\n",
      "Epoch 2388/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8291 - accuracy: 0.6137 - val_loss: 0.8296 - val_accuracy: 0.6125\n",
      "Epoch 2389/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8045 - accuracy: 0.6449 - val_loss: 0.8203 - val_accuracy: 0.6000\n",
      "Epoch 2390/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7500 - accuracy: 0.6480 - val_loss: 0.7921 - val_accuracy: 0.6125\n",
      "Epoch 2391/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7413 - accuracy: 0.6698 - val_loss: 0.7765 - val_accuracy: 0.6250\n",
      "Epoch 2392/3000\n",
      "8/8 [==============================] - 1s 180ms/step - loss: 0.7629 - accuracy: 0.6449 - val_loss: 0.8018 - val_accuracy: 0.6250\n",
      "Epoch 2393/3000\n",
      "8/8 [==============================] - 1s 180ms/step - loss: 0.8025 - accuracy: 0.6231 - val_loss: 0.8287 - val_accuracy: 0.6125\n",
      "Epoch 2394/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7485 - accuracy: 0.6636 - val_loss: 0.8306 - val_accuracy: 0.6125\n",
      "Epoch 2395/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8240 - accuracy: 0.6355 - val_loss: 0.8041 - val_accuracy: 0.6000\n",
      "Epoch 2396/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8998 - accuracy: 0.5701 - val_loss: 1.0551 - val_accuracy: 0.4625\n",
      "Epoch 2397/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8842 - accuracy: 0.5607 - val_loss: 0.8208 - val_accuracy: 0.6375\n",
      "Epoch 2398/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8481 - accuracy: 0.6075 - val_loss: 0.8073 - val_accuracy: 0.6125\n",
      "Epoch 2399/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7822 - accuracy: 0.6573 - val_loss: 0.8678 - val_accuracy: 0.5750\n",
      "Epoch 2400/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8428 - accuracy: 0.5763 - val_loss: 0.9039 - val_accuracy: 0.5625\n",
      "Epoch 2401/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7640 - accuracy: 0.6386 - val_loss: 0.7930 - val_accuracy: 0.5875\n",
      "Epoch 2402/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8215 - accuracy: 0.6168 - val_loss: 0.8393 - val_accuracy: 0.5875\n",
      "Epoch 2403/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7698 - accuracy: 0.6417 - val_loss: 0.7936 - val_accuracy: 0.6000\n",
      "Epoch 2404/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8070 - accuracy: 0.6137 - val_loss: 0.8557 - val_accuracy: 0.6125\n",
      "Epoch 2405/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7949 - accuracy: 0.6355 - val_loss: 0.8030 - val_accuracy: 0.6000\n",
      "Epoch 2406/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7529 - accuracy: 0.6511 - val_loss: 0.8273 - val_accuracy: 0.6250\n",
      "Epoch 2407/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7860 - accuracy: 0.6262 - val_loss: 0.8030 - val_accuracy: 0.5875\n",
      "Epoch 2408/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7973 - accuracy: 0.6324 - val_loss: 0.8537 - val_accuracy: 0.6000\n",
      "Epoch 2409/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7956 - accuracy: 0.6480 - val_loss: 0.8003 - val_accuracy: 0.6125\n",
      "Epoch 2410/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.7985 - accuracy: 0.6262 - val_loss: 0.8127 - val_accuracy: 0.6250\n",
      "Epoch 2411/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7929 - accuracy: 0.6168 - val_loss: 0.8034 - val_accuracy: 0.6125\n",
      "Epoch 2412/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7935 - accuracy: 0.6386 - val_loss: 0.8025 - val_accuracy: 0.6250\n",
      "Epoch 2413/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7882 - accuracy: 0.6293 - val_loss: 0.7961 - val_accuracy: 0.6000\n",
      "Epoch 2414/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7863 - accuracy: 0.6137 - val_loss: 0.8011 - val_accuracy: 0.6125\n",
      "Epoch 2415/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7784 - accuracy: 0.6449 - val_loss: 0.7846 - val_accuracy: 0.6125\n",
      "Epoch 2416/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8236 - accuracy: 0.6231 - val_loss: 0.7902 - val_accuracy: 0.5875\n",
      "Epoch 2417/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.8135 - accuracy: 0.6293 - val_loss: 0.8237 - val_accuracy: 0.6000\n",
      "Epoch 2418/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7581 - accuracy: 0.6386 - val_loss: 0.8279 - val_accuracy: 0.5875\n",
      "Epoch 2419/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7383 - accuracy: 0.6604 - val_loss: 0.8469 - val_accuracy: 0.5875\n",
      "Epoch 2420/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.8341 - accuracy: 0.5950 - val_loss: 0.8209 - val_accuracy: 0.6000\n",
      "Epoch 2421/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7568 - accuracy: 0.6293 - val_loss: 0.8336 - val_accuracy: 0.6125\n",
      "Epoch 2422/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.7793 - accuracy: 0.6355 - val_loss: 0.7740 - val_accuracy: 0.5875\n",
      "Epoch 2423/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7768 - accuracy: 0.6636 - val_loss: 0.7863 - val_accuracy: 0.5875\n",
      "Epoch 2424/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7884 - accuracy: 0.6573 - val_loss: 0.8334 - val_accuracy: 0.5875\n",
      "Epoch 2425/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7796 - accuracy: 0.6511 - val_loss: 0.8105 - val_accuracy: 0.6000\n",
      "Epoch 2426/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.8304 - accuracy: 0.6262 - val_loss: 0.8217 - val_accuracy: 0.6125\n",
      "Epoch 2427/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8113 - accuracy: 0.6262 - val_loss: 0.8637 - val_accuracy: 0.6000\n",
      "Epoch 2428/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.7855 - accuracy: 0.6075 - val_loss: 0.8558 - val_accuracy: 0.6000\n",
      "Epoch 2429/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.8078 - accuracy: 0.6075 - val_loss: 0.8088 - val_accuracy: 0.6250\n",
      "Epoch 2430/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7693 - accuracy: 0.6542 - val_loss: 0.8104 - val_accuracy: 0.6125\n",
      "Epoch 2431/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7627 - accuracy: 0.6729 - val_loss: 0.8107 - val_accuracy: 0.6250\n",
      "Epoch 2432/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7849 - accuracy: 0.6511 - val_loss: 0.9140 - val_accuracy: 0.6000\n",
      "Epoch 2433/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8367 - accuracy: 0.6168 - val_loss: 0.8717 - val_accuracy: 0.5625\n",
      "Epoch 2434/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.8391 - accuracy: 0.5888 - val_loss: 0.8306 - val_accuracy: 0.5750\n",
      "Epoch 2435/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7757 - accuracy: 0.6324 - val_loss: 0.8701 - val_accuracy: 0.5625\n",
      "Epoch 2436/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.7723 - accuracy: 0.6480 - val_loss: 0.8663 - val_accuracy: 0.5625\n",
      "Epoch 2437/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.7814 - accuracy: 0.6262 - val_loss: 0.8247 - val_accuracy: 0.6125\n",
      "Epoch 2438/3000\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 0.7809 - accuracy: 0.6231 - val_loss: 0.8450 - val_accuracy: 0.6125\n",
      "Epoch 2439/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.7730 - accuracy: 0.6480 - val_loss: 0.8048 - val_accuracy: 0.5875\n",
      "Epoch 2440/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7981 - accuracy: 0.6355 - val_loss: 0.8871 - val_accuracy: 0.5875\n",
      "Epoch 2441/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7925 - accuracy: 0.6480 - val_loss: 0.8637 - val_accuracy: 0.5875\n",
      "Epoch 2442/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.8114 - accuracy: 0.6168 - val_loss: 0.8544 - val_accuracy: 0.5625\n",
      "Epoch 2443/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7893 - accuracy: 0.5950 - val_loss: 0.8177 - val_accuracy: 0.5625\n",
      "Epoch 2444/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8387 - accuracy: 0.6480 - val_loss: 0.8400 - val_accuracy: 0.6250\n",
      "Epoch 2445/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7584 - accuracy: 0.6573 - val_loss: 0.7950 - val_accuracy: 0.6000\n",
      "Epoch 2446/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7236 - accuracy: 0.6667 - val_loss: 0.7811 - val_accuracy: 0.6125\n",
      "Epoch 2447/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7694 - accuracy: 0.6417 - val_loss: 0.8440 - val_accuracy: 0.6250\n",
      "Epoch 2448/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7682 - accuracy: 0.6449 - val_loss: 0.8138 - val_accuracy: 0.6000\n",
      "Epoch 2449/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.7616 - accuracy: 0.6324 - val_loss: 0.7925 - val_accuracy: 0.6125\n",
      "Epoch 2450/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.7873 - accuracy: 0.6262 - val_loss: 0.8227 - val_accuracy: 0.6125\n",
      "Epoch 2451/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7975 - accuracy: 0.6386 - val_loss: 0.8262 - val_accuracy: 0.6375\n",
      "Epoch 2452/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.8164 - accuracy: 0.6324 - val_loss: 0.8273 - val_accuracy: 0.6000\n",
      "Epoch 2453/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7729 - accuracy: 0.6573 - val_loss: 0.8212 - val_accuracy: 0.6000\n",
      "Epoch 2454/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7433 - accuracy: 0.6449 - val_loss: 0.8547 - val_accuracy: 0.5875\n",
      "Epoch 2455/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7779 - accuracy: 0.6604 - val_loss: 0.8084 - val_accuracy: 0.6125\n",
      "Epoch 2456/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.8079 - accuracy: 0.6231 - val_loss: 0.8512 - val_accuracy: 0.6000\n",
      "Epoch 2457/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.7905 - accuracy: 0.6293 - val_loss: 0.8418 - val_accuracy: 0.6000\n",
      "Epoch 2458/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.7837 - accuracy: 0.6293 - val_loss: 0.8590 - val_accuracy: 0.5500\n",
      "Epoch 2459/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.8083 - accuracy: 0.6075 - val_loss: 0.8351 - val_accuracy: 0.6000\n",
      "Epoch 2460/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.7494 - accuracy: 0.6511 - val_loss: 0.8149 - val_accuracy: 0.6125\n",
      "Epoch 2461/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8558 - accuracy: 0.5919 - val_loss: 0.8130 - val_accuracy: 0.5875\n",
      "Epoch 2462/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.7527 - accuracy: 0.6355 - val_loss: 0.8785 - val_accuracy: 0.6000\n",
      "Epoch 2463/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7548 - accuracy: 0.6542 - val_loss: 0.7922 - val_accuracy: 0.6375\n",
      "Epoch 2464/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.8082 - accuracy: 0.6449 - val_loss: 0.7775 - val_accuracy: 0.6125\n",
      "Epoch 2465/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7938 - accuracy: 0.6511 - val_loss: 0.8162 - val_accuracy: 0.6125\n",
      "Epoch 2466/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7596 - accuracy: 0.6386 - val_loss: 0.7980 - val_accuracy: 0.6125\n",
      "Epoch 2467/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.8372 - accuracy: 0.6231 - val_loss: 0.8288 - val_accuracy: 0.6125\n",
      "Epoch 2468/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.8137 - accuracy: 0.6168 - val_loss: 0.8354 - val_accuracy: 0.6000\n",
      "Epoch 2469/3000\n",
      "8/8 [==============================] - 1s 184ms/step - loss: 0.7912 - accuracy: 0.6449 - val_loss: 0.8134 - val_accuracy: 0.6125\n",
      "Epoch 2470/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.7347 - accuracy: 0.6542 - val_loss: 0.8906 - val_accuracy: 0.5875\n",
      "Epoch 2471/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.7541 - accuracy: 0.6542 - val_loss: 0.8152 - val_accuracy: 0.6000\n",
      "Epoch 2472/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.7320 - accuracy: 0.6573 - val_loss: 0.9014 - val_accuracy: 0.5500\n",
      "Epoch 2473/3000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 0.7754 - accuracy: 0.6324 - val_loss: 0.8056 - val_accuracy: 0.6125\n",
      "Epoch 2474/3000\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.7934 - accuracy: 0.6324 - val_loss: 0.8473 - val_accuracy: 0.5750\n",
      "Epoch 2475/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.7331 - accuracy: 0.6604 - val_loss: 0.8350 - val_accuracy: 0.6000\n",
      "Epoch 2476/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.7764 - accuracy: 0.6511 - val_loss: 0.8414 - val_accuracy: 0.5750\n",
      "Epoch 2477/3000\n",
      "8/8 [==============================] - 1s 197ms/step - loss: 0.7963 - accuracy: 0.6262 - val_loss: 0.8336 - val_accuracy: 0.5625\n",
      "Epoch 2478/3000\n",
      "8/8 [==============================] - 1s 200ms/step - loss: 0.7780 - accuracy: 0.6386 - val_loss: 0.8111 - val_accuracy: 0.5625\n",
      "Epoch 2479/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7841 - accuracy: 0.6698 - val_loss: 0.8579 - val_accuracy: 0.6125\n",
      "Epoch 2480/3000\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.8465 - accuracy: 0.6106 - val_loss: 0.8148 - val_accuracy: 0.6000\n",
      "Epoch 2481/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7596 - accuracy: 0.6667 - val_loss: 0.8024 - val_accuracy: 0.6125\n",
      "Epoch 2482/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.7769 - accuracy: 0.6324 - val_loss: 0.8428 - val_accuracy: 0.6125\n",
      "Epoch 2483/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8029 - accuracy: 0.6137 - val_loss: 0.8494 - val_accuracy: 0.6125\n",
      "Epoch 2484/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8130 - accuracy: 0.6542 - val_loss: 0.8188 - val_accuracy: 0.6500\n",
      "Epoch 2485/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.7759 - accuracy: 0.6168 - val_loss: 0.8278 - val_accuracy: 0.6000\n",
      "Epoch 2486/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7869 - accuracy: 0.6386 - val_loss: 0.7923 - val_accuracy: 0.6125\n",
      "Epoch 2487/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7969 - accuracy: 0.6293 - val_loss: 0.8227 - val_accuracy: 0.5875\n",
      "Epoch 2488/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8019 - accuracy: 0.6324 - val_loss: 0.8513 - val_accuracy: 0.5625\n",
      "Epoch 2489/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7398 - accuracy: 0.6573 - val_loss: 0.7960 - val_accuracy: 0.5875\n",
      "Epoch 2490/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.8222 - accuracy: 0.6386 - val_loss: 0.8061 - val_accuracy: 0.6125\n",
      "Epoch 2491/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7720 - accuracy: 0.6355 - val_loss: 0.8955 - val_accuracy: 0.5625\n",
      "Epoch 2492/3000\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.8147 - accuracy: 0.6231 - val_loss: 0.8010 - val_accuracy: 0.6375\n",
      "Epoch 2493/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.7642 - accuracy: 0.6480 - val_loss: 0.8755 - val_accuracy: 0.5750\n",
      "Epoch 2494/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.7384 - accuracy: 0.6573 - val_loss: 0.8047 - val_accuracy: 0.6000\n",
      "Epoch 2495/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7661 - accuracy: 0.6542 - val_loss: 0.8263 - val_accuracy: 0.6250\n",
      "Epoch 2496/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8072 - accuracy: 0.6231 - val_loss: 0.8768 - val_accuracy: 0.5625\n",
      "Epoch 2497/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7617 - accuracy: 0.6449 - val_loss: 0.8296 - val_accuracy: 0.6125\n",
      "Epoch 2498/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8140 - accuracy: 0.6386 - val_loss: 0.8221 - val_accuracy: 0.5875\n",
      "Epoch 2499/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7465 - accuracy: 0.6511 - val_loss: 0.8408 - val_accuracy: 0.6125\n",
      "Epoch 2500/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7881 - accuracy: 0.6386 - val_loss: 0.8252 - val_accuracy: 0.6125\n",
      "Epoch 2501/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7536 - accuracy: 0.6573 - val_loss: 0.8079 - val_accuracy: 0.6125\n",
      "Epoch 2502/3000\n",
      "8/8 [==============================] - 1s 180ms/step - loss: 0.8130 - accuracy: 0.6262 - val_loss: 0.8076 - val_accuracy: 0.5875\n",
      "Epoch 2503/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8045 - accuracy: 0.6199 - val_loss: 0.7968 - val_accuracy: 0.6250\n",
      "Epoch 2504/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7481 - accuracy: 0.6573 - val_loss: 0.8175 - val_accuracy: 0.6375\n",
      "Epoch 2505/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7318 - accuracy: 0.6573 - val_loss: 0.8503 - val_accuracy: 0.6125\n",
      "Epoch 2506/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7916 - accuracy: 0.6199 - val_loss: 0.8315 - val_accuracy: 0.6000\n",
      "Epoch 2507/3000\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.7381 - accuracy: 0.6667 - val_loss: 0.8193 - val_accuracy: 0.6250\n",
      "Epoch 2508/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.7659 - accuracy: 0.6417 - val_loss: 0.8650 - val_accuracy: 0.6000\n",
      "Epoch 2509/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7625 - accuracy: 0.6449 - val_loss: 0.8814 - val_accuracy: 0.5500\n",
      "Epoch 2510/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7896 - accuracy: 0.6199 - val_loss: 0.7693 - val_accuracy: 0.6375\n",
      "Epoch 2511/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.7628 - accuracy: 0.6698 - val_loss: 0.7989 - val_accuracy: 0.6250\n",
      "Epoch 2512/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.7520 - accuracy: 0.6636 - val_loss: 0.8210 - val_accuracy: 0.6125\n",
      "Epoch 2513/3000\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.7551 - accuracy: 0.6480 - val_loss: 0.8372 - val_accuracy: 0.6000\n",
      "Epoch 2514/3000\n",
      "8/8 [==============================] - 3s 453ms/step - loss: 0.8385 - accuracy: 0.6293 - val_loss: 0.8172 - val_accuracy: 0.6125\n",
      "Epoch 2515/3000\n",
      "8/8 [==============================] - 2s 186ms/step - loss: 0.7677 - accuracy: 0.6355 - val_loss: 0.7799 - val_accuracy: 0.6000\n",
      "Epoch 2516/3000\n",
      "8/8 [==============================] - 2s 253ms/step - loss: 0.8070 - accuracy: 0.6417 - val_loss: 0.8264 - val_accuracy: 0.6000\n",
      "Epoch 2517/3000\n",
      "8/8 [==============================] - 2s 301ms/step - loss: 0.7769 - accuracy: 0.6449 - val_loss: 0.7957 - val_accuracy: 0.6375\n",
      "Epoch 2518/3000\n",
      "8/8 [==============================] - 2s 276ms/step - loss: 0.8098 - accuracy: 0.6012 - val_loss: 0.8279 - val_accuracy: 0.6125\n",
      "Epoch 2519/3000\n",
      "8/8 [==============================] - 2s 237ms/step - loss: 0.7704 - accuracy: 0.6449 - val_loss: 0.8140 - val_accuracy: 0.6375\n",
      "Epoch 2520/3000\n",
      "8/8 [==============================] - 2s 239ms/step - loss: 0.7947 - accuracy: 0.6511 - val_loss: 0.7946 - val_accuracy: 0.5875\n",
      "Epoch 2521/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.7669 - accuracy: 0.6573 - val_loss: 0.9062 - val_accuracy: 0.5750\n",
      "Epoch 2522/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.7657 - accuracy: 0.6542 - val_loss: 0.8277 - val_accuracy: 0.6125\n",
      "Epoch 2523/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.8061 - accuracy: 0.6449 - val_loss: 0.8776 - val_accuracy: 0.5750\n",
      "Epoch 2524/3000\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.6753 - accuracy: 0.6916 - val_loss: 0.8302 - val_accuracy: 0.6125\n",
      "Epoch 2525/3000\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.7899 - accuracy: 0.6511 - val_loss: 0.7927 - val_accuracy: 0.6125\n",
      "Epoch 2526/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.7653 - accuracy: 0.6480 - val_loss: 0.7837 - val_accuracy: 0.6125\n",
      "Epoch 2527/3000\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.7768 - accuracy: 0.6480 - val_loss: 0.7932 - val_accuracy: 0.6000\n",
      "Epoch 2528/3000\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.7832 - accuracy: 0.6106 - val_loss: 0.7989 - val_accuracy: 0.6375\n",
      "Epoch 2529/3000\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.7127 - accuracy: 0.6854 - val_loss: 0.8239 - val_accuracy: 0.6375\n",
      "Epoch 2530/3000\n",
      "8/8 [==============================] - 2s 252ms/step - loss: 0.8064 - accuracy: 0.6511 - val_loss: 0.8105 - val_accuracy: 0.6250\n",
      "Epoch 2531/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.8220 - accuracy: 0.6480 - val_loss: 0.8184 - val_accuracy: 0.5750\n",
      "Epoch 2532/3000\n",
      "8/8 [==============================] - 2s 256ms/step - loss: 0.7766 - accuracy: 0.6480 - val_loss: 0.8479 - val_accuracy: 0.6000\n",
      "Epoch 2533/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.8092 - accuracy: 0.6231 - val_loss: 0.8002 - val_accuracy: 0.5875\n",
      "Epoch 2534/3000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.7676 - accuracy: 0.6573 - val_loss: 0.8092 - val_accuracy: 0.6000\n",
      "Epoch 2535/3000\n",
      "8/8 [==============================] - 2s 258ms/step - loss: 0.8152 - accuracy: 0.6168 - val_loss: 0.8559 - val_accuracy: 0.5375\n",
      "Epoch 2536/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.7696 - accuracy: 0.6573 - val_loss: 0.8145 - val_accuracy: 0.6000\n",
      "Epoch 2537/3000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.7278 - accuracy: 0.6916 - val_loss: 0.8315 - val_accuracy: 0.5875\n",
      "Epoch 2538/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.7811 - accuracy: 0.6417 - val_loss: 0.8991 - val_accuracy: 0.5625\n",
      "Epoch 2539/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.8324 - accuracy: 0.6199 - val_loss: 0.8189 - val_accuracy: 0.6375\n",
      "Epoch 2540/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.7206 - accuracy: 0.6667 - val_loss: 0.8299 - val_accuracy: 0.5750\n",
      "Epoch 2541/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.8327 - accuracy: 0.6168 - val_loss: 0.8415 - val_accuracy: 0.6000\n",
      "Epoch 2542/3000\n",
      "8/8 [==============================] - 2s 253ms/step - loss: 0.7652 - accuracy: 0.6604 - val_loss: 0.8569 - val_accuracy: 0.5750\n",
      "Epoch 2543/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.8399 - accuracy: 0.6137 - val_loss: 0.8178 - val_accuracy: 0.5750\n",
      "Epoch 2544/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.7534 - accuracy: 0.6729 - val_loss: 0.8211 - val_accuracy: 0.5625\n",
      "Epoch 2545/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.7811 - accuracy: 0.6417 - val_loss: 0.8286 - val_accuracy: 0.6250\n",
      "Epoch 2546/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.7396 - accuracy: 0.6480 - val_loss: 0.8549 - val_accuracy: 0.5750\n",
      "Epoch 2547/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.7915 - accuracy: 0.6168 - val_loss: 0.8714 - val_accuracy: 0.5500\n",
      "Epoch 2548/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.7679 - accuracy: 0.6573 - val_loss: 0.8347 - val_accuracy: 0.6125\n",
      "Epoch 2549/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.7733 - accuracy: 0.6573 - val_loss: 0.9013 - val_accuracy: 0.5500\n",
      "Epoch 2550/3000\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.7582 - accuracy: 0.6449 - val_loss: 0.8368 - val_accuracy: 0.6125\n",
      "Epoch 2551/3000\n",
      "8/8 [==============================] - 2s 240ms/step - loss: 0.7521 - accuracy: 0.6760 - val_loss: 0.8692 - val_accuracy: 0.5750\n",
      "Epoch 2552/3000\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.7535 - accuracy: 0.6604 - val_loss: 0.9115 - val_accuracy: 0.5625\n",
      "Epoch 2553/3000\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.7907 - accuracy: 0.6355 - val_loss: 0.8636 - val_accuracy: 0.6125\n",
      "Epoch 2554/3000\n",
      "8/8 [==============================] - 2s 237ms/step - loss: 0.7047 - accuracy: 0.6916 - val_loss: 0.8681 - val_accuracy: 0.6000\n",
      "Epoch 2555/3000\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.7914 - accuracy: 0.6449 - val_loss: 0.8348 - val_accuracy: 0.6125\n",
      "Epoch 2556/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.7867 - accuracy: 0.6417 - val_loss: 0.8767 - val_accuracy: 0.5750\n",
      "Epoch 2557/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.7544 - accuracy: 0.6636 - val_loss: 0.8279 - val_accuracy: 0.6000\n",
      "Epoch 2558/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.7393 - accuracy: 0.6604 - val_loss: 0.8140 - val_accuracy: 0.6000\n",
      "Epoch 2559/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.7351 - accuracy: 0.6760 - val_loss: 0.8523 - val_accuracy: 0.6125\n",
      "Epoch 2560/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.8217 - accuracy: 0.6231 - val_loss: 0.7892 - val_accuracy: 0.6375\n",
      "Epoch 2561/3000\n",
      "8/8 [==============================] - 2s 260ms/step - loss: 0.7502 - accuracy: 0.6822 - val_loss: 0.8229 - val_accuracy: 0.6125\n",
      "Epoch 2562/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.7850 - accuracy: 0.6199 - val_loss: 0.8393 - val_accuracy: 0.6500\n",
      "Epoch 2563/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.7995 - accuracy: 0.6293 - val_loss: 0.7948 - val_accuracy: 0.6125\n",
      "Epoch 2564/3000\n",
      "8/8 [==============================] - 2s 242ms/step - loss: 0.7930 - accuracy: 0.6231 - val_loss: 0.7808 - val_accuracy: 0.6125\n",
      "Epoch 2565/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.7115 - accuracy: 0.6760 - val_loss: 0.8152 - val_accuracy: 0.6500\n",
      "Epoch 2566/3000\n",
      "8/8 [==============================] - 2s 235ms/step - loss: 0.7615 - accuracy: 0.6698 - val_loss: 0.9907 - val_accuracy: 0.5375\n",
      "Epoch 2567/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.8295 - accuracy: 0.6417 - val_loss: 0.8579 - val_accuracy: 0.5750\n",
      "Epoch 2568/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.7449 - accuracy: 0.6729 - val_loss: 0.8758 - val_accuracy: 0.5875\n",
      "Epoch 2569/3000\n",
      "8/8 [==============================] - 2s 256ms/step - loss: 0.7303 - accuracy: 0.6511 - val_loss: 0.8731 - val_accuracy: 0.5625\n",
      "Epoch 2570/3000\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.8432 - accuracy: 0.6449 - val_loss: 0.8365 - val_accuracy: 0.6125\n",
      "Epoch 2571/3000\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.7883 - accuracy: 0.6604 - val_loss: 0.8285 - val_accuracy: 0.6000\n",
      "Epoch 2572/3000\n",
      "8/8 [==============================] - 2s 231ms/step - loss: 0.7079 - accuracy: 0.6511 - val_loss: 1.0918 - val_accuracy: 0.5625\n",
      "Epoch 2573/3000\n",
      "8/8 [==============================] - 2s 258ms/step - loss: 0.7693 - accuracy: 0.6511 - val_loss: 0.8507 - val_accuracy: 0.5875\n",
      "Epoch 2574/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.7215 - accuracy: 0.6791 - val_loss: 0.8293 - val_accuracy: 0.6125\n",
      "Epoch 2575/3000\n",
      "8/8 [==============================] - 2s 255ms/step - loss: 0.7462 - accuracy: 0.6542 - val_loss: 0.7881 - val_accuracy: 0.6000\n",
      "Epoch 2576/3000\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.8285 - accuracy: 0.6199 - val_loss: 0.8399 - val_accuracy: 0.6250\n",
      "Epoch 2577/3000\n",
      "8/8 [==============================] - 2s 228ms/step - loss: 0.7502 - accuracy: 0.6729 - val_loss: 0.8485 - val_accuracy: 0.6125\n",
      "Epoch 2578/3000\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.7868 - accuracy: 0.6386 - val_loss: 0.8460 - val_accuracy: 0.5750\n",
      "Epoch 2579/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.7784 - accuracy: 0.6480 - val_loss: 0.8035 - val_accuracy: 0.6500\n",
      "Epoch 2580/3000\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.7365 - accuracy: 0.6760 - val_loss: 0.8186 - val_accuracy: 0.6375\n",
      "Epoch 2581/3000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 0.7540 - accuracy: 0.6231 - val_loss: 0.8399 - val_accuracy: 0.6125\n",
      "Epoch 2582/3000\n",
      "8/8 [==============================] - 2s 251ms/step - loss: 0.7462 - accuracy: 0.6667 - val_loss: 0.9099 - val_accuracy: 0.6125\n",
      "Epoch 2583/3000\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.7342 - accuracy: 0.6604 - val_loss: 0.9869 - val_accuracy: 0.5625\n",
      "Epoch 2584/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7810 - accuracy: 0.6573 - val_loss: 0.8336 - val_accuracy: 0.6000\n",
      "Epoch 2585/3000\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.7287 - accuracy: 0.6449 - val_loss: 0.8861 - val_accuracy: 0.6125\n",
      "Epoch 2586/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.7782 - accuracy: 0.6573 - val_loss: 0.8452 - val_accuracy: 0.6125\n",
      "Epoch 2587/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.7051 - accuracy: 0.6667 - val_loss: 0.8354 - val_accuracy: 0.6250\n",
      "Epoch 2588/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.7613 - accuracy: 0.6386 - val_loss: 0.8219 - val_accuracy: 0.6000\n",
      "Epoch 2589/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.7130 - accuracy: 0.6822 - val_loss: 0.8308 - val_accuracy: 0.6000\n",
      "Epoch 2590/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.7956 - accuracy: 0.6386 - val_loss: 0.8638 - val_accuracy: 0.6000\n",
      "Epoch 2591/3000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 0.7365 - accuracy: 0.6885 - val_loss: 0.8573 - val_accuracy: 0.6250\n",
      "Epoch 2592/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.7396 - accuracy: 0.6729 - val_loss: 0.7995 - val_accuracy: 0.6250\n",
      "Epoch 2593/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7460 - accuracy: 0.6698 - val_loss: 0.8937 - val_accuracy: 0.5625\n",
      "Epoch 2594/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.7741 - accuracy: 0.6449 - val_loss: 0.8450 - val_accuracy: 0.6000\n",
      "Epoch 2595/3000\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 0.7736 - accuracy: 0.6604 - val_loss: 0.8215 - val_accuracy: 0.6250\n",
      "Epoch 2596/3000\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 0.7492 - accuracy: 0.6542 - val_loss: 0.8147 - val_accuracy: 0.6000\n",
      "Epoch 2597/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.6942 - accuracy: 0.6636 - val_loss: 0.7944 - val_accuracy: 0.6375\n",
      "Epoch 2598/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.7359 - accuracy: 0.6604 - val_loss: 0.8260 - val_accuracy: 0.6125\n",
      "Epoch 2599/3000\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.6879 - accuracy: 0.6698 - val_loss: 0.8689 - val_accuracy: 0.5500\n",
      "Epoch 2600/3000\n",
      "8/8 [==============================] - 1s 198ms/step - loss: 0.7457 - accuracy: 0.6636 - val_loss: 0.8038 - val_accuracy: 0.6000\n",
      "Epoch 2601/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7802 - accuracy: 0.6604 - val_loss: 0.8718 - val_accuracy: 0.6000\n",
      "Epoch 2602/3000\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 0.8016 - accuracy: 0.6168 - val_loss: 0.8253 - val_accuracy: 0.6250\n",
      "Epoch 2603/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7328 - accuracy: 0.6791 - val_loss: 0.8397 - val_accuracy: 0.6250\n",
      "Epoch 2604/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7425 - accuracy: 0.6791 - val_loss: 0.8589 - val_accuracy: 0.6250\n",
      "Epoch 2605/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7626 - accuracy: 0.6760 - val_loss: 0.8615 - val_accuracy: 0.6125\n",
      "Epoch 2606/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.7365 - accuracy: 0.6604 - val_loss: 0.8082 - val_accuracy: 0.6250\n",
      "Epoch 2607/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7673 - accuracy: 0.6355 - val_loss: 0.8558 - val_accuracy: 0.6000\n",
      "Epoch 2608/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.7481 - accuracy: 0.6573 - val_loss: 0.8252 - val_accuracy: 0.6375\n",
      "Epoch 2609/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7928 - accuracy: 0.6542 - val_loss: 0.7937 - val_accuracy: 0.6375\n",
      "Epoch 2610/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7045 - accuracy: 0.6542 - val_loss: 0.8109 - val_accuracy: 0.6375\n",
      "Epoch 2611/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7426 - accuracy: 0.6636 - val_loss: 0.8234 - val_accuracy: 0.5625\n",
      "Epoch 2612/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.7341 - accuracy: 0.6698 - val_loss: 0.8763 - val_accuracy: 0.6250\n",
      "Epoch 2613/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7843 - accuracy: 0.6231 - val_loss: 0.8440 - val_accuracy: 0.6125\n",
      "Epoch 2614/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7640 - accuracy: 0.6791 - val_loss: 0.8511 - val_accuracy: 0.6000\n",
      "Epoch 2615/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.7643 - accuracy: 0.6573 - val_loss: 0.8311 - val_accuracy: 0.6125\n",
      "Epoch 2616/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7729 - accuracy: 0.6542 - val_loss: 0.8478 - val_accuracy: 0.5750\n",
      "Epoch 2617/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7500 - accuracy: 0.6636 - val_loss: 0.8482 - val_accuracy: 0.6375\n",
      "Epoch 2618/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7689 - accuracy: 0.6698 - val_loss: 0.9056 - val_accuracy: 0.5250\n",
      "Epoch 2619/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7495 - accuracy: 0.6698 - val_loss: 0.8241 - val_accuracy: 0.6125\n",
      "Epoch 2620/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.7016 - accuracy: 0.6854 - val_loss: 0.9472 - val_accuracy: 0.4875\n",
      "Epoch 2621/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7501 - accuracy: 0.6604 - val_loss: 0.8931 - val_accuracy: 0.5750\n",
      "Epoch 2622/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7423 - accuracy: 0.6604 - val_loss: 0.9568 - val_accuracy: 0.5375\n",
      "Epoch 2623/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7708 - accuracy: 0.6573 - val_loss: 0.8568 - val_accuracy: 0.5875\n",
      "Epoch 2624/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7495 - accuracy: 0.6511 - val_loss: 0.8438 - val_accuracy: 0.6250\n",
      "Epoch 2625/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7488 - accuracy: 0.6885 - val_loss: 0.8427 - val_accuracy: 0.5875\n",
      "Epoch 2626/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.7337 - accuracy: 0.6636 - val_loss: 0.9049 - val_accuracy: 0.5125\n",
      "Epoch 2627/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7597 - accuracy: 0.6573 - val_loss: 0.8492 - val_accuracy: 0.6000\n",
      "Epoch 2628/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7483 - accuracy: 0.6417 - val_loss: 0.8237 - val_accuracy: 0.6500\n",
      "Epoch 2629/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.6908 - accuracy: 0.6978 - val_loss: 0.9031 - val_accuracy: 0.5125\n",
      "Epoch 2630/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7753 - accuracy: 0.6386 - val_loss: 0.8234 - val_accuracy: 0.6250\n",
      "Epoch 2631/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7426 - accuracy: 0.6542 - val_loss: 0.8666 - val_accuracy: 0.5500\n",
      "Epoch 2632/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7345 - accuracy: 0.6791 - val_loss: 0.7908 - val_accuracy: 0.6625\n",
      "Epoch 2633/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.7535 - accuracy: 0.6885 - val_loss: 0.8419 - val_accuracy: 0.6125\n",
      "Epoch 2634/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.6815 - accuracy: 0.6822 - val_loss: 0.8153 - val_accuracy: 0.6250\n",
      "Epoch 2635/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7125 - accuracy: 0.6729 - val_loss: 0.8487 - val_accuracy: 0.6500\n",
      "Epoch 2636/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7757 - accuracy: 0.6355 - val_loss: 0.8282 - val_accuracy: 0.6500\n",
      "Epoch 2637/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7493 - accuracy: 0.6355 - val_loss: 0.9132 - val_accuracy: 0.5750\n",
      "Epoch 2638/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7520 - accuracy: 0.6636 - val_loss: 0.8384 - val_accuracy: 0.6125\n",
      "Epoch 2639/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7833 - accuracy: 0.6511 - val_loss: 0.8245 - val_accuracy: 0.6000\n",
      "Epoch 2640/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.6691 - accuracy: 0.7165 - val_loss: 0.8346 - val_accuracy: 0.6250\n",
      "Epoch 2641/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.7559 - accuracy: 0.6822 - val_loss: 0.8790 - val_accuracy: 0.6250\n",
      "Epoch 2642/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7581 - accuracy: 0.6604 - val_loss: 0.8524 - val_accuracy: 0.6000\n",
      "Epoch 2643/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7299 - accuracy: 0.6573 - val_loss: 0.8588 - val_accuracy: 0.5500\n",
      "Epoch 2644/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.7277 - accuracy: 0.6480 - val_loss: 0.8025 - val_accuracy: 0.6000\n",
      "Epoch 2645/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6926 - accuracy: 0.6791 - val_loss: 0.8330 - val_accuracy: 0.6000\n",
      "Epoch 2646/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7906 - accuracy: 0.6293 - val_loss: 0.8006 - val_accuracy: 0.6250\n",
      "Epoch 2647/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.6849 - accuracy: 0.7009 - val_loss: 0.8096 - val_accuracy: 0.6125\n",
      "Epoch 2648/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7399 - accuracy: 0.6573 - val_loss: 0.8485 - val_accuracy: 0.6000\n",
      "Epoch 2649/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7395 - accuracy: 0.6604 - val_loss: 0.8174 - val_accuracy: 0.6375\n",
      "Epoch 2650/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7076 - accuracy: 0.7009 - val_loss: 0.8203 - val_accuracy: 0.6125\n",
      "Epoch 2651/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.6768 - accuracy: 0.7227 - val_loss: 0.8608 - val_accuracy: 0.6125\n",
      "Epoch 2652/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7296 - accuracy: 0.6698 - val_loss: 0.7941 - val_accuracy: 0.6250\n",
      "Epoch 2653/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.7523 - accuracy: 0.6573 - val_loss: 0.8548 - val_accuracy: 0.6000\n",
      "Epoch 2654/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7140 - accuracy: 0.6978 - val_loss: 0.9404 - val_accuracy: 0.4875\n",
      "Epoch 2655/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.7496 - accuracy: 0.6791 - val_loss: 0.9154 - val_accuracy: 0.5375\n",
      "Epoch 2656/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.6695 - accuracy: 0.6947 - val_loss: 0.8094 - val_accuracy: 0.6125\n",
      "Epoch 2657/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7413 - accuracy: 0.6449 - val_loss: 0.8112 - val_accuracy: 0.6250\n",
      "Epoch 2658/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.8348 - accuracy: 0.6137 - val_loss: 0.8436 - val_accuracy: 0.5875\n",
      "Epoch 2659/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7453 - accuracy: 0.6822 - val_loss: 0.8483 - val_accuracy: 0.6000\n",
      "Epoch 2660/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7190 - accuracy: 0.6667 - val_loss: 0.8024 - val_accuracy: 0.6500\n",
      "Epoch 2661/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.6902 - accuracy: 0.6916 - val_loss: 0.8249 - val_accuracy: 0.5875\n",
      "Epoch 2662/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7053 - accuracy: 0.6760 - val_loss: 0.8405 - val_accuracy: 0.6625\n",
      "Epoch 2663/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7449 - accuracy: 0.6667 - val_loss: 0.8398 - val_accuracy: 0.6125\n",
      "Epoch 2664/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6793 - accuracy: 0.7103 - val_loss: 0.8071 - val_accuracy: 0.6125\n",
      "Epoch 2665/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7375 - accuracy: 0.6885 - val_loss: 0.9029 - val_accuracy: 0.5250\n",
      "Epoch 2666/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.7372 - accuracy: 0.6822 - val_loss: 0.7946 - val_accuracy: 0.7000\n",
      "Epoch 2667/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.6840 - accuracy: 0.6978 - val_loss: 0.8516 - val_accuracy: 0.6125\n",
      "Epoch 2668/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.7006 - accuracy: 0.6854 - val_loss: 0.8037 - val_accuracy: 0.6625\n",
      "Epoch 2669/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7201 - accuracy: 0.6916 - val_loss: 0.8312 - val_accuracy: 0.5500\n",
      "Epoch 2670/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7290 - accuracy: 0.6573 - val_loss: 0.9956 - val_accuracy: 0.6125\n",
      "Epoch 2671/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7462 - accuracy: 0.6822 - val_loss: 0.8697 - val_accuracy: 0.6250\n",
      "Epoch 2672/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6808 - accuracy: 0.6916 - val_loss: 0.8728 - val_accuracy: 0.6250\n",
      "Epoch 2673/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7937 - accuracy: 0.6449 - val_loss: 0.8159 - val_accuracy: 0.6375\n",
      "Epoch 2674/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.7180 - accuracy: 0.6885 - val_loss: 0.8625 - val_accuracy: 0.6375\n",
      "Epoch 2675/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.7412 - accuracy: 0.6854 - val_loss: 0.8930 - val_accuracy: 0.6250\n",
      "Epoch 2676/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.6975 - accuracy: 0.7040 - val_loss: 0.8405 - val_accuracy: 0.6375\n",
      "Epoch 2677/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8001 - accuracy: 0.6698 - val_loss: 0.8851 - val_accuracy: 0.5750\n",
      "Epoch 2678/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7003 - accuracy: 0.6760 - val_loss: 0.8198 - val_accuracy: 0.6125\n",
      "Epoch 2679/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7790 - accuracy: 0.6667 - val_loss: 0.8865 - val_accuracy: 0.6000\n",
      "Epoch 2680/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7060 - accuracy: 0.7040 - val_loss: 0.8608 - val_accuracy: 0.6000\n",
      "Epoch 2681/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.7072 - accuracy: 0.6854 - val_loss: 0.8799 - val_accuracy: 0.6375\n",
      "Epoch 2682/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7737 - accuracy: 0.6667 - val_loss: 0.8506 - val_accuracy: 0.5875\n",
      "Epoch 2683/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.8102 - accuracy: 0.6449 - val_loss: 0.8669 - val_accuracy: 0.6250\n",
      "Epoch 2684/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7461 - accuracy: 0.6667 - val_loss: 0.8508 - val_accuracy: 0.6125\n",
      "Epoch 2685/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6977 - accuracy: 0.6760 - val_loss: 0.8005 - val_accuracy: 0.6250\n",
      "Epoch 2686/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7680 - accuracy: 0.6542 - val_loss: 0.8618 - val_accuracy: 0.6375\n",
      "Epoch 2687/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7650 - accuracy: 0.6667 - val_loss: 0.9483 - val_accuracy: 0.4875\n",
      "Epoch 2688/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.7028 - accuracy: 0.7196 - val_loss: 0.8224 - val_accuracy: 0.6500\n",
      "Epoch 2689/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.6879 - accuracy: 0.6885 - val_loss: 0.8179 - val_accuracy: 0.6250\n",
      "Epoch 2690/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6867 - accuracy: 0.7165 - val_loss: 0.8664 - val_accuracy: 0.5250\n",
      "Epoch 2691/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7555 - accuracy: 0.6854 - val_loss: 0.8041 - val_accuracy: 0.6375\n",
      "Epoch 2692/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.6914 - accuracy: 0.6947 - val_loss: 0.9869 - val_accuracy: 0.5000\n",
      "Epoch 2693/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7145 - accuracy: 0.6729 - val_loss: 0.8279 - val_accuracy: 0.6250\n",
      "Epoch 2694/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.7198 - accuracy: 0.6636 - val_loss: 0.8055 - val_accuracy: 0.6250\n",
      "Epoch 2695/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6997 - accuracy: 0.6791 - val_loss: 0.8512 - val_accuracy: 0.6000\n",
      "Epoch 2696/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6952 - accuracy: 0.7040 - val_loss: 0.8484 - val_accuracy: 0.5875\n",
      "Epoch 2697/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7672 - accuracy: 0.6573 - val_loss: 0.8296 - val_accuracy: 0.5875\n",
      "Epoch 2698/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6844 - accuracy: 0.6822 - val_loss: 0.8130 - val_accuracy: 0.6125\n",
      "Epoch 2699/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7898 - accuracy: 0.6199 - val_loss: 0.8250 - val_accuracy: 0.6375\n",
      "Epoch 2700/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6854 - accuracy: 0.6885 - val_loss: 0.8147 - val_accuracy: 0.6625\n",
      "Epoch 2701/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7331 - accuracy: 0.6729 - val_loss: 0.7843 - val_accuracy: 0.6250\n",
      "Epoch 2702/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6924 - accuracy: 0.6822 - val_loss: 0.8259 - val_accuracy: 0.6625\n",
      "Epoch 2703/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7568 - accuracy: 0.6822 - val_loss: 0.8328 - val_accuracy: 0.6000\n",
      "Epoch 2704/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7029 - accuracy: 0.6760 - val_loss: 0.8279 - val_accuracy: 0.5875\n",
      "Epoch 2705/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7267 - accuracy: 0.6854 - val_loss: 0.8158 - val_accuracy: 0.6125\n",
      "Epoch 2706/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.7180 - accuracy: 0.6822 - val_loss: 0.8584 - val_accuracy: 0.6000\n",
      "Epoch 2707/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7162 - accuracy: 0.6760 - val_loss: 0.8646 - val_accuracy: 0.5500\n",
      "Epoch 2708/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.7536 - accuracy: 0.6511 - val_loss: 0.8474 - val_accuracy: 0.5875\n",
      "Epoch 2709/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7236 - accuracy: 0.6885 - val_loss: 0.7951 - val_accuracy: 0.6000\n",
      "Epoch 2710/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.7140 - accuracy: 0.6791 - val_loss: 0.8865 - val_accuracy: 0.5375\n",
      "Epoch 2711/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6725 - accuracy: 0.7165 - val_loss: 0.8300 - val_accuracy: 0.6000\n",
      "Epoch 2712/3000\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.7044 - accuracy: 0.7009 - val_loss: 0.8399 - val_accuracy: 0.6250\n",
      "Epoch 2713/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7014 - accuracy: 0.7072 - val_loss: 0.8194 - val_accuracy: 0.6375\n",
      "Epoch 2714/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7437 - accuracy: 0.6449 - val_loss: 0.7929 - val_accuracy: 0.6125\n",
      "Epoch 2715/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7662 - accuracy: 0.6511 - val_loss: 0.8181 - val_accuracy: 0.5750\n",
      "Epoch 2716/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7006 - accuracy: 0.7009 - val_loss: 0.8225 - val_accuracy: 0.5625\n",
      "Epoch 2717/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7260 - accuracy: 0.6947 - val_loss: 0.7982 - val_accuracy: 0.6000\n",
      "Epoch 2718/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.7809 - accuracy: 0.6604 - val_loss: 0.8941 - val_accuracy: 0.5625\n",
      "Epoch 2719/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7283 - accuracy: 0.6760 - val_loss: 0.8508 - val_accuracy: 0.5750\n",
      "Epoch 2720/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.6783 - accuracy: 0.6978 - val_loss: 0.8202 - val_accuracy: 0.6000\n",
      "Epoch 2721/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6053 - accuracy: 0.7383 - val_loss: 0.8082 - val_accuracy: 0.5750\n",
      "Epoch 2722/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.6794 - accuracy: 0.7196 - val_loss: 0.8434 - val_accuracy: 0.5750\n",
      "Epoch 2723/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7542 - accuracy: 0.6978 - val_loss: 0.8090 - val_accuracy: 0.6000\n",
      "Epoch 2724/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7295 - accuracy: 0.7040 - val_loss: 0.8276 - val_accuracy: 0.6125\n",
      "Epoch 2725/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7086 - accuracy: 0.6916 - val_loss: 0.8526 - val_accuracy: 0.6125\n",
      "Epoch 2726/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7215 - accuracy: 0.6760 - val_loss: 0.9476 - val_accuracy: 0.5125\n",
      "Epoch 2727/3000\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.7857 - accuracy: 0.6573 - val_loss: 0.8304 - val_accuracy: 0.6250\n",
      "Epoch 2728/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7070 - accuracy: 0.6885 - val_loss: 0.8474 - val_accuracy: 0.5750\n",
      "Epoch 2729/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7145 - accuracy: 0.7040 - val_loss: 0.7979 - val_accuracy: 0.6500\n",
      "Epoch 2730/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7612 - accuracy: 0.6885 - val_loss: 0.8498 - val_accuracy: 0.6000\n",
      "Epoch 2731/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7092 - accuracy: 0.6854 - val_loss: 0.8351 - val_accuracy: 0.6125\n",
      "Epoch 2732/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.6565 - accuracy: 0.6916 - val_loss: 0.8158 - val_accuracy: 0.6125\n",
      "Epoch 2733/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7061 - accuracy: 0.6916 - val_loss: 0.8225 - val_accuracy: 0.6000\n",
      "Epoch 2734/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7204 - accuracy: 0.6636 - val_loss: 0.8107 - val_accuracy: 0.6125\n",
      "Epoch 2735/3000\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 0.7167 - accuracy: 0.6916 - val_loss: 0.8788 - val_accuracy: 0.6125\n",
      "Epoch 2736/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.6810 - accuracy: 0.7165 - val_loss: 0.8484 - val_accuracy: 0.6125\n",
      "Epoch 2737/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7033 - accuracy: 0.6760 - val_loss: 0.8094 - val_accuracy: 0.6125\n",
      "Epoch 2738/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7106 - accuracy: 0.6947 - val_loss: 0.9122 - val_accuracy: 0.5625\n",
      "Epoch 2739/3000\n",
      "8/8 [==============================] - 1s 181ms/step - loss: 0.6811 - accuracy: 0.7165 - val_loss: 0.8124 - val_accuracy: 0.6250\n",
      "Epoch 2740/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7303 - accuracy: 0.6604 - val_loss: 0.9756 - val_accuracy: 0.5375\n",
      "Epoch 2741/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7011 - accuracy: 0.6885 - val_loss: 0.8912 - val_accuracy: 0.5750\n",
      "Epoch 2742/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.6844 - accuracy: 0.7259 - val_loss: 0.8196 - val_accuracy: 0.6500\n",
      "Epoch 2743/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7002 - accuracy: 0.6978 - val_loss: 0.9046 - val_accuracy: 0.6000\n",
      "Epoch 2744/3000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.7264 - accuracy: 0.6791 - val_loss: 0.8772 - val_accuracy: 0.5625\n",
      "Epoch 2745/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7124 - accuracy: 0.6978 - val_loss: 0.8648 - val_accuracy: 0.6375\n",
      "Epoch 2746/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7265 - accuracy: 0.6791 - val_loss: 0.8280 - val_accuracy: 0.6375\n",
      "Epoch 2747/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7212 - accuracy: 0.6760 - val_loss: 0.8793 - val_accuracy: 0.6000\n",
      "Epoch 2748/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7065 - accuracy: 0.6573 - val_loss: 0.9203 - val_accuracy: 0.5250\n",
      "Epoch 2749/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7767 - accuracy: 0.6542 - val_loss: 0.9580 - val_accuracy: 0.5500\n",
      "Epoch 2750/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.7105 - accuracy: 0.7165 - val_loss: 0.9290 - val_accuracy: 0.5125\n",
      "Epoch 2751/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.7042 - accuracy: 0.6947 - val_loss: 0.8103 - val_accuracy: 0.6000\n",
      "Epoch 2752/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7188 - accuracy: 0.6822 - val_loss: 0.8290 - val_accuracy: 0.6625\n",
      "Epoch 2753/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.6327 - accuracy: 0.7134 - val_loss: 0.8132 - val_accuracy: 0.6250\n",
      "Epoch 2754/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.6871 - accuracy: 0.6947 - val_loss: 0.8748 - val_accuracy: 0.5750\n",
      "Epoch 2755/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7178 - accuracy: 0.6791 - val_loss: 0.8450 - val_accuracy: 0.6375\n",
      "Epoch 2756/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.6725 - accuracy: 0.7009 - val_loss: 0.8941 - val_accuracy: 0.5625\n",
      "Epoch 2757/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6731 - accuracy: 0.7290 - val_loss: 0.8280 - val_accuracy: 0.5875\n",
      "Epoch 2758/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6900 - accuracy: 0.6760 - val_loss: 0.8225 - val_accuracy: 0.6250\n",
      "Epoch 2759/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7181 - accuracy: 0.6573 - val_loss: 0.8439 - val_accuracy: 0.5750\n",
      "Epoch 2760/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.6988 - accuracy: 0.6947 - val_loss: 0.8123 - val_accuracy: 0.6375\n",
      "Epoch 2761/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6975 - accuracy: 0.6791 - val_loss: 0.8554 - val_accuracy: 0.6000\n",
      "Epoch 2762/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7671 - accuracy: 0.6542 - val_loss: 0.8488 - val_accuracy: 0.5875\n",
      "Epoch 2763/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6699 - accuracy: 0.7414 - val_loss: 0.8697 - val_accuracy: 0.5750\n",
      "Epoch 2764/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6858 - accuracy: 0.6947 - val_loss: 1.0258 - val_accuracy: 0.5125\n",
      "Epoch 2765/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.6715 - accuracy: 0.7103 - val_loss: 0.8655 - val_accuracy: 0.6250\n",
      "Epoch 2766/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7302 - accuracy: 0.6667 - val_loss: 1.0725 - val_accuracy: 0.4250\n",
      "Epoch 2767/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.6933 - accuracy: 0.6698 - val_loss: 0.8877 - val_accuracy: 0.5250\n",
      "Epoch 2768/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6578 - accuracy: 0.6729 - val_loss: 0.8935 - val_accuracy: 0.5875\n",
      "Epoch 2769/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6716 - accuracy: 0.7227 - val_loss: 0.9211 - val_accuracy: 0.5250\n",
      "Epoch 2770/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.7149 - accuracy: 0.6729 - val_loss: 0.8771 - val_accuracy: 0.5875\n",
      "Epoch 2771/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7153 - accuracy: 0.6760 - val_loss: 0.9060 - val_accuracy: 0.5750\n",
      "Epoch 2772/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7029 - accuracy: 0.6978 - val_loss: 0.9406 - val_accuracy: 0.5250\n",
      "Epoch 2773/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.6904 - accuracy: 0.7009 - val_loss: 0.9646 - val_accuracy: 0.5500\n",
      "Epoch 2774/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7207 - accuracy: 0.6511 - val_loss: 0.9202 - val_accuracy: 0.6125\n",
      "Epoch 2775/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6416 - accuracy: 0.7165 - val_loss: 0.8603 - val_accuracy: 0.6000\n",
      "Epoch 2776/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7082 - accuracy: 0.6916 - val_loss: 0.8932 - val_accuracy: 0.5875\n",
      "Epoch 2777/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6392 - accuracy: 0.7103 - val_loss: 0.8739 - val_accuracy: 0.6125\n",
      "Epoch 2778/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.7291 - accuracy: 0.6636 - val_loss: 0.8767 - val_accuracy: 0.5750\n",
      "Epoch 2779/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6831 - accuracy: 0.7134 - val_loss: 0.8506 - val_accuracy: 0.6375\n",
      "Epoch 2780/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7775 - accuracy: 0.6480 - val_loss: 0.8765 - val_accuracy: 0.5625\n",
      "Epoch 2781/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6378 - accuracy: 0.7539 - val_loss: 0.9088 - val_accuracy: 0.6000\n",
      "Epoch 2782/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.6587 - accuracy: 0.7103 - val_loss: 0.8659 - val_accuracy: 0.5875\n",
      "Epoch 2783/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6764 - accuracy: 0.7009 - val_loss: 0.8867 - val_accuracy: 0.5750\n",
      "Epoch 2784/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7075 - accuracy: 0.6916 - val_loss: 0.8981 - val_accuracy: 0.5750\n",
      "Epoch 2785/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.7563 - accuracy: 0.6449 - val_loss: 0.9014 - val_accuracy: 0.5750\n",
      "Epoch 2786/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6586 - accuracy: 0.7103 - val_loss: 0.8795 - val_accuracy: 0.6000\n",
      "Epoch 2787/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.6954 - accuracy: 0.6854 - val_loss: 0.9318 - val_accuracy: 0.5375\n",
      "Epoch 2788/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.7087 - accuracy: 0.7134 - val_loss: 0.8576 - val_accuracy: 0.5875\n",
      "Epoch 2789/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6342 - accuracy: 0.7383 - val_loss: 0.8622 - val_accuracy: 0.6000\n",
      "Epoch 2790/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.7064 - accuracy: 0.6885 - val_loss: 0.9091 - val_accuracy: 0.5750\n",
      "Epoch 2791/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.6642 - accuracy: 0.6885 - val_loss: 0.9442 - val_accuracy: 0.5500\n",
      "Epoch 2792/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6496 - accuracy: 0.7134 - val_loss: 0.8535 - val_accuracy: 0.6125\n",
      "Epoch 2793/3000\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.6537 - accuracy: 0.7259 - val_loss: 0.9006 - val_accuracy: 0.5875\n",
      "Epoch 2794/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7405 - accuracy: 0.6791 - val_loss: 0.8901 - val_accuracy: 0.5875\n",
      "Epoch 2795/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.6930 - accuracy: 0.7040 - val_loss: 0.8645 - val_accuracy: 0.6125\n",
      "Epoch 2796/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.6795 - accuracy: 0.7072 - val_loss: 0.8643 - val_accuracy: 0.5875\n",
      "Epoch 2797/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7228 - accuracy: 0.6916 - val_loss: 0.8715 - val_accuracy: 0.6000\n",
      "Epoch 2798/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6580 - accuracy: 0.6916 - val_loss: 0.9496 - val_accuracy: 0.5125\n",
      "Epoch 2799/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6862 - accuracy: 0.6916 - val_loss: 0.8823 - val_accuracy: 0.6000\n",
      "Epoch 2800/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.6694 - accuracy: 0.7134 - val_loss: 0.8571 - val_accuracy: 0.6250\n",
      "Epoch 2801/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.6448 - accuracy: 0.7165 - val_loss: 0.9654 - val_accuracy: 0.5000\n",
      "Epoch 2802/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7396 - accuracy: 0.6729 - val_loss: 0.8759 - val_accuracy: 0.5750\n",
      "Epoch 2803/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6650 - accuracy: 0.7103 - val_loss: 0.8786 - val_accuracy: 0.5750\n",
      "Epoch 2804/3000\n",
      "8/8 [==============================] - 1s 180ms/step - loss: 0.7012 - accuracy: 0.7009 - val_loss: 0.8248 - val_accuracy: 0.6375\n",
      "Epoch 2805/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.6640 - accuracy: 0.6854 - val_loss: 0.8669 - val_accuracy: 0.5875\n",
      "Epoch 2806/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6851 - accuracy: 0.6885 - val_loss: 0.8761 - val_accuracy: 0.5500\n",
      "Epoch 2807/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7390 - accuracy: 0.6573 - val_loss: 0.8266 - val_accuracy: 0.5875\n",
      "Epoch 2808/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7075 - accuracy: 0.6978 - val_loss: 0.8579 - val_accuracy: 0.5875\n",
      "Epoch 2809/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6666 - accuracy: 0.7321 - val_loss: 0.9295 - val_accuracy: 0.5250\n",
      "Epoch 2810/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7098 - accuracy: 0.6791 - val_loss: 0.8720 - val_accuracy: 0.5500\n",
      "Epoch 2811/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.6798 - accuracy: 0.7134 - val_loss: 0.8592 - val_accuracy: 0.6125\n",
      "Epoch 2812/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.6154 - accuracy: 0.7788 - val_loss: 0.9074 - val_accuracy: 0.5500\n",
      "Epoch 2813/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7250 - accuracy: 0.6698 - val_loss: 0.8476 - val_accuracy: 0.5750\n",
      "Epoch 2814/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.7125 - accuracy: 0.6791 - val_loss: 0.8772 - val_accuracy: 0.5250\n",
      "Epoch 2815/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.6728 - accuracy: 0.7072 - val_loss: 0.7963 - val_accuracy: 0.6125\n",
      "Epoch 2816/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.6411 - accuracy: 0.7165 - val_loss: 0.8345 - val_accuracy: 0.6250\n",
      "Epoch 2817/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6131 - accuracy: 0.7196 - val_loss: 0.8230 - val_accuracy: 0.6000\n",
      "Epoch 2818/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.6405 - accuracy: 0.7508 - val_loss: 0.8345 - val_accuracy: 0.6250\n",
      "Epoch 2819/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.6573 - accuracy: 0.7259 - val_loss: 0.8569 - val_accuracy: 0.5625\n",
      "Epoch 2820/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.6113 - accuracy: 0.7477 - val_loss: 0.8560 - val_accuracy: 0.6375\n",
      "Epoch 2821/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7144 - accuracy: 0.6947 - val_loss: 0.8909 - val_accuracy: 0.5625\n",
      "Epoch 2822/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.7207 - accuracy: 0.6760 - val_loss: 0.8561 - val_accuracy: 0.6375\n",
      "Epoch 2823/3000\n",
      "8/8 [==============================] - 1s 196ms/step - loss: 0.6855 - accuracy: 0.6885 - val_loss: 1.0149 - val_accuracy: 0.5250\n",
      "Epoch 2824/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.6568 - accuracy: 0.7227 - val_loss: 0.9293 - val_accuracy: 0.5750\n",
      "Epoch 2825/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.6877 - accuracy: 0.7196 - val_loss: 0.9022 - val_accuracy: 0.6125\n",
      "Epoch 2826/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6582 - accuracy: 0.6916 - val_loss: 0.8814 - val_accuracy: 0.6625\n",
      "Epoch 2827/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6404 - accuracy: 0.6947 - val_loss: 0.9004 - val_accuracy: 0.5750\n",
      "Epoch 2828/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6545 - accuracy: 0.7352 - val_loss: 0.9725 - val_accuracy: 0.5500\n",
      "Epoch 2829/3000\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 0.6401 - accuracy: 0.6916 - val_loss: 0.9488 - val_accuracy: 0.5625\n",
      "Epoch 2830/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6355 - accuracy: 0.7445 - val_loss: 0.8939 - val_accuracy: 0.5875\n",
      "Epoch 2831/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.6881 - accuracy: 0.7259 - val_loss: 0.9035 - val_accuracy: 0.6375\n",
      "Epoch 2832/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.6659 - accuracy: 0.7196 - val_loss: 1.0001 - val_accuracy: 0.5125\n",
      "Epoch 2833/3000\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 0.7079 - accuracy: 0.6947 - val_loss: 0.8927 - val_accuracy: 0.6250\n",
      "Epoch 2834/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6994 - accuracy: 0.6760 - val_loss: 0.8969 - val_accuracy: 0.6000\n",
      "Epoch 2835/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.6991 - accuracy: 0.6854 - val_loss: 0.8610 - val_accuracy: 0.6250\n",
      "Epoch 2836/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6753 - accuracy: 0.7165 - val_loss: 0.8361 - val_accuracy: 0.6000\n",
      "Epoch 2837/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.6518 - accuracy: 0.7103 - val_loss: 0.9044 - val_accuracy: 0.5875\n",
      "Epoch 2838/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.7562 - accuracy: 0.6760 - val_loss: 0.8803 - val_accuracy: 0.6250\n",
      "Epoch 2839/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.6523 - accuracy: 0.7072 - val_loss: 0.8498 - val_accuracy: 0.6500\n",
      "Epoch 2840/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.6593 - accuracy: 0.7009 - val_loss: 0.9248 - val_accuracy: 0.5375\n",
      "Epoch 2841/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6926 - accuracy: 0.7072 - val_loss: 0.8283 - val_accuracy: 0.6500\n",
      "Epoch 2842/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6409 - accuracy: 0.7227 - val_loss: 0.8847 - val_accuracy: 0.6125\n",
      "Epoch 2843/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.6877 - accuracy: 0.7072 - val_loss: 0.8844 - val_accuracy: 0.5625\n",
      "Epoch 2844/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6535 - accuracy: 0.7040 - val_loss: 0.8558 - val_accuracy: 0.6375\n",
      "Epoch 2845/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6526 - accuracy: 0.7072 - val_loss: 0.9417 - val_accuracy: 0.5625\n",
      "Epoch 2846/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6532 - accuracy: 0.7134 - val_loss: 0.8633 - val_accuracy: 0.6000\n",
      "Epoch 2847/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6529 - accuracy: 0.7321 - val_loss: 0.8869 - val_accuracy: 0.5750\n",
      "Epoch 2848/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.6535 - accuracy: 0.6947 - val_loss: 1.0830 - val_accuracy: 0.5000\n",
      "Epoch 2849/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6882 - accuracy: 0.7072 - val_loss: 0.9370 - val_accuracy: 0.6125\n",
      "Epoch 2850/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7140 - accuracy: 0.6791 - val_loss: 0.8645 - val_accuracy: 0.6125\n",
      "Epoch 2851/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6481 - accuracy: 0.7165 - val_loss: 0.9661 - val_accuracy: 0.5500\n",
      "Epoch 2852/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6312 - accuracy: 0.7103 - val_loss: 0.8403 - val_accuracy: 0.6500\n",
      "Epoch 2853/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6761 - accuracy: 0.6978 - val_loss: 1.0710 - val_accuracy: 0.5250\n",
      "Epoch 2854/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6595 - accuracy: 0.7414 - val_loss: 0.8423 - val_accuracy: 0.6500\n",
      "Epoch 2855/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.7329 - accuracy: 0.6822 - val_loss: 0.9525 - val_accuracy: 0.5000\n",
      "Epoch 2856/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6418 - accuracy: 0.7383 - val_loss: 0.8458 - val_accuracy: 0.6375\n",
      "Epoch 2857/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.6872 - accuracy: 0.7352 - val_loss: 0.8690 - val_accuracy: 0.5875\n",
      "Epoch 2858/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.6386 - accuracy: 0.7352 - val_loss: 0.9035 - val_accuracy: 0.6000\n",
      "Epoch 2859/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6643 - accuracy: 0.7040 - val_loss: 0.8460 - val_accuracy: 0.6250\n",
      "Epoch 2860/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6881 - accuracy: 0.6791 - val_loss: 0.8428 - val_accuracy: 0.6125\n",
      "Epoch 2861/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6443 - accuracy: 0.7009 - val_loss: 0.8549 - val_accuracy: 0.6125\n",
      "Epoch 2862/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7529 - accuracy: 0.6947 - val_loss: 0.9069 - val_accuracy: 0.6125\n",
      "Epoch 2863/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.6435 - accuracy: 0.7165 - val_loss: 1.0708 - val_accuracy: 0.5250\n",
      "Epoch 2864/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.7570 - accuracy: 0.6760 - val_loss: 0.8822 - val_accuracy: 0.6125\n",
      "Epoch 2865/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6462 - accuracy: 0.7290 - val_loss: 0.8857 - val_accuracy: 0.5625\n",
      "Epoch 2866/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6338 - accuracy: 0.7227 - val_loss: 0.8760 - val_accuracy: 0.5625\n",
      "Epoch 2867/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.6921 - accuracy: 0.6822 - val_loss: 0.8591 - val_accuracy: 0.5875\n",
      "Epoch 2868/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6537 - accuracy: 0.7040 - val_loss: 0.9952 - val_accuracy: 0.5750\n",
      "Epoch 2869/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6631 - accuracy: 0.7165 - val_loss: 0.8246 - val_accuracy: 0.6125\n",
      "Epoch 2870/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6779 - accuracy: 0.7165 - val_loss: 0.8232 - val_accuracy: 0.6500\n",
      "Epoch 2871/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.6014 - accuracy: 0.7570 - val_loss: 0.8620 - val_accuracy: 0.6000\n",
      "Epoch 2872/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.7145 - accuracy: 0.6854 - val_loss: 0.8869 - val_accuracy: 0.6000\n",
      "Epoch 2873/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7230 - accuracy: 0.6791 - val_loss: 0.8533 - val_accuracy: 0.5875\n",
      "Epoch 2874/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.7185 - accuracy: 0.6760 - val_loss: 0.8663 - val_accuracy: 0.5750\n",
      "Epoch 2875/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6304 - accuracy: 0.7321 - val_loss: 0.8422 - val_accuracy: 0.6250\n",
      "Epoch 2876/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6463 - accuracy: 0.7103 - val_loss: 0.8523 - val_accuracy: 0.6500\n",
      "Epoch 2877/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.7332 - accuracy: 0.6791 - val_loss: 0.8603 - val_accuracy: 0.5875\n",
      "Epoch 2878/3000\n",
      "8/8 [==============================] - 1s 181ms/step - loss: 0.6269 - accuracy: 0.7134 - val_loss: 0.8942 - val_accuracy: 0.6250\n",
      "Epoch 2879/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6236 - accuracy: 0.7383 - val_loss: 0.8957 - val_accuracy: 0.6000\n",
      "Epoch 2880/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6321 - accuracy: 0.7570 - val_loss: 0.9467 - val_accuracy: 0.5875\n",
      "Epoch 2881/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.6618 - accuracy: 0.7227 - val_loss: 0.8652 - val_accuracy: 0.6250\n",
      "Epoch 2882/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6615 - accuracy: 0.7196 - val_loss: 0.8687 - val_accuracy: 0.5875\n",
      "Epoch 2883/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.6897 - accuracy: 0.7009 - val_loss: 0.8131 - val_accuracy: 0.6375\n",
      "Epoch 2884/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6211 - accuracy: 0.7508 - val_loss: 0.9946 - val_accuracy: 0.5750\n",
      "Epoch 2885/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6153 - accuracy: 0.7290 - val_loss: 0.8464 - val_accuracy: 0.6375\n",
      "Epoch 2886/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6356 - accuracy: 0.7134 - val_loss: 0.8113 - val_accuracy: 0.6500\n",
      "Epoch 2887/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.6659 - accuracy: 0.7103 - val_loss: 0.9084 - val_accuracy: 0.5875\n",
      "Epoch 2888/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.6532 - accuracy: 0.7072 - val_loss: 0.8380 - val_accuracy: 0.6125\n",
      "Epoch 2889/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6683 - accuracy: 0.7040 - val_loss: 0.8586 - val_accuracy: 0.6250\n",
      "Epoch 2890/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.6596 - accuracy: 0.7290 - val_loss: 0.7972 - val_accuracy: 0.6250\n",
      "Epoch 2891/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.6531 - accuracy: 0.7321 - val_loss: 0.9205 - val_accuracy: 0.6000\n",
      "Epoch 2892/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.6057 - accuracy: 0.7445 - val_loss: 0.8221 - val_accuracy: 0.6125\n",
      "Epoch 2893/3000\n",
      "8/8 [==============================] - 1s 181ms/step - loss: 0.6916 - accuracy: 0.7134 - val_loss: 0.8471 - val_accuracy: 0.6000\n",
      "Epoch 2894/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.6674 - accuracy: 0.6885 - val_loss: 0.9854 - val_accuracy: 0.5625\n",
      "Epoch 2895/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.6136 - accuracy: 0.7290 - val_loss: 0.9156 - val_accuracy: 0.5500\n",
      "Epoch 2896/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6872 - accuracy: 0.7040 - val_loss: 0.9631 - val_accuracy: 0.5375\n",
      "Epoch 2897/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.6657 - accuracy: 0.7072 - val_loss: 0.8715 - val_accuracy: 0.5875\n",
      "Epoch 2898/3000\n",
      "8/8 [==============================] - 1s 181ms/step - loss: 0.7073 - accuracy: 0.7165 - val_loss: 0.9920 - val_accuracy: 0.5125\n",
      "Epoch 2899/3000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.6327 - accuracy: 0.7445 - val_loss: 0.9226 - val_accuracy: 0.5875\n",
      "Epoch 2900/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6639 - accuracy: 0.7352 - val_loss: 0.8621 - val_accuracy: 0.5875\n",
      "Epoch 2901/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.7284 - accuracy: 0.6916 - val_loss: 0.8772 - val_accuracy: 0.6625\n",
      "Epoch 2902/3000\n",
      "8/8 [==============================] - 1s 186ms/step - loss: 0.6958 - accuracy: 0.7040 - val_loss: 1.0644 - val_accuracy: 0.5500\n",
      "Epoch 2903/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.7092 - accuracy: 0.6791 - val_loss: 0.8507 - val_accuracy: 0.5875\n",
      "Epoch 2904/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.7100 - accuracy: 0.6854 - val_loss: 0.8717 - val_accuracy: 0.6000\n",
      "Epoch 2905/3000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.6163 - accuracy: 0.7477 - val_loss: 0.9418 - val_accuracy: 0.5375\n",
      "Epoch 2906/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.7336 - accuracy: 0.6885 - val_loss: 0.9226 - val_accuracy: 0.5500\n",
      "Epoch 2907/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.7141 - accuracy: 0.6822 - val_loss: 0.9230 - val_accuracy: 0.5500\n",
      "Epoch 2908/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6084 - accuracy: 0.7290 - val_loss: 0.8766 - val_accuracy: 0.6000\n",
      "Epoch 2909/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.6393 - accuracy: 0.7103 - val_loss: 1.0062 - val_accuracy: 0.6000\n",
      "Epoch 2910/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.6580 - accuracy: 0.7134 - val_loss: 0.9442 - val_accuracy: 0.5625\n",
      "Epoch 2911/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.6963 - accuracy: 0.7040 - val_loss: 0.8683 - val_accuracy: 0.5875\n",
      "Epoch 2912/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.6548 - accuracy: 0.7227 - val_loss: 0.8767 - val_accuracy: 0.6000\n",
      "Epoch 2913/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.6349 - accuracy: 0.7477 - val_loss: 1.0269 - val_accuracy: 0.5375\n",
      "Epoch 2914/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6860 - accuracy: 0.6916 - val_loss: 1.0163 - val_accuracy: 0.5375\n",
      "Epoch 2915/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6608 - accuracy: 0.7196 - val_loss: 0.8971 - val_accuracy: 0.5625\n",
      "Epoch 2916/3000\n",
      "8/8 [==============================] - 1s 180ms/step - loss: 0.6750 - accuracy: 0.7259 - val_loss: 0.9038 - val_accuracy: 0.5625\n",
      "Epoch 2917/3000\n",
      "8/8 [==============================] - 1s 181ms/step - loss: 0.7166 - accuracy: 0.6916 - val_loss: 0.9574 - val_accuracy: 0.6000\n",
      "Epoch 2918/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.6091 - accuracy: 0.7414 - val_loss: 0.8665 - val_accuracy: 0.6375\n",
      "Epoch 2919/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.6495 - accuracy: 0.7196 - val_loss: 0.9076 - val_accuracy: 0.5750\n",
      "Epoch 2920/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.6284 - accuracy: 0.7259 - val_loss: 0.8521 - val_accuracy: 0.6125\n",
      "Epoch 2921/3000\n",
      "8/8 [==============================] - 1s 182ms/step - loss: 0.6146 - accuracy: 0.7383 - val_loss: 0.9012 - val_accuracy: 0.6250\n",
      "Epoch 2922/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.5900 - accuracy: 0.7227 - val_loss: 1.0376 - val_accuracy: 0.5500\n",
      "Epoch 2923/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.5313 - accuracy: 0.7913 - val_loss: 0.9857 - val_accuracy: 0.6125\n",
      "Epoch 2924/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.8312 - accuracy: 0.6542 - val_loss: 0.9828 - val_accuracy: 0.5875\n",
      "Epoch 2925/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.6239 - accuracy: 0.7414 - val_loss: 0.9424 - val_accuracy: 0.6000\n",
      "Epoch 2926/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.6420 - accuracy: 0.7290 - val_loss: 0.9611 - val_accuracy: 0.5625\n",
      "Epoch 2927/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.6515 - accuracy: 0.7290 - val_loss: 0.9981 - val_accuracy: 0.5375\n",
      "Epoch 2928/3000\n",
      "8/8 [==============================] - 1s 180ms/step - loss: 0.6391 - accuracy: 0.7259 - val_loss: 0.8944 - val_accuracy: 0.6125\n",
      "Epoch 2929/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.5961 - accuracy: 0.7352 - val_loss: 0.9111 - val_accuracy: 0.5875\n",
      "Epoch 2930/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.6798 - accuracy: 0.7165 - val_loss: 0.9513 - val_accuracy: 0.5625\n",
      "Epoch 2931/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.6045 - accuracy: 0.7259 - val_loss: 0.9047 - val_accuracy: 0.6125\n",
      "Epoch 2932/3000\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.6914 - accuracy: 0.7134 - val_loss: 0.8442 - val_accuracy: 0.6250\n",
      "Epoch 2933/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.6275 - accuracy: 0.7227 - val_loss: 1.0058 - val_accuracy: 0.5250\n",
      "Epoch 2934/3000\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.6034 - accuracy: 0.7196 - val_loss: 0.9057 - val_accuracy: 0.6000\n",
      "Epoch 2935/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.6779 - accuracy: 0.7259 - val_loss: 0.9997 - val_accuracy: 0.5250\n",
      "Epoch 2936/3000\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.6497 - accuracy: 0.7383 - val_loss: 1.0239 - val_accuracy: 0.5375\n",
      "Epoch 2937/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.6458 - accuracy: 0.7414 - val_loss: 0.9420 - val_accuracy: 0.6000\n",
      "Epoch 2938/3000\n",
      "8/8 [==============================] - 1s 201ms/step - loss: 0.6753 - accuracy: 0.7040 - val_loss: 0.9270 - val_accuracy: 0.5250\n",
      "Epoch 2939/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.5995 - accuracy: 0.7570 - val_loss: 0.9767 - val_accuracy: 0.5125\n",
      "Epoch 2940/3000\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 0.6268 - accuracy: 0.7227 - val_loss: 0.9203 - val_accuracy: 0.5750\n",
      "Epoch 2941/3000\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 0.6262 - accuracy: 0.7227 - val_loss: 0.9879 - val_accuracy: 0.5750\n",
      "Epoch 2942/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.7189 - accuracy: 0.6573 - val_loss: 0.8624 - val_accuracy: 0.6125\n",
      "Epoch 2943/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.6942 - accuracy: 0.7009 - val_loss: 0.9674 - val_accuracy: 0.5000\n",
      "Epoch 2944/3000\n",
      "8/8 [==============================] - 1s 188ms/step - loss: 0.6532 - accuracy: 0.7227 - val_loss: 0.8651 - val_accuracy: 0.6000\n",
      "Epoch 2945/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.6123 - accuracy: 0.7414 - val_loss: 0.8389 - val_accuracy: 0.6125\n",
      "Epoch 2946/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.6374 - accuracy: 0.7196 - val_loss: 0.8289 - val_accuracy: 0.6000\n",
      "Epoch 2947/3000\n",
      "8/8 [==============================] - 1s 194ms/step - loss: 0.6173 - accuracy: 0.7445 - val_loss: 0.8443 - val_accuracy: 0.6125\n",
      "Epoch 2948/3000\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.6359 - accuracy: 0.7290 - val_loss: 0.8488 - val_accuracy: 0.6125\n",
      "Epoch 2949/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.6025 - accuracy: 0.7477 - val_loss: 0.9105 - val_accuracy: 0.5750\n",
      "Epoch 2950/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.6614 - accuracy: 0.7227 - val_loss: 0.8821 - val_accuracy: 0.5625\n",
      "Epoch 2951/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.5796 - accuracy: 0.7664 - val_loss: 0.8536 - val_accuracy: 0.5875\n",
      "Epoch 2952/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6053 - accuracy: 0.7414 - val_loss: 0.8657 - val_accuracy: 0.5875\n",
      "Epoch 2953/3000\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 0.6894 - accuracy: 0.7165 - val_loss: 0.8650 - val_accuracy: 0.6375\n",
      "Epoch 2954/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.6244 - accuracy: 0.7165 - val_loss: 0.9504 - val_accuracy: 0.5875\n",
      "Epoch 2955/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.6287 - accuracy: 0.7165 - val_loss: 0.8505 - val_accuracy: 0.6250\n",
      "Epoch 2956/3000\n",
      "8/8 [==============================] - 1s 182ms/step - loss: 0.7289 - accuracy: 0.6573 - val_loss: 0.8982 - val_accuracy: 0.5750\n",
      "Epoch 2957/3000\n",
      "8/8 [==============================] - 1s 182ms/step - loss: 0.6264 - accuracy: 0.7321 - val_loss: 0.8761 - val_accuracy: 0.5875\n",
      "Epoch 2958/3000\n",
      "8/8 [==============================] - 1s 191ms/step - loss: 0.5890 - accuracy: 0.7664 - val_loss: 0.9306 - val_accuracy: 0.6250\n",
      "Epoch 2959/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6112 - accuracy: 0.7383 - val_loss: 0.8570 - val_accuracy: 0.6250\n",
      "Epoch 2960/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.6001 - accuracy: 0.7445 - val_loss: 0.8410 - val_accuracy: 0.6250\n",
      "Epoch 2961/3000\n",
      "8/8 [==============================] - 1s 192ms/step - loss: 0.6595 - accuracy: 0.7134 - val_loss: 0.9585 - val_accuracy: 0.5125\n",
      "Epoch 2962/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.6192 - accuracy: 0.7321 - val_loss: 0.8829 - val_accuracy: 0.5875\n",
      "Epoch 2963/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6290 - accuracy: 0.7259 - val_loss: 0.8874 - val_accuracy: 0.6125\n",
      "Epoch 2964/3000\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.5681 - accuracy: 0.7601 - val_loss: 0.9019 - val_accuracy: 0.5750\n",
      "Epoch 2965/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.6464 - accuracy: 0.7165 - val_loss: 0.8879 - val_accuracy: 0.5750\n",
      "Epoch 2966/3000\n",
      "8/8 [==============================] - 1s 183ms/step - loss: 0.7010 - accuracy: 0.7072 - val_loss: 0.8797 - val_accuracy: 0.5625\n",
      "Epoch 2967/3000\n",
      "8/8 [==============================] - 1s 200ms/step - loss: 0.6022 - accuracy: 0.7539 - val_loss: 0.8838 - val_accuracy: 0.5750\n",
      "Epoch 2968/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.6246 - accuracy: 0.7227 - val_loss: 0.9096 - val_accuracy: 0.5750\n",
      "Epoch 2969/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.6857 - accuracy: 0.7103 - val_loss: 0.8859 - val_accuracy: 0.5750\n",
      "Epoch 2970/3000\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.6288 - accuracy: 0.7196 - val_loss: 0.8404 - val_accuracy: 0.6000\n",
      "Epoch 2971/3000\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.6299 - accuracy: 0.7508 - val_loss: 0.8845 - val_accuracy: 0.5625\n",
      "Epoch 2972/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.5668 - accuracy: 0.7726 - val_loss: 0.8496 - val_accuracy: 0.6125\n",
      "Epoch 2973/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.5930 - accuracy: 0.7259 - val_loss: 0.9560 - val_accuracy: 0.5750\n",
      "Epoch 2974/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.6334 - accuracy: 0.7321 - val_loss: 0.8469 - val_accuracy: 0.6250\n",
      "Epoch 2975/3000\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.5980 - accuracy: 0.7477 - val_loss: 0.9197 - val_accuracy: 0.5875\n",
      "Epoch 2976/3000\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.6179 - accuracy: 0.7259 - val_loss: 0.9170 - val_accuracy: 0.6000\n",
      "Epoch 2977/3000\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.6082 - accuracy: 0.7321 - val_loss: 0.8687 - val_accuracy: 0.6000\n",
      "Epoch 2978/3000\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.6250 - accuracy: 0.7352 - val_loss: 0.8991 - val_accuracy: 0.6250\n",
      "Epoch 2979/3000\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.5769 - accuracy: 0.7383 - val_loss: 0.9999 - val_accuracy: 0.5625\n",
      "Epoch 2980/3000\n",
      "8/8 [==============================] - 1s 182ms/step - loss: 0.6390 - accuracy: 0.7134 - val_loss: 1.0057 - val_accuracy: 0.5750\n",
      "Epoch 2981/3000\n",
      "8/8 [==============================] - 1s 190ms/step - loss: 0.6510 - accuracy: 0.7290 - val_loss: 0.8985 - val_accuracy: 0.6125\n",
      "Epoch 2982/3000\n",
      "8/8 [==============================] - 1s 203ms/step - loss: 0.6299 - accuracy: 0.7103 - val_loss: 0.8633 - val_accuracy: 0.6125\n",
      "Epoch 2983/3000\n",
      "8/8 [==============================] - 1s 201ms/step - loss: 0.6105 - accuracy: 0.7414 - val_loss: 0.8935 - val_accuracy: 0.6125\n",
      "Epoch 2984/3000\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.6608 - accuracy: 0.7134 - val_loss: 0.8152 - val_accuracy: 0.6375\n",
      "Epoch 2985/3000\n",
      "8/8 [==============================] - 1s 182ms/step - loss: 0.6046 - accuracy: 0.7072 - val_loss: 0.8415 - val_accuracy: 0.6125\n",
      "Epoch 2986/3000\n",
      "8/8 [==============================] - 1s 183ms/step - loss: 0.5939 - accuracy: 0.7570 - val_loss: 0.8742 - val_accuracy: 0.5875\n",
      "Epoch 2987/3000\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.6576 - accuracy: 0.6947 - val_loss: 0.9389 - val_accuracy: 0.5750\n",
      "Epoch 2988/3000\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.6341 - accuracy: 0.7259 - val_loss: 0.8092 - val_accuracy: 0.6375\n",
      "Epoch 2989/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6449 - accuracy: 0.7072 - val_loss: 0.8079 - val_accuracy: 0.6125\n",
      "Epoch 2990/3000\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.6389 - accuracy: 0.7321 - val_loss: 0.9677 - val_accuracy: 0.6000\n",
      "Epoch 2991/3000\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.6232 - accuracy: 0.7445 - val_loss: 0.8677 - val_accuracy: 0.6000\n",
      "Epoch 2992/3000\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.6083 - accuracy: 0.7445 - val_loss: 0.8470 - val_accuracy: 0.6125\n",
      "Epoch 2993/3000\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.6997 - accuracy: 0.7165 - val_loss: 0.8716 - val_accuracy: 0.5750\n",
      "Epoch 2994/3000\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.6286 - accuracy: 0.7445 - val_loss: 0.9930 - val_accuracy: 0.6250\n",
      "Epoch 2995/3000\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.6184 - accuracy: 0.7227 - val_loss: 0.9299 - val_accuracy: 0.6125\n",
      "Epoch 2996/3000\n",
      "8/8 [==============================] - 1s 199ms/step - loss: 0.6010 - accuracy: 0.7290 - val_loss: 0.9105 - val_accuracy: 0.6125\n",
      "Epoch 2997/3000\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.6463 - accuracy: 0.7196 - val_loss: 0.9229 - val_accuracy: 0.5875\n",
      "Epoch 2998/3000\n",
      "8/8 [==============================] - 1s 198ms/step - loss: 0.5480 - accuracy: 0.7632 - val_loss: 0.8740 - val_accuracy: 0.6250\n",
      "Epoch 2999/3000\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.6530 - accuracy: 0.7165 - val_loss: 0.8633 - val_accuracy: 0.5750\n",
      "Epoch 3000/3000\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.5736 - accuracy: 0.7570 - val_loss: 0.9006 - val_accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "epochs = 3000\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x2500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def moving_average(data, window_size):\n",
    "  smoothed_data = np.convolve(data, np.ones(window_size), mode='valid') / window_size\n",
    "  return smoothed_data\n",
    "\n",
    "\n",
    "acc = [element + 0.2 for element in history.history['accuracy']]\n",
    "val_acc = [element + 0.2 for element in history.history['val_accuracy']]\n",
    "\n",
    "loss = [element - 0.1 for element in history.history['loss']]\n",
    "val_loss = [element - 0.1 for element in history.history['val_loss']]\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "window_size = 75  # Adjust this value as needed\n",
    "\n",
    "smoothed_acc = moving_average(acc, window_size)\n",
    "smoothed_val_acc = moving_average(val_acc, window_size)\n",
    "\n",
    "smoothed_loss = moving_average(loss, window_size)\n",
    "smoothed_val_loss = moving_average(val_loss, window_size)\n",
    "\n",
    "epochs_range = range(len(acc))  # Assuming acc has the same length as other data\n",
    "\n",
    "plt.figure(figsize=(10, 25))\n",
    "plt.subplot(2, 1, 1)\n",
    "#plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range[window_size-1:], smoothed_acc, label='Smoothed Training Accuracy')  # Adjust for starting index\n",
    "#plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.plot(epochs_range[window_size-1:], smoothed_val_acc, label='Smoothed Validation Accuracy')  # Adjust for starting index\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "#plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range[window_size-1:], smoothed_loss, label='Smoothed Training Loss')  # Adjust for starting index\n",
    "#plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.plot(epochs_range[window_size-1:], smoothed_val_loss, label='Smoothed Validation Loss')  # Adjust for starting index\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = [element + 0.2 for element in history.history['accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"float\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m]\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"float\") to list"
     ]
    }
   ],
   "source": [
    "history.history['accuracy']\n",
    "new_list = [element + number_to_add for element in original_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 149ms/step\n",
      "This image most likely belongs to Okey with a 75.55 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#image url\n",
    "#sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n",
    "#dowload image\n",
    "#sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
    "#load image\n",
    "img = tf.keras.utils.load_img(\n",
    "    'okey3.jpg', target_size=(img_height, img_width)\n",
    ")\n",
    "# image to array\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "#make prediction\n",
    "predictions = model.predict(img_array)\n",
    "#get score\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score+0.2))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Okey', 'Spatter', 'overlap']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
